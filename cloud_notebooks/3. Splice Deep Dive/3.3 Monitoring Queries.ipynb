{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['JDBC_HOST'] = 'jrtest01-splice-hregion'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<link rel=\"stylesheet\" href=\"https://doc.splicemachine.com/jupyter/css/custom.css\">\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<link rel=\"stylesheet\" href=\"https://doc.splicemachine.com/jupyter/css/custom.css\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monitoring Queries with the Database Console\n",
    "\n",
    "This notebook introduces the Spark Database Console, which you can use to monitor Splice Machine queries that are running in Spark, in these sections:\n",
    "\n",
    "* *Accessing the Console*\n",
    "* *Basic UI Features*\n",
    "* *Running a Basic Query*\n",
    "* *Drilling Down into a Query*\n",
    "* *Terminating an Active Query*\n",
    "* *Parallelism and Spark*\n",
    "\n",
    "## About Spark Jobs in Splice Machine\n",
    "\n",
    "You may recall that Splice Machine has a dual-engine architecture can run statements and queries directly in HBase (the `control` side) or in Apache Spark. You can see which engine is used (`control` or `Spark`) from examining the top line of the `explain` for a query. Fast queries that run in milliseconds are sent directly to the control engine, while larger queries processing more data go to the Spark engine.\n",
    "\n",
    "You can use the DB Console to monitor the progress of queries that are sent to the Spark engine, including GC usage. You can also terminate queries when necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing the Console\n",
    "\n",
    "You access the Spark DB Console by opening a new browser tab, then navigating to the console's URL:\n",
    "\n",
    "* For our training classes, open a new browser tab and point at `localhost:4040`. \n",
    "* For actual clusters, the access path depends on whether you are using Splice Machine's cloud service or your own infrastructure.  See our documentation for specifics.\n",
    "\n",
    "<p class=\"noteNote\">The Spark DB Console is not accessible until you've run at least one Spark query on your cluster.</p>\n",
    "\n",
    "Once you've started a Spark query, you'll see the DB Console ( *Spark* ) UI:\n",
    "<img class=\"fitwidth\" src=\"https://doc.splicemachine.com/zeppelin/images/zepSparkJobs-a.png\" alt=\"Console UI Top-Level Display\">\n",
    "\n",
    "\n",
    "<p class=\"noteNote\">The <em>Executors</em> tab of the console does not work when running code in this class.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic UI Features\n",
    "\n",
    "Before we use the console to examine a specific query, let's go over a few interesting notes about the DB Console:\n",
    "\n",
    "* Queries are reported as *Jobs* in the Spark UI\n",
    "* Each Job will have *Stages*\n",
    "* Each Stage will have *Tasks*\n",
    "\n",
    "### Drilling Down\n",
    "\n",
    "In general, you can click anything that displays as a <span class=\"ConsoleLink\">blue link</span> to drill down into a more detailed view. For example,if you were  looking at the following information displayed in the Console, you could click <span class=\"ConsoleLink\">Produce Result Set</span> in the following description from the completed jobs table, which will drill down into the job details for *Job 6*:\n",
    "<img class=\"fitwidth\" src=\"https://doc.splicemachine.com/zeppelin/images/zepConsoleDrillDown-a.png\" alt=\"Drilling Down in the Console UI\">\n",
    "\n",
    "You can continue to drill down from there to reveal increasing levels of detail. In the next section of this notebook, we will view job details and then drill down for an example query.\n",
    "\n",
    "### Switching Views\n",
    "\n",
    "You can quickly switch to a different view by clicking a tab in the tab bar at the top of the console screen. Note that the *Jobs* tab is selected in this screen shot:\n",
    "<img class=\"fitwidth\" src=\"https://doc.splicemachine.com/zeppelin/images/zepConsoleTabs-a.png\" alt=\"Console UI Main Tabs display\">\n",
    "\n",
    "### Hovering\n",
    "\n",
    "You can hover the cursor over interface element links, like the <span class=\"ConsoleLink\">Event Timeline</span> drop-down in the following image, to display a screen tip for the item:\n",
    "<img class=\"fitwidth\" src=\"https://doc.splicemachine.com/zeppelin/images/zepConsoleHover-a.png\" alt=\"Console UI Event Timeline drop-down\">\n",
    "\n",
    "Similarly, you can hover over the <span class=\"ConsoleLink\">?</span> to display the definition for a term; this example is displaying the definition of a job:\n",
    "<img class=\"fitwidth\" src=\"https://doc.splicemachine.com/zeppelin/images/zepConsoleHover2-a.png\" alt=\"Hovering to display term definition in the Console UI\">\n",
    "\n",
    "And you can hover over an event in timeline display to see summary information; for example:\n",
    "<img class=\"fitwidth\" src=\"https://doc.splicemachine.com/zeppelin/images/zepConsoleTimelineHover-a.png\" alt=\"Hovering over the Console UI Timeline Display\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running a Basic Query\n",
    "\n",
    "Let's generate an `EXPLAIN` plan for a simple query that we previously ran: `explain select count(*) from index_example`. Generate the plan by running the next cell:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql \n",
    "\n",
    "explain select count(*) from dev1.index_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />\n",
    "\n",
    "Notice the `engine=Spark` on the top line, which indicates that this query will be processed by the Spark engine, which means that we can monitor the query in the Spark DB Console.\n",
    "\n",
    "Now let's actually run the query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql \n",
    "\n",
    "select count(*) from dev1.index_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />\n",
    "\n",
    "Now let's use the DB Console to view the query - remember to go to `localhost:4040` in a new browser window. You should see something like this:\n",
    "<img class=\"fitwidth\" src=\"https://doc.splicemachine.com/zeppelin/images/zepSparkJob2-a.png\" alt=\"Viewing a query in the console UI\">\n",
    "\n",
    "If you got to the DB Console quickly enough after running the query, it may show as an *Active Job* instead of being a *Completed Job.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drilling Down into Our Results\n",
    "\n",
    "Let's examine the *Stages* of the *Job* we just ran by starting on the Jobs page and clicking <span class=\"ConsoleLink\">Produce Result Set</span> for the above query. You'll see the *Job Detail* display for the query:\n",
    "\n",
    "  <img class=\"fitwidth\" src=\"https://doc.splicemachine.com/zeppelin/images/zepJobDetail1-a.png\" alt=\"Job Detail in the Console UI\">\n",
    "\n",
    "Note that the detail includes this information:\n",
    "\n",
    "* This job has two Stages.\n",
    "* Each Stage has a duration.\n",
    "* Each Stage in this Job ran one Task.\n",
    "\n",
    "  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; *Note:* The number of tasks required for the job may be different in your environment.\n",
    "\n",
    "### Viewing Job Details Graphically\n",
    "\n",
    "You can see a graphical representation of the actual activity performed within the Job's Stages by clicking the <span class=\"ConsoleLink\">DAG Visualization</span> link above the *Completed Stages* section of the Job Details display. Here's what that looks like for our example query:\n",
    "\n",
    "  <img class=\"fitwidth\" src=\"https://doc.splicemachine.com/zeppelin/images/zepJobDetailDag-a.png\" alt=\"Directed Graph Visualization in the Console UI\">\n",
    "\n",
    "Note that this is essentially another view of the EXPLAIN plan for this query, with the execution flow depicted by the arrows.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viewing Stage Details\n",
    "\n",
    "To drill down into the detail of the first Stage of our query, click anywhere in the box representing that Stage starting with TableScan in the DAG visualization. The Console displays the details of that Stage:\n",
    "\n",
    "  <img class=\"fitwidth\" src=\"https://doc.splicemachine.com/zeppelin/images/zepStageDetailDag-a.png\" alt=\"Viewing details of a stage in the Console UI\">\n",
    "\n",
    "The DAG Visualization for the Stage is shown at the top of this view; you can hide the DAG by clicking the <span class=\"ConsoleLink\">DAG Visualization</span> link, or you can scroll down below the graph to see the *Summary Metrics* for the Stage:\n",
    "\n",
    "  <img class=\"fitwidth\" src=\"https://doc.splicemachine.com/zeppelin/images/zepStageDetails-a.png\" alt=\"Stage Details \">\n",
    "\n",
    "At the very bottom of this view, we see *Tasks.*  These are the most basic work units in the Spark Engine. For each task you will see:\n",
    "\n",
    "* a duration\n",
    "* garbage collection time\n",
    "* other information relevant to the task activity\n",
    "\n",
    "In the above example, we see that the set of Tasks:\n",
    "\n",
    "* performed a TableScan\n",
    "* read around 1.3M rows total\n",
    "* wrote out some bytes of records for processing by the next Stage\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viewing the Event Timeline\n",
    "\n",
    "You can get another view of the current Stage by clicking the <span class=\"ConsoleLink\">Event Timeline</span> link; the Console the displays all tasks in this stage on a timeline:\n",
    "  <img class=\"fitwidth\" src=\"https://doc.splicemachine.com/zeppelin/images/zepStageTimeline-a.png\" alt=\"Viewing the event timeline for a stage in the Console UI\">\n",
    "\n",
    "This view is especially useful when a Stage has many tasks, and you want to see how many executors and how much parallelism is being achieved for this stage of the query. More on this in a moment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Terminating an Active Query\n",
    "You can terminate an active job if you determine that something isn't working as expected. Simply access the *Jobs* tab while a job is actively running, and click the the *(kill)* text displayed next to the job description, as shown here:\n",
    "\n",
    "<img class=\"fitwidth\" src=\"https://doc.splicemachine.com/zeppelin/images/zepKillJob-a.png\">\n",
    "\n",
    "You'll be asked to confirm that you want to terminate that job.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About Parallelism and Spark\n",
    "\n",
    "The power of Splice Machine in performing large analytic queries quickly lies in its ability to run those queries with parallel resources.  Spark has the capability of running a number of Job/Stages/Tasks in parallel.  How much parallelism you see, and where, depends on the following:\n",
    "\n",
    "<table class=\"splicezepOddEven\">\n",
    "    <col width=\"25%\" />\n",
    "    <col />\n",
    "    <thead>\n",
    "        <tr>\n",
    "            <th>Parallelism Factor</th>\n",
    "            <th>Description</th>\n",
    "        </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td>Active executors</td>\n",
    "            <td><p>How many executors are available to run your query?</p>\n",
    "                <p>The available executor count on your cluster depends on your configuration; in our training example we have just one, but clusters can have many executors.  Each executor is typically configured to run 4 tasks in parallel.  Therefore your maximum parallelism is typically the number of executors * 4 simultaneous tasks.  For example if your cluster had 12 executors, you can run 48 tasks in parallel across all running jobs.</p></td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Tasks per stage in one query</td>\n",
    "            <td><p>Splice Machine and Spark will dynamically split up the workload across many tasks for large data sets.</p>\n",
    "            <p>Our example data set contains only 1 million rows; as a result, our example query won't have many Tasks per Stage. With more data in your tables, you will see more tasks in parallel in a given Stage.</p>\n",
    "                </td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td># of Queries being run simultaneously</td>\n",
    "            <td>Spark can run queries simultaneously with available resources.</td>\n",
    "        </tr>\n",
    "    </tbody>\n",
    "</table>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where to Go Next\n",
    "The next notebook in this presentation introduces you to <a href=\"./3.4%20Transactions%20with%20Spark%20%26%20JDBC.ipynb\">the transactional nature of Splice Machine and using JDBC to program transactions.</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Additional Help\n",
    "As you've seen in this notebook, the Database Console UI is extremely useful in getting a view into how well your queries are getting processed.  \n",
    "\n",
    "Once you have your data loaded at or near target scale, if you are not seeing good throughput (task activity, etc), please visit our <a href=\"https://splicemachine.slack.com/messages/splice-community/\" target=\"_blank\"><em>splice-community</em> Slack channel</a> and ask for help; if you've not already done so, you can register for this channel <a href=\"https://www.splicemachine.com/community/slack-channel-signup/\" target=\"_blank\">here</a>.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
