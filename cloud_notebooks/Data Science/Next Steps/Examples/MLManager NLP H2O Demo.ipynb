{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "#s {\n",
    "}\n",
    "h1, h2, h3, h4, h5, h6, table, button, a, p, blockquote {\n",
    "font-family:Geneva;\n",
    "}\n",
    "\n",
    ".log {\n",
    "transition: all .2s ease-in-out;\n",
    "}\n",
    "\n",
    ".log:hover {a\n",
    "transform: scale(1.05);\n",
    "}\n",
    "</style>\n",
    "<div id='s' style='width:90%'>\n",
    "<center><img class='log' src='https://splicemachine.com/wp-content/uploads/splice-logo-1.png' width='20%' style='z-index:5'></center>\n",
    "<center><h1 class='log' style='font-size:40px; color:black;'>Welcome to Splice Machine MLManager</h1></center>\n",
    "<center><h2 class = 'log' style='font-size:25px; color:grey;'>The data platform for intelligent applications</center>\n",
    "<center><img class='log' src='https://splice-demo.s3.amazonaws.com/splice-machine-data-science-process-h2o.png' width='40%' style='z-index:5'></center>\n",
    "</div>\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this notebook, we're going to take a look at using MLManager with [H2O](https://www.h2o.ai/) + [Spark](https://spark.apache.org/)\n",
    "<h2 style='font-size:25px;  font-weight:bold'>What is <a href=http://docs.h2o.ai/sparkling-water/2.1/latest-stable/doc/pysparkling.html>PySparkling Water?</a> What is <a href=https://splicemachine.com/product/ml-manager/>MLManager?</a></h2>\n",
    "<style>\n",
    "blockquote{\n",
    "  font-size: 15px;\n",
    "  background: #f9f9f9;\n",
    "  border-left: 10px solid #ccc;\n",
    "  margin: .5em 10px;\n",
    "  padding: 30em, 10px;\n",
    "  quotes: \"\\201C\"\"\\201D\"\"\\2018\"\"\\2019\";\n",
    "  padding: 10px 20px;\n",
    "  line-height: 1.4;\n",
    "}\n",
    "\n",
    "blockquote:before {\n",
    "  content: open-quote;\n",
    "  display: inline;\n",
    "  height: 0;\n",
    "  line-height: 0;\n",
    "  left: -10px;\n",
    "  position: relative;\n",
    "  top: 30px;\n",
    "  bottom:30px;\n",
    "  color: #ccc;\n",
    "  font-size: 3em;\n",
    "    display:none;\n",
    "\n",
    "}\n",
    "\n",
    "p{\n",
    "  margin: 0;\n",
    "}\n",
    "\n",
    "footer{\n",
    "  margin:0;\n",
    "  text-align: right;\n",
    "  font-size: 1em;\n",
    "  font-style: italic;\n",
    "}\n",
    "</style>\n",
    "<blockquote><p class='quotation'><b><br><span style='font-size:25px'>PySparkling</span></b> <br><br>PySparkling Water is an awesome H2O extension that allows you to run H2O clusters on top of existing Spark clusters. With Splice Machine, this integration is taken care of for you, so it's simple to start modeling with your new favorite library</i></br><footer>Splice Machine</footer></blockquote><br>\n",
    "<blockquote><p class='quotation'><b><br><span style='font-size:25px'>MLManager (+MLFlow)</span></b><br><br>As a data scientist constantly creating new models and testing new features, it is necessary to effectively track and manage those different ML runs. MLManager + MLFlow allows you to track entire <code>experiments</code> and individual <code>run</code> parameters and metrics. The way you organize your flow is unique to you, and the intuitive Python API allows you to organize your development process and run with it.<br>\n",
    "     <center><img class='log' src='https://s3.amazonaws.com/splice-demo/mlflow+ui.png' width='40%' style='z-index:5'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's get started\n",
    "## In this notebook, we will see how to use Spark, H2O and MLManager to predict sentiment analysis of Amazon reviews, tracking everything in the [MLFlow UI](/mlflow) and deploy our models to production\n",
    "This is an adaptation of the original [H2O Demo](http://docs.h2o.ai/h2o-tutorials/latest-stable/h2o-world-2017/nlp/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important imports and setup\n",
    "* Create our Spark Session\n",
    "* Create our Native Spark Data Source\n",
    "* Create our PySparkling Water cluster\n",
    "* Import our MLManager functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from splicemachine.spark import PySpliceContext\n",
    "from splicemachine.mlflow_support import *\n",
    "from splicemachine.mlflow_support.utilities import get_user\n",
    "from pysparkling import *\n",
    "import h2o\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Spark Session\n",
    "spark = SparkSession.builder.config('spark.driver.memoryOverhead',1000).config('spark.driver.memory','2g').getOrCreate()\n",
    "# Native Spark Data Source\n",
    "splice = PySpliceContext(spark)\n",
    "# Register Splice so we can access database functions\n",
    "mlflow.register_splice_context(splice)\n",
    "# Create H2O Cluster\n",
    "conf = H2OConf().setInternalClusterMode()\n",
    "hc = H2OContext.getOrCreate(conf)\n",
    "schema = get_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Our Spark UI\n",
    "<blockquote>Now that we've created a SparkSession dedicated to this notebook, we can monitor the active jobs in the Spark UI. You can navigate to <code>/sparkmonitor/PORT</code> in the URL, replacing the port with the port of your active Spark Session. You can also view the Spark Session right here in the notebook using our <code>get_spark_ui</code> function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from splicemachine.notebook import get_spark_ui\n",
    "help(get_spark_ui)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_spark_ui()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Great! Now let's import our data\n",
    "<style>\n",
    "blockquote{\n",
    "  font-size: 15px;\n",
    "  background: #f9f9f9;\n",
    "  border-left: 10px solid #ccc;\n",
    "  margin: .5em 10px;\n",
    "  padding: 30em, 10px;\n",
    "  quotes: \"\\201C\"\"\\201D\"\"\\2018\"\"\\2019\";\n",
    "  padding: 10px 20px;\n",
    "  line-height: 1.4;\n",
    "}\n",
    "\n",
    "blockquote:before {\n",
    "  content: open-quote;\n",
    "  display: inline;\n",
    "  height: 0;\n",
    "  line-height: 0;\n",
    "  left: -10px;\n",
    "  position: relative;\n",
    "  top: 30px;\n",
    "  bottom:30px;\n",
    "  color: #ccc;\n",
    "  font-size: 3em;\n",
    "    display:none;\n",
    "\n",
    "}\n",
    "\n",
    "p{\n",
    "  margin: 0;\n",
    "}\n",
    "\n",
    "footer{\n",
    "  margin:0;\n",
    "  text-align: right;\n",
    "  font-size: 1em;\n",
    "  font-style: italic;\n",
    "}\n",
    "</style>\n",
    "<blockquote><p class='quotation'><b><br><span style='font-size:25px'>Importing Data</span></b> <br><br>There are a few easy ways to get data into Splice Machine, and we'll demonstrate 2 of them here. You can use the built-in <code>%%sql</code> magic to import data directly from external sources, such as S3, or you can use H2O to directly read the data from S3, create a table from that dataframe, and insert the data directly using the <code>PySpliceContext</code> you created in the cell above. </i></br><footer>Splice Machine</footer></blockquote><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 1: Direct Import from SQL\n",
    "<style>\n",
    "blockquote{\n",
    "  font-size: 15px;\n",
    "  background: #f9f9f9;\n",
    "  border-left: 10px solid #ccc;\n",
    "  margin: .5em 10px;\n",
    "  padding: 30em, 10px;\n",
    "  quotes: \"\\201C\"\"\\201D\"\"\\2018\"\"\\2019\";\n",
    "  padding: 10px 20px;\n",
    "  line-height: 1.4;\n",
    "}\n",
    "\n",
    "blockquote:before {\n",
    "  content: open-quote;\n",
    "  display: inline;\n",
    "  height: 0;\n",
    "  line-height: 0;\n",
    "  left: -10px;\n",
    "  position: relative;\n",
    "  top: 30px;\n",
    "  bottom:30px;\n",
    "  color: #ccc;\n",
    "  font-size: 3em;\n",
    "    display:none;\n",
    "\n",
    "}\n",
    "\n",
    "p{\n",
    "  margin: 0;\n",
    "}\n",
    "\n",
    "footer{\n",
    "  margin:0;\n",
    "  text-align: right;\n",
    "  font-size: 1em;\n",
    "  font-style: italic;\n",
    "}\n",
    "</style>\n",
    "<blockquote><p class='quotation'><b><br><span style='font-size:25px'>SQL Import</span></b> <br><br>This method is simple: Create your table, point it to a an S3 location, and run the import command</i></br><footer>Splice Machine</footer></blockquote><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS AMAZON_REVIEWS;\n",
    "CREATE TABLE AMAZON_REVIEWS(\n",
    "    PRODUCTID VARCHAR(250),\n",
    "    USERID VARCHAR(250),\n",
    "    SUMMARY VARCHAR(500),\n",
    "    SCORE INT,\n",
    "    HELPFULNESSDENOMINATOR BIGINT,\n",
    "    ID INT,\n",
    "    PROFILENAME VARCHAR(500),\n",
    "    HELPFULNESSNUMERATOR BIGINT,\n",
    "    REVIEW_TIME BIGINT,\n",
    "    REVIEW VARCHAR(15000),\n",
    "    PRIMARY KEY(ID)\n",
    ");\n",
    "\n",
    "\n",
    "-- Import the data\n",
    "call SYSCS_UTIL.IMPORT_DATA (\n",
    "     null,\n",
    "     'AMAZON_REVIEWS',\n",
    "     null,\n",
    "     's3a://splice-demo/AmazonReviews.csv',\n",
    "     ',',\n",
    "     null,\n",
    "     null,\n",
    "     null,\n",
    "     null,\n",
    "     -1,\n",
    "     's3a://splice-demo/bad',\n",
    "     null, \n",
    "     null);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "select top 10 * from AMAZON_REVIEWS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we can easily import the data into a Spark or H2O Data Frame with the <code>PySpliceContext</code> (Native Spark Data Source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get data from table into Spark Dataframe\n",
    "df2 = splice.df(f'select * from {schema}.amazon_reviews')\n",
    "hdf = hc.asH2OFrame(df2)\n",
    "hdf.describe()\n",
    "del hdf # Delete because we won't be using this frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 2: Import from H2O\n",
    "<style>\n",
    "blockquote{\n",
    "  font-size: 15px;\n",
    "  background: #f9f9f9;\n",
    "  border-left: 10px solid #ccc;\n",
    "  margin: .5em 10px;\n",
    "  padding: 30em, 10px;\n",
    "  quotes: \"\\201C\"\"\\201D\"\"\\2018\"\"\\2019\";\n",
    "  padding: 10px 20px;\n",
    "  line-height: 1.4;\n",
    "}\n",
    "\n",
    "blockquote:before {\n",
    "  content: open-quote;\n",
    "  display: inline;\n",
    "  height: 0;\n",
    "  line-height: 0;\n",
    "  left: -10px;\n",
    "  position: relative;\n",
    "  top: 30px;\n",
    "  bottom:30px;\n",
    "  color: #ccc;\n",
    "  font-size: 3em;\n",
    "    display:none;\n",
    "\n",
    "}\n",
    "\n",
    "p{\n",
    "  margin: 0;\n",
    "}\n",
    "\n",
    "footer{\n",
    "  margin:0;\n",
    "  text-align: right;\n",
    "  font-size: 1em;\n",
    "  font-style: italic;\n",
    "}\n",
    "</style>\n",
    "<blockquote><p class='quotation'><b><br><span style='font-size:25px'>H2O Import</span></b> <br><br>This method is also straightforward, and may be preferable to Data Scientists: Import your data using H2O, and then use the <code>PySpliceContext</code> to create the table from the dataframe and insert the data directly. You'll notice that this method doesn't directly involve any SQL.</i></br><footer>Splice Machine</footer></blockquote><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_path = \"https://splice-demo.s3.amazonaws.com/AmazonReviews.csv\"\n",
    "# Load data into H2O\n",
    "reviews = h2o.import_file(data_path)\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## H2O offers great functions to convert H2OFrames into Pandas and Spark DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spark DataFrame\n",
    "df = hc.asSparkFrame(reviews, copyMetadata=False)\n",
    "df.limit(100).show()\n",
    "del df._h2o_frame\n",
    "print(type(df))\n",
    "# Pandas DataFrame\n",
    "pdf = reviews.head().as_data_frame()\n",
    "display(pdf)\n",
    "print(type(pdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nice!\n",
    "<style>\n",
    "blockquote{\n",
    "  font-size: 15px;\n",
    "  background: #f9f9f9;\n",
    "  border-left: 10px solid #ccc;\n",
    "  margin: .5em 10px;\n",
    "  padding: 30em, 10px;\n",
    "  quotes: \"\\201C\"\"\\201D\"\"\\2018\"\"\\2019\";\n",
    "  padding: 10px 20px;\n",
    "  line-height: 1.4;\n",
    "}\n",
    "\n",
    "blockquote:before {\n",
    "  content: open-quote;\n",
    "  display: inline;\n",
    "  height: 0;\n",
    "  line-height: 0;\n",
    "  left: -10px;\n",
    "  position: relative;\n",
    "  top: 30px;\n",
    "  bottom:30px;\n",
    "  color: #ccc;\n",
    "  font-size: 3em;\n",
    "    display:none;\n",
    "\n",
    "}\n",
    "\n",
    "p{\n",
    "  margin: 0;\n",
    "}\n",
    "\n",
    "footer{\n",
    "  margin:0;\n",
    "  text-align: right;\n",
    "  font-size: 1em;\n",
    "  font-style: italic;\n",
    "}\n",
    "</style>\n",
    "<blockquote><p class='quotation'><b><br><span style='font-size:25px'>Create Table and Insert Data</span></b> <br><br>Now that we have our Spark DataFrame, we can create a table and insert data using <code>splice.createTable</code> and <code>splice.insert</code><br><b>Note: </b>If your code is hanging on the <code>insert</code> your cluser may be out of memory. Try configuring your Spark or H2O cluster with more memory. Read about that <a href=https://docs.h2o.ai/sparkling-water/2.1/latest-stable/doc/configuration/configuration_properties.html>here</a> and <a href=https://spark.apache.org/docs/latest/configuration.html#available-properties>here</a></footer></blockquote><br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(splice.createTable)\n",
    "print('----------------------------------------------------------------------------------------------------------------')\n",
    "help(splice.insert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create the table\n",
    "df = df.withColumnRenamed('Time', 'Review_Time')\n",
    "df = df.withColumnRenamed('Text', 'Review')\n",
    "splice._dropTableIfExists(f'{schema}.AMAZON_REVIEWS_H2O')\n",
    "splice.createTable(df, f'{schema}.AMAZON_REVIEWS_H2O', to_upper=True, drop_table=True)\n",
    "print('Inserting... ', end='')\n",
    "splice.insert(df, f'{schema}.AMAZON_REVIEWS_H2O',to_upper=True) # Use to_upper to give the SQL table uppercase columns\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "select top 10 varchar(Summary) Summary, Score, HelpfulnessDenominator, Id  from AMAZON_REVIEWS_H2O;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Awesome! Let's get modeling\n",
    "<style>\n",
    "blockquote{\n",
    "  font-size: 15px;\n",
    "  background: #f9f9f9;\n",
    "  border-left: 10px solid #ccc;\n",
    "  margin: .5em 10px;\n",
    "  padding: 30em, 10px;\n",
    "  quotes: \"\\201C\"\"\\201D\"\"\\2018\"\"\\2019\";\n",
    "  padding: 10px 20px;\n",
    "  line-height: 1.4;\n",
    "}\n",
    "\n",
    "blockquote:before {\n",
    "  content: open-quote;\n",
    "  display: inline;\n",
    "  height: 0;\n",
    "  line-height: 0;\n",
    "  left: -10px;\n",
    "  position: relative;\n",
    "  top: 30px;\n",
    "  bottom:30px;\n",
    "  color: #ccc;\n",
    "  font-size: 3em;\n",
    "    display:none;\n",
    "\n",
    "}\n",
    "\n",
    "p{\n",
    "  margin: 0;\n",
    "}\n",
    "\n",
    "footer{\n",
    "  margin:0;\n",
    "  text-align: right;\n",
    "  font-size: 1em;\n",
    "  font-style: italic;\n",
    "}\n",
    "</style>\n",
    "<blockquote><p class='quotation'><b><br><span style='font-size:25px'>Modeling</span></b> <br><br>We're going to try three different ways to approach this problem, and track it all with MLManager. \n",
    "    <ol>\n",
    "        <li>No Text Model: We will try to predict the customer reviews without using the text from the review. Just the Numeric Columns</li>\n",
    "        <li>Using the reviews: We will use Word2Vec to create vectors from the text of the reviews. We will then train a model on that word embedding feature-vector</li>\n",
    "        <li>Using the review summaries: We will use Word2Vec to create vectors from the text of the review summaries</li>\n",
    "    </ol>\n",
    "    Which do you think will perform the best?\n",
    "    </i></br><footer>Splice Machine</footer></blockquote><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Attempt\n",
    "Let's create a simple model using the non-review columns\n",
    "<br>\n",
    "<blockquote>\n",
    "    First, let's start our mlflow experiment! We can start a run and log import parameters, tags, and metrics as they come<br>\n",
    "Next, we can turn this into a binary-classification problem by turning score into a positive or negative review. We will say that 4 and 5 start reviews are positive, but you can change this and try other things!\n",
    "</br><footer>Splice Machine</footer></blockquote><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set our mlflow experiment\n",
    "mlflow.set_experiment('Sentiment Analysis')\n",
    "# Look at our dataframe\n",
    "reviews[\"PositiveReview\"] = (reviews[\"Score\"] >= 4).ifelse(\"1\", \"0\")\n",
    "reviews[\"PositiveReview\"].table()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can now see our experiment in the MLFlow UI \n",
    "\n",
    "<blockquote>You can always navigate to <a href=/mlflow>/mlflow</a> to view the MLFlow UI, or you can view it right here in the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from splicemachine.notebook import get_mlflow_ui\n",
    "get_mlflow_ui()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's see our Data Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from pyspark.sql.types import FloatType, IntegerType\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pdf = reviews[['ProductId', 'UserId', 'HelpfulnessNumerator', 'HelpfulnessDenominator', 'Time','PositiveReview']].as_data_frame()\n",
    "corr = pdf.corr()\n",
    "\n",
    "ticks = [i for i in range(len(corr.columns))]\n",
    "# Generate a mask for the upper triangle\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "# Color Scheme\n",
    "cmap = \"Greens\"\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr,  cmap=cmap, vmax=.3, center=0,\n",
    "            square=False, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
    "\n",
    "plt.xticks(ticks, corr.columns)\n",
    "plt.yticks(ticks, corr.columns)\n",
    "plt.title('Sentiment Data correlation heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can see some of our features have decent correlation (remember that we aren't using the reviews yet). Let's try a basic model\n",
    "### First, let's log some important information in our <code>run</code>\n",
    "<blockquote>H2O Has a <a href=https://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science.html>lot</a> of algorithms, so we'll use a Gradient Boosting Estimator<br>We'll log some things like our feature vector, label, train/test/validation split, training time, and even the model and notebook themselves directly to <a href='/mlflow'>mlflow</a></blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from h2o.estimators import H2OGradientBoostingEstimator\n",
    "from splicemachine.mlflow_support.utilities import get_user\n",
    "\n",
    "RATIOS = [0.7,0.15]\n",
    "\n",
    "# Start our run to keep track of important information\n",
    "mlflow.start_run(run_name='simple_run')\n",
    "\n",
    "predictors = ['ProductId', 'UserId', 'HelpfulnessNumerator', 'HelpfulnessDenominator', 'Time']\n",
    "response = 'PositiveReview'\n",
    "\n",
    "# lp is short for log_param\n",
    "# lm is short for log_metric\n",
    "mlflow.lp('predictors', predictors)\n",
    "mlflow.lp('label', response)\n",
    "mlflow.lp('source data table', f'{get_user()}.AMAZON_REVIEWS')\n",
    "\n",
    "# Train Test Split\n",
    "train,test,valid = reviews.split_frame(ratios=RATIOS)\n",
    "# Log our ratios\n",
    "mlflow.lp('ratios',RATIOS)\n",
    "\n",
    "gbm_baseline = H2OGradientBoostingEstimator(stopping_metric = \"AUC\", stopping_tolerance = 0.001,\n",
    "                                            stopping_rounds = 5, score_tree_interval = 10,\n",
    "                                            model_id = \"gbm_baseline.hex\"\n",
    "                                           )\n",
    "\n",
    "mlflow.lp('model_type', gbm_baseline.__class__)\n",
    "\n",
    "# Code block to time training\n",
    "with mlflow.timer('train_time'):\n",
    "    gbm_baseline.train(x = predictors, y = response, \n",
    "                       training_frame = train, validation_frame = test\n",
    "                      )\n",
    "# Log the model params to mlflow\n",
    "mlflow.log_params(gbm_baseline.get_params())\n",
    "# Log the model to MLFlow\n",
    "mlflow.log_model(gbm_baseline, 'baseline_model')\n",
    "# Log the training notebook to MLFlow\n",
    "mlflow.log_artifact('MLManager NLP H2O Demo.ipynb', 'training_notebook')\n",
    "gbm_baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You can see above that H2O gives you loads of details about your model. Let's inspect it a bit more and log some results to MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline  \n",
    "\n",
    "# Print and Log Model params\n",
    "params = dict(zip(gbm_baseline.summary().col_header[1:],\n",
    "                    gbm_baseline.summary().cell_values[0][1:]))\n",
    "print(gbm_baseline.summary())\n",
    "mlflow.log_params(params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, IFrame\n",
    "#Plot and Log Scoring history\n",
    "gbm_baseline.plot()\n",
    "print(\"AUC on Validation Data: \" + str(round(gbm_baseline.auc(valid = True), 3)))\n",
    "# Log training and validation metrics over time\n",
    "for step, row in gbm_baseline.scoring_history().iterrows():\n",
    "    row_dict = row.to_dict()\n",
    "    for r in row_dict:\n",
    "        if 'train' in r or 'valid' in r:\n",
    "            mlflow.log_metric(r, row_dict[r],step=step)\n",
    "\n",
    "cur_run = mlflow.current_run_id()\n",
    "cur_exp = mlflow.current_exp_id()\n",
    "link = f'/mlflow/#/metric/training_auc?runs=[\"{cur_run}\"]&experiment={cur_exp}&plot_metric_keys=[\\\"training_logloss\\\",\\\"validation_logloss\\\",\\\"training_rmse\\\",\\\"validation_rmse\\\"]'\n",
    "display(HTML(f'<font size=\"+2\">See your metrics plot <a target=\"_blank\" href={link}>here</a></font>'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print and Log Confusion Matrix\n",
    "print(gbm_baseline.confusion_matrix(valid = True))\n",
    "mlflow.lm('fpr', gbm_baseline.fpr(valid=True)[0][0])\n",
    "mlflow.lm('tpr', gbm_baseline.tpr(valid=True)[0][0])\n",
    "mlflow.lm('fnr', gbm_baseline.fnr(valid=True)[0][0])\n",
    "mlflow.lm('tnr', gbm_baseline.fnr(valid=True)[0][0])\n",
    "mlflow.lm('F0point5', gbm_baseline.F0point5(valid=True)[0][1])\n",
    "mlflow.lm('F1', gbm_baseline.F1(valid=True)[0][1])\n",
    "mlflow.lm('F2', gbm_baseline.F2(valid=True)[0][1])\n",
    "mlflow.lm('auc', gbm_baseline.auc(valid = True))\n",
    "mlflow.lp('threshold', gbm_baseline.F1(valid=True)[0][0]) # First element is the threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot and Log Variable Importance\n",
    "gbm_baseline.varimp_plot()\n",
    "for var in gbm_baseline.varimp():\n",
    "    mlflow.lm(f'varimp_{var[0]}',var[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partial Dependence Plot\n",
    "pdp_helpfulness = gbm_baseline.partial_plot(train, cols = [\"HelpfulnessNumerator\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# There is room for improvement \n",
    "## Let's now Tokenize words in the Review\n",
    "### But first, let's start our new run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Start new mlflow run\n",
    "mlflow.start_run(run_name='review_tokenizer')\n",
    "mlflow.lp('source data table', f'{get_user()}.AMAZON_REVIEWS')\n",
    "# Get common stop words from H2O\n",
    "data_path = \"https://splice-demo.s3.amazonaws.com/stop_words.csv\"\n",
    "STOP_WORDS = pd.read_csv(data_path, header=0)\n",
    "STOP_WORDS = list(STOP_WORDS['STOP_WORD'])\n",
    "print(STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect our reviews before tokenization\n",
    "reviews['Text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we can train our Doc2Vec model\n",
    "<blockquote>We are going to use the popular Gensim doc2vec implementation for scikit-learn. We use scikit-learn here because of it's implementation of <code>Pipelines</code> which allow us to create custom transformations on the data before training/running our model. This gives us the ultimate flexibility. We will use doc2vec, which is just an extension of word2vec but for full documents (sentences). We can also time how long it takes to train the word vectorizer, and log the vector size so we can change it and see how performance changes. Then we can look at some word synonyms to see how well the tokenizer did</i></br><footer>Splice Machine</footer></blockquote><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def tokenize( reviews ):\n",
    "    review_tokens = []\n",
    "    for review in reviews[0]:\n",
    "        # Remove non-letters\n",
    "        review = re.sub(\"[^a-zA-Z]\",\" \", review)\n",
    "        review = review.lower().split()\n",
    "\n",
    "        stops = set(STOP_WORDS)\n",
    "        review = [w for w in review if w not in stops]\n",
    "        review_tokens.append(review)\n",
    "    return(review_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Doc2Vec Model\n",
    "<blockquote>This will take a few minutes to run as the model needs to generate mappings of every sentence to vectors</i></br><footer>Splice Machine</footer></blockquote><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline as skPipe\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from gensim.sklearn_api import W2VTransformer, D2VTransformer\n",
    "import pandas as pd\n",
    "\n",
    "print('Collecting dataset...', end='')\n",
    "pdf = reviews['Text'].as_data_frame().astype('string')\n",
    "print('Done.')\n",
    "\n",
    "VECTOR_LENGTH = 50\n",
    "\n",
    "d2v_model = skPipe(verbose=True,\n",
    "                   steps = [\n",
    "                       ('preprocessor', FunctionTransformer(tokenize, validate=False)),\n",
    "                       ('doc2vec', D2VTransformer(size=VECTOR_LENGTH)),\n",
    "                       ('postprocessor', FunctionTransformer(lambda X: X.astype('double'), validate=True))\n",
    "                   ])\n",
    "with mlflow.timer('doc2vec_train_time'):\n",
    "    # tokenize and build vocab\n",
    "    d2v_model.fit([pdf.dropna()['Text']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we can use the Doc2Vec Model to see the most similar sentences of an input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "doc2vec_model = deepcopy(d2v_model.steps[1][1].gensim_model)\n",
    "\n",
    "# Tokenize our input\n",
    "inp = \"This tastes delicious\"\n",
    "tokens = tokenize([[inp]])\n",
    "new_vector = doc2vec_model.infer_vector(tokens[0])\n",
    "# Get our vectorized sentence\n",
    "sims = doc2vec_model.docvecs.most_similar([new_vector])\n",
    "print(f'Vector of input: {sims}\\n')\n",
    "# Get the most similar review\n",
    "index = sims[0][0]\n",
    "output = pdf.dropna()['Text'].iloc[index]\n",
    "\n",
    "print(f'Input: {inp}\\nMost similar Output: {output}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we can save this model and end our run\n",
    "<blockquote>We want to save this vectorizer as an <b>independent</b> <code>run</code>. This is because we may want to build more than 1 model that utilizes these word vectors. We don't want to duplicate those identical word vectors, so we can use the outputs for <b>more than one model</b>. This is the idea of a <i>feature store</i> where we use features from one dataset on multiple models. This is crucial to creating efficient ML workflow systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.log_model(d2v_model, 'doc2vec_model')\n",
    "mlflow.lp('vector_size', VECTOR_LENGTH)\n",
    "exp_id = mlflow.current_exp_id()\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_mlflow_ui(exp_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's vectorize our reviews\n",
    "<blockquote>Now that we have a word embedding for each word in our vocabulary, we will aggregate the words for each review using the <code>transform</code> function.  This will give us one aggregated word embedding for each review.</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate a vector for each review\n",
    "review_vecs = h2o.H2OFrame(d2v_model.transform([pdf.fillna(\"\")['Text']]))\n",
    "# Add the review vectors to the original dataframe\n",
    "# Add aggregated word embeddings \n",
    "ext_reviews = reviews.cbind(review_vecs)\n",
    "ext_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: GBM with Review vectors\n",
    "<blockquote>\n",
    "    Now we can train a GBM like before, but include the review vectors. This should hopefully increase improvement! We'll log everything to mlflow so we can compare the results.\n",
    "    </i></br><footer>Splice Machine</footer></blockquote><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from h2o.estimators import H2OGradientBoostingEstimator\n",
    "mlflow.end_run()\n",
    "mlflow.start_run(run_name='GBM with word vectors')\n",
    "RATIOS = [0.7,0.15]\n",
    "# Train Test Split\n",
    "ext_train,ext_test,ext_valid = ext_reviews.split_frame(ratios=RATIOS)\n",
    "# Log our ratios\n",
    "mlflow.lp('ratios',RATIOS)\n",
    "# Log what word vectors we're using\n",
    "mlflow.lp('word vectors', 'reviews')\n",
    "\n",
    "non_token_predictors = ['ProductId', 'UserId', 'HelpfulnessNumerator', 'HelpfulnessDenominator', 'Time']\n",
    "predictors = non_token_predictors + review_vecs.names\n",
    "response = 'PositiveReview'\n",
    "\n",
    "mlflow.lp('label', response)\n",
    "# There are a lot of predictors here (C1-C50 + features) so let's shorten that\n",
    "mlflow.lp('predictors', non_token_predictors + [f'C1-C{len(review_vecs.columns)}'])\n",
    "\n",
    "gbm_embeddings = H2OGradientBoostingEstimator(stopping_metric = \"AUC\", stopping_tolerance = 0.001,\n",
    "                                              stopping_rounds = 5, score_tree_interval = 10,\n",
    "                                              model_id = \"gbm_embeddings.hex\"\n",
    "                                             )\n",
    "with mlflow.timer('train_time'):\n",
    "    gbm_embeddings.train(x = predictors, y = response, \n",
    "                       training_frame = ext_train, validation_frame = ext_test\n",
    "                      )\n",
    "\n",
    "# Log the model params to mlflow\n",
    "mlflow.log_params(gbm_embeddings.get_params())\n",
    "# Log the model to MLFlow\n",
    "mlflow.log_model(gbm_embeddings, 'vectorized_model')\n",
    "# Log the training notebook to MLFlow\n",
    "mlflow.log_artifact('MLManager NLP H2O Demo.ipynb', 'training_notebook')\n",
    "gbm_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Just like before, let's log all of our outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline  \n",
    "from IPython.display import HTML, IFrame\n",
    "\n",
    "# Print and Log Model params\n",
    "params = dict(zip(gbm_embeddings.summary().col_header[1:],\n",
    "                    gbm_embeddings.summary().cell_values[0][1:]))\n",
    "print(gbm_embeddings.summary())\n",
    "mlflow.log_params(params)\n",
    "\n",
    "\n",
    "#Plot and Log Scoring history\n",
    "gbm_embeddings.plot()\n",
    "print(\"AUC on Validation Data: \" + str(round(gbm_embeddings.auc(valid = True), 3)))\n",
    "# Log training and validation metrics over time\n",
    "for step, row in gbm_embeddings.scoring_history().iterrows():\n",
    "    row_dict = row.to_dict()\n",
    "    for r in row_dict:\n",
    "        if 'train' in r or 'valid' in r:\n",
    "            mlflow.log_metric(r, row_dict[r],step=step)\n",
    "\n",
    "\n",
    "# Print and Log Confusion Matrix\n",
    "print(gbm_embeddings.confusion_matrix(valid = True))\n",
    "mlflow.lm('fpr', gbm_embeddings.fpr(valid=True)[0][0])\n",
    "mlflow.lm('tpr', gbm_embeddings.tpr(valid=True)[0][0])\n",
    "mlflow.lm('fnr', gbm_embeddings.fnr(valid=True)[0][0])\n",
    "mlflow.lm('tnr', gbm_embeddings.fnr(valid=True)[0][0])\n",
    "mlflow.lm('F0point5', gbm_embeddings.F0point5(valid=True)[0][1])\n",
    "mlflow.lm('F1', gbm_embeddings.F1(valid=True)[0][1])\n",
    "mlflow.lm('F2', gbm_embeddings.F2(valid=True)[0][1])\n",
    "mlflow.lm('auc', gbm_embeddings.auc(valid = True))\n",
    "mlflow.lp('threshold', gbm_embeddings.F1(valid=True)[0][0]) # First element is the threshold\n",
    "\n",
    "\n",
    "# Plot and Log Variable Importance\n",
    "gbm_embeddings.varimp_plot()\n",
    "for var in gbm_embeddings.varimp():\n",
    "    mlflow.lm(f'varimp_{var[0]}',var[-1])\n",
    "    \n",
    "    \n",
    "# Partial Dependence Plot\n",
    "pdp_helpfulness = gbm_embeddings.partial_plot(ext_train, cols = [\"HelpfulnessNumerator\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_run = cur_run\n",
    "cur_run = mlflow.current_run_id()\n",
    "cur_exp = mlflow.current_exp_id()\n",
    "link = f'/mlflow/#/metric/training_auc?runs=[\"{cur_run}\",\"{old_run}\"]&experiment={cur_exp}&plot_metric_keys=[\\\"validation_logloss\\\"]'\n",
    "display(HTML(f'<font size=\"+1\">Compare your 2 runs <a target=\"_blank\" href={link}>here</a></font>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_embeddings.scoring_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Baseline AUC: \" + str(round(gbm_baseline.auc(valid = True), 3)))\n",
    "print(\"With Embeddings AUC: \" + str(round(gbm_embeddings.auc(valid = True), 3)))\n",
    "link = f'/mlflow/#/metric/training_auc?runs=[\"{cur_run}\",\"{old_run}\"]&experiment={cur_exp}&plot_metric_keys=[\\\"training_auc\\\",\\\"validation_auc\\\"]'\n",
    "display(HTML(f'<font size=\"+1\">See a metrics comparison <a target=\"_blank\" href={link}>here</a></font>'))\n",
    "IFrame(link.replace('\\\"','%22'),width='100%',height='800px')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# That's some great imrpovement! So what's next?\n",
    "<blockquote>We included the customer reviews and developed a better model. We've logged everything to MLFlow for detailed comparisons. Now what?<br>\n",
    "    Let's deploy our models to production so we can utilize what we've built. First, we'll deploy our word vectorizer model, and then deploy our GBM model. Finally, we'll create a feed from the first model to the second, so we can see the final predictions!\n",
    "        </i></br><footer>Splice Machine</footer></blockquote><br>\n",
    "<img src=https://splice-demo.s3.amazonaws.com/H2O+Model+Deployment+Flow.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Deploy Word2Vec Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "help(mlflow.deploy_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get the run_id from the name. Note that multiple runs can have the same name, so this returns a list\n",
    "run_id = mlflow.get_run_ids_by_name('review_tokenizer')[0]\n",
    "\n",
    "# We specify model_cols so the trigger knows which columns go into the model\n",
    "jid = mlflow.deploy_db(schema, 'AMAZON_REVIEWS', run_id, classes=[f'C{i+1}' for i in range(VECTOR_LENGTH)], model_cols=['REVIEW'])\n",
    "mlflow.watch_job(jid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sweet! Now when we insert new data into our <code>AMAZON_REVIEWS</code> table, we will automatically have the review vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "delete from amazon_reviews where ID=9993329;\n",
    "\n",
    "insert into amazon_reviews (productid, userid, summary, score, helpfulnessdenominator, id, profilename, helpfulnessnumerator, review_time, review) \n",
    "    values ('B00141QYSQ', 'A1YS02UZZGRDCT', 'Do Not Buy', 2, 7, 9993329, 'Evan Eberhardt', 0, 1314489600, 'Nothing like what i expected');\n",
    "\n",
    "select * from amazon_reviews where id=9993329;\n",
    "delete from amazon_reviews where ID=9993329;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazing! Up Next: GBM\n",
    "<blockquote>\n",
    "    Now we need to deploy our GBM model in a slightly different way. We will create a <b>new</b> table with the GBM model. This model will take input as the original features plus the vectorization of the review. \n",
    "    <br>To create a new table, you use the same <code>deploy_db</code> function but with a few extra paramaters:\n",
    "    <ul>\n",
    "        <li><code>df</code>: The dataframe used to create the table with</li>\n",
    "        <li><code>create_model_table</code>: a boolean to indicate that you'd like to create a new table</li>\n",
    "        <li><code>primary_key</code>: A list[tuple[str,str]] the primary key(s) you'd like to use for the table. Tables deployed with a model <b>require</b> a primary key</li>\n",
    "    </ul>\n",
    "        </i></br><footer>Splice Machine</footer></blockquote><br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the run_id from the name. Note that multiple runs can have the same name, so this returns a list\n",
    "run_id = mlflow.get_run_ids_by_name('GBM with word vectors')[0]\n",
    "\n",
    "deploy_df = hc.asSparkFrame(ext_reviews[predictors])\n",
    "\n",
    "splice._dropTableIfExists(f'{schema}.gbm_w2v_model')\n",
    "\n",
    "jid = mlflow.deploy_db(schema, 'gbm_w2v_model', run_id, df=deploy_df, create_model_table=True, primary_key={'REVIEW_ID': 'INT'}, classes=['negative', 'positive'])\n",
    "mlflow.watch_job(jid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Almost Done!\n",
    "<blockquote>\n",
    "    Now we have 2 models deployed in the database:\n",
    "    <ul>\n",
    "        <li> A model that takes a sentence and converts it into a vector</li>\n",
    "        <li> A model that takes the vector + a few other features and makes a prediction about the review </li>\n",
    "    </ul>\n",
    "    Now, all we need to do is connect them with a simple pipeline. We'll connect the 2 tables together like the image above to create a full cycle ML Pipeline\n",
    "</i></br><footer>Splice Machine</footer></blockquote><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "CREATE TRIGGER WORD2VEC_PIPELINE\n",
    "AFTER UPDATE\n",
    "ON AMAZON_REVIEWS\n",
    "REFERENCING NEW AS N\n",
    "FOR EACH ROW\n",
    "INSERT INTO GBM_W2V_MODEL (PRODUCTID,USERID,HELPFULNESSNUMERATOR,HELPFULNESSDENOMINATOR,TIME,C1,C2,C3,C4,C5,C6,C7,C8,C9,C10,C11,C12,C13,C14,C15,C16,C17,C18,C19,C20,C21,C22,C23,C24,C25,C26,C27,C28,C29,C30,C31,C32,C33,C34,C35,C36,C37,C38,C39,C40,C41,C42,C43,C44,C45,C46,C47,C48,C49,C50,REVIEW_ID)\n",
    "    values(N.PRODUCTID,N.USERID,N.HELPFULNESSNUMERATOR,N.HELPFULNESSDENOMINATOR,N.REVIEW_TIME,N.C1,N.C2,N.C3,N.C4,N.C5,N.C6,N.C7,N.C8,N.C9,N.C10,N.C11,N.C12,N.C13,N.C14,N.C15,N.C16,N.C17,N.C18,N.C19,N.C20,N.C21,N.C22,N.C23,N.C24,N.C25,N.C26,N.C27,N.C28,N.C29,N.C30,N.C31,N.C32,N.C33,N.C34,N.C35,N.C36,N.C37,N.C38,N.C39,N.C40,N.C41,N.C42,N.C43,N.C44,N.C45,N.C46,N.C47,N.C48,N.C49,N.C50,N.ID)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "delete from amazon_reviews where ID in (9993329,999350);\n",
    "delete from GBM_W2V_MODEL where REVIEW_ID in (9993329,999350);\n",
    "\n",
    "insert into amazon_reviews (productid, userid, summary, score, helpfulnessdenominator, id, profilename, helpfulnessnumerator, review_time, review) \n",
    "    values ('B00141QYSQ', 'A1YS02UZZGRDCT', 'Do Not Buy', 2, 7, 9993329, 'Evan Eberhardt', 0, 1314489600, 'Nothing like what i expected');\n",
    "\n",
    "insert into amazon_reviews (productid, userid, summary, score, helpfulnessdenominator, id, profilename, helpfulnessnumerator, review_time, review) \n",
    "    values ('B0009XLVGA', 'A1NHQNQ3TVXTZF', 'An awesome choice', 5, 2, 999350, 'Evan Eberhardt', 0, 1314433500, 'You have to buy this! Its great!');\n",
    "\n",
    "\n",
    "select REVIEW_ID, CUR_USER, EVAL_TIME, PREDICTION, \"negative\", \"positive\" from GBM_W2V_MODEL WHERE REVIEW_ID=9993329 or REVIEW_ID=999350"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's see which models are deployed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.get_deployed_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Incredible!\n",
    "## Let's recap\n",
    "<blockquote>\n",
    "    We:\n",
    "    <ul>\n",
    "        <li> Imported data from external sources in both SQL and Python</li>\n",
    "        <li> Created a simple model with decent accuracy using H2O </li>\n",
    "        <li> Imroved that model drastically using a word2vec pipeline with SKLearn </li>\n",
    "        <li> Tracked, compared, and persisted all of our model and run information in mlflow </li>\n",
    "        <li> Deployed the better model, along with the standalone word2vec pipeline to table directly in the database </li>\n",
    "        <li> Chained those tables together with simple triggers </li>\n",
    "        <li> Made predictions on new Amazon reviews </li>\n",
    "        <li> Viewed which models we have in production </li>\n",
    "    </ul>\n",
    "    \n",
    " That's quite the accomplishment. Congratulations!\n",
    "</i></br><footer>Splice Machine</footer></blockquote><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "212px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
