{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Life of a Query\n",
    "\n",
    "This notebook walks you through using Splice Machine to create, populate, and query a sample database. We'll use the TPC-H benchmarking data as our sample dataset.\n",
    "\n",
    "TPC-H is a decision support benchmark. It consists of a suite of business-oriented ad hoc queries and concurrent data modifications. The queries and the data populating the database have been chosen to have broad industry-wide relevance. This benchmark illustrates decision support systems that examine large volumes of data, execute queries with a high degree of complexity, and give answers to critical business questions.\n",
    "\n",
    "We demonstrate running and optimizing queries in Splice Machine, in these sections:\n",
    "\n",
    "<ul class=\"italic\">\n",
    "    <li>Creating our Database in Splice Machine</li>\n",
    "    <li>Analytic Workloads</li>\n",
    "        <li>Examining a Query Execution Plan</li>\n",
    "        <li>Informing the Optimizer</li>\n",
    "        <li>Adding Indexes to the Database</li>\n",
    "        <li>Running Queries</li>\n",
    "    <li>Transactional Workloads</li>\n",
    "    <li>A Glimpse at Splice Machine Benchmark Results</li>\n",
    "</ul>\n",
    "\n",
    "<p class=\"noteIcon\">The code paragraphs in this notebook use the <em>%%sql</em> magic, which is pre-configured to interact with Splice Machine using ANSI SQL.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating our Database in Splice Machine\n",
    "\n",
    "First we'll create our database in Splice Machine, in the following steps:\n",
    "\n",
    "<ol class=\"italic\">\n",
    "    <li>Create the Tables</li>\n",
    "    <li>Import the Data</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview of the TPC-H Schema\n",
    "\n",
    "Here's a view of the TPC-H schema:\n",
    "\n",
    "<img class=\"fit3qtrwidth\" src=\"https://s3.amazonaws.com/splice-examples/images/tutorials/sample-data-tpch-schema.png\">\n",
    "\n",
    "#### Create the Tables\n",
    "\n",
    "We'll now create the TPCH tables in our schema. In case we're working on a database in which we may have already imported TPCH data, we'll first conditionally drop the tables we want to create:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql \n",
    "DROP TABLE IF EXISTS LINEITEM;\n",
    "DROP TABLE IF EXISTS ORDERS;\n",
    "DROP TABLE IF EXISTS CUSTOMER;\n",
    "DROP TABLE IF EXISTS PARTSUPP;\n",
    "DROP TABLE IF EXISTS SUPPLIER;\n",
    "DROP TABLE IF EXISTS PART;\n",
    "DROP TABLE IF EXISTS REGION;\n",
    "DROP TABLE IF EXISTS NATION;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql \n",
    "CREATE TABLE LINEITEM (\n",
    " L_ORDERKEY BIGINT NOT NULL,\n",
    " L_PARTKEY INTEGER NOT NULL,\n",
    " L_SUPPKEY INTEGER NOT NULL, \n",
    " L_LINENUMBER INTEGER NOT NULL, \n",
    " L_QUANTITY DECIMAL(15,2),\n",
    " L_EXTENDEDPRICE DECIMAL(15,2),\n",
    " L_DISCOUNT DECIMAL(15,2),\n",
    " L_TAX DECIMAL(15,2),\n",
    " L_RETURNFLAG VARCHAR(1), \n",
    " L_LINESTATUS VARCHAR(1),\n",
    " L_SHIPDATE DATE,\n",
    " L_COMMITDATE DATE,\n",
    " L_RECEIPTDATE DATE,\n",
    " L_SHIPINSTRUCT VARCHAR(25),\n",
    " L_SHIPMODE VARCHAR(10),\n",
    " L_COMMENT VARCHAR(44),\n",
    " PRIMARY KEY(L_ORDERKEY,L_LINENUMBER)\n",
    " );\n",
    " \n",
    " CREATE TABLE ORDERS (\n",
    " O_ORDERKEY BIGINT NOT NULL PRIMARY KEY,\n",
    " O_CUSTKEY INTEGER,\n",
    " O_ORDERSTATUS VARCHAR(1),\n",
    " O_TOTALPRICE DECIMAL(15,2),\n",
    " O_ORDERDATE DATE,\n",
    " O_ORDERPRIORITY VARCHAR(15),\n",
    " O_CLERK VARCHAR(15),\n",
    " O_SHIPPRIORITY INTEGER ,\n",
    " O_COMMENT VARCHAR(79)\n",
    " );\n",
    " \n",
    " CREATE TABLE CUSTOMER (\n",
    " C_CUSTKEY INTEGER NOT NULL PRIMARY KEY,\n",
    " C_NAME VARCHAR(25),\n",
    " C_ADDRESS VARCHAR(40),\n",
    " C_NATIONKEY INTEGER NOT NULL,\n",
    " C_PHONE VARCHAR(15),\n",
    " C_ACCTBAL DECIMAL(15,2),\n",
    " C_MKTSEGMENT VARCHAR(10),\n",
    " C_COMMENT VARCHAR(117)\n",
    " );\n",
    " \n",
    " CREATE TABLE PARTSUPP (\n",
    " PS_PARTKEY INTEGER NOT NULL ,\n",
    " PS_SUPPKEY INTEGER NOT NULL , \n",
    " PS_AVAILQTY INTEGER,\n",
    " PS_SUPPLYCOST DECIMAL(15,2),\n",
    " PS_COMMENT VARCHAR(199),\n",
    " PRIMARY KEY(PS_PARTKEY,PS_SUPPKEY) \n",
    " );\n",
    " \n",
    " CREATE TABLE SUPPLIER (\n",
    " S_SUPPKEY INTEGER NOT NULL PRIMARY KEY,\n",
    " S_NAME VARCHAR(25) ,\n",
    " S_ADDRESS VARCHAR(40) ,\n",
    " S_NATIONKEY INTEGER ,\n",
    " S_PHONE VARCHAR(15) ,\n",
    " S_ACCTBAL DECIMAL(15,2),\n",
    " S_COMMENT VARCHAR(101)\n",
    " );\n",
    " \n",
    " CREATE TABLE PART (\n",
    " P_PARTKEY INTEGER NOT NULL PRIMARY KEY,\n",
    " P_NAME VARCHAR(55) ,\n",
    " P_MFGR VARCHAR(25) ,\n",
    " P_BRAND VARCHAR(10) ,\n",
    " P_TYPE VARCHAR(25) ,\n",
    " P_SIZE INTEGER ,\n",
    " P_CONTAINER VARCHAR(10) ,\n",
    " P_RETAILPRICE DECIMAL(15,2),\n",
    " P_COMMENT VARCHAR(23)\n",
    " );\n",
    " \n",
    " CREATE TABLE REGION (\n",
    " R_REGIONKEY INTEGER NOT NULL PRIMARY KEY,\n",
    " R_NAME VARCHAR(25),\n",
    " R_COMMENT VARCHAR(152)\n",
    " );\n",
    " \n",
    " CREATE TABLE NATION (\n",
    " N_NATIONKEY INTEGER NOT NULL,\n",
    " N_NAME VARCHAR(25),\n",
    " N_REGIONKEY INTEGER NOT NULL,\n",
    " N_COMMENT VARCHAR(152),\n",
    " PRIMARY KEY (N_NATIONKEY)\n",
    " );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the Data\n",
    "\n",
    "We have pre-loaded flat files with the TPCH data into an S3 bucket to facilitate importing the data. All we need to do is run an `IMPORT` statement for each table.\n",
    "\n",
    "<p class=\"noteNote\">Importing this much data can take a few minutes; you'll see the result of each import displayed below the <code>IMPORT</code> statements as they complete.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql \n",
    "call SYSCS_UTIL.IMPORT_DATA (null, 'LINEITEM', null, 's3a://splice-benchmark-data/flat/TPCH/1/lineitem', '|', null, null, null, null, 0, '/tmp', true, null);\n",
    "\n",
    "call SYSCS_UTIL.IMPORT_DATA (null, 'ORDERS',   null, 's3a://splice-benchmark-data/flat/TPCH/1/orders',   '|', null, null, null, null, 0, '/tmp', true, null);\n",
    "\n",
    "call SYSCS_UTIL.IMPORT_DATA (null, 'CUSTOMER', null, 's3a://splice-benchmark-data/flat/TPCH/1/customer', '|', null, null, null, null, 0, '/tmp', true, null);\n",
    "\n",
    "call SYSCS_UTIL.IMPORT_DATA (null, 'PARTSUPP', null, 's3a://splice-benchmark-data/flat/TPCH/1/partsupp', '|', null, null, null, null, 0, '/tmp', true, null);\n",
    "\n",
    "call SYSCS_UTIL.IMPORT_DATA (null, 'SUPPLIER', null, 's3a://splice-benchmark-data/flat/TPCH/1/supplier', '|', null, null, null, null, 0, '/tmp', true, null);\n",
    "\n",
    "call SYSCS_UTIL.IMPORT_DATA (null, 'PART',     null, 's3a://splice-benchmark-data/flat/TPCH/1/part',     '|', null, null, null, null, 0, '/tmp', true, null);\n",
    "\n",
    "call SYSCS_UTIL.IMPORT_DATA (null, 'REGION',   null, 's3a://splice-benchmark-data/flat/TPCH/1/region',   '|', null, null, null, null, 0, '/tmp', true, null);\n",
    "\n",
    "call SYSCS_UTIL.IMPORT_DATA (null, 'NATION',   null, 's3a://splice-benchmark-data/flat/TPCH/1/nation',   '|', null, null, null, null, 0, '/tmp', true, null);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analytic Workload\n",
    "\n",
    "Analytic workloads usually involve large scans of data, joins, aggregations and complex filtering conditions.\n",
    "Splice Machine processes such requests using the its OLAP engine which is powered by Spark.\n",
    "As you experiment with SQL on Splice Machine, you'll see that the first line of any EXPLAIN plan specifies which engine is used to resolve the request.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examining a Query Execution Plan\n",
    "\n",
    "In the next few sections of this notebook, we'll examine execution plans for TPC-H Query 4, which is known as the <em>Order Priority Checking Query</em>. This query counts the number of orders ordered in a given quarter of a given year in which at least one lineitem was received by the customer later than its committed date; you can use it to determine how well the order priority system is working and gives an assessment of customer satisfaction.\n",
    "\n",
    "Splice Machine generates an execution plan prior to running your query. You can use the `explain` command to generate and display the execution plan without actually running the query; this can help you to determine optimizing strategies for your queries. \n",
    "<p class=\"noteIcon\">The <a href=\"https://doc.splicemachine.com/developers_tuning_explainplan_examples.html\" target=\"_blank\">Reading Explain Plans</a> topic in our documentation describes how to read explain plans.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql \n",
    "-- QUERY 04\n",
    "explain  select\n",
    "\to_orderpriority,\n",
    "\tcount(*) as order_count\n",
    "from\n",
    "\torders\n",
    "where\n",
    "\to_orderdate >= date('1993-07-01')\n",
    "\tand o_orderdate < add_months('1993-07-01',3)\n",
    "\tand exists (\n",
    "\t\tselect\n",
    "\t\t\t*\n",
    "\t\tfrom\n",
    "\t\t\tlineitem\n",
    "\t\twhere\n",
    "\t\t\tl_orderkey = o_orderkey\n",
    "\t\t\tand l_commitdate < l_receiptdate\n",
    "\t)\n",
    "group by\n",
    "\to_orderpriority\n",
    "order by\n",
    "\to_orderpriority\n",
    "-- END OF QUERY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing Query Performance\n",
    "\n",
    "In this section we'll look at optimizing the execution plan for TPCH Query 4; we'll:\n",
    "\n",
    "* Collect Statistics to Inform the Optimizer\n",
    "* Add Indexes to Further Optimize the Plan\n",
    "* Compare Execution Plans\n",
    "\n",
    "The *Splice Machine Optimizer* is a cost-based optimizer that generates optimal execution plans for database queries. You use our `analyze` command to collect statistics from your database, which the optimizer uses when planning the execution of a query.\n",
    "\n",
    "<p class=\"noteIcon\">Cost-based optimizers are powerful features of modern databases that enable query plans to change as the data profiles change. Optimizers make use of count distinct, quantiles, and most frequent item counts as heuristics.</p>\n",
    "\n",
    "When creating a plan for a query, our optimizer performs a number of important and valuable actions, including:\n",
    "\n",
    "* It creates an access plan, which determine the best path for accessing the data the query will operate upon; for example, the access path might be to scan an entire table or to use an index.\n",
    "* When joining tables, the optimizer evaluates the best *join order* and the *join strategy* to use.\n",
    "* The optimizer unrolls subqueries to reduce processing time\n",
    "\n",
    "These metrics are usually extremely expensive but if approximate results are acceptable, there is a class of specialized algorithms, called streaming algorithms, or *sketches*, that can produce results orders-of magnitude faster and with mathematically proven error bounds. Splice Machine leverages the [Yahoo Sketches Library](https://datasketches.apache.org/docs/Background/TheChallenge.html) for its statistics gathering. \n",
    "\n",
    "### Collect Statistics\n",
    "Our first optimization is to collect statistics to inform the optimizer about our database. We use our `analyze` command to collect statistics on a schema (or table). This process requires a couple minutes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql \n",
    "analyze table LINEITEM;\n",
    "analyze table ORDERS;\n",
    "analyze table CUSTOMER;\n",
    "analyze table PARTSUPP;\n",
    "analyze table SUPPLIER;\n",
    "analyze table PART;\n",
    "analyze table REGION;\n",
    "analyze table NATION;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rerun the Explain Plan After Collecting Statistics\n",
    "\n",
    "Now let's re-run the `explain` plan for Query 4 and see how the optimizer changed the plan after gathering statistics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql \n",
    "-- QUERY 04\n",
    "explain select\n",
    "\to_orderpriority,\n",
    "\tcount(*) as order_count\n",
    "from\n",
    "\torders\n",
    "where\n",
    "\to_orderdate >= date('1993-07-01')\n",
    "\tand o_orderdate < add_months('1993-07-01',3)\n",
    "\tand exists (\n",
    "\t\tselect\n",
    "\t\t\t*\n",
    "\t\tfrom\n",
    "\t\t\tlineitem\n",
    "\t\twhere\n",
    "\t\t\tl_orderkey = o_orderkey\n",
    "\t\t\tand l_commitdate < l_receiptdate\n",
    "\t)\n",
    "group by\n",
    "\to_orderpriority\n",
    "order by\n",
    "\to_orderpriority\n",
    "-- END OF QUERY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Execution Plans After Analyzing the Database\n",
    "\n",
    "Now let's compare the plans to see what changed. At a quick glance, you'll notice that a very large difference in the `totalCost` numbers for every operation in the plan:\n",
    "\n",
    "#### After Collecting Statistics\n",
    "```\n",
    "Plan\n",
    "Cursor(n=10,rows=5,updateMode=,engine=OLAP (cost))\n",
    "  ->  ScrollInsensitive(n=10,totalCost=176167.046,outputRows=5,outputHeapSize=249 B,partitions=1)\n",
    "    ->  OrderBy(n=11,totalCost=176166.944,outputRows=5,outputHeapSize=249 B,partitions=1)\n",
    "      ->  ProjectRestrict(n=8,totalCost=88083.421,outputRows=5,outputHeapSize=249 B,partitions=1)\n",
    "        ->  GroupBy(n=7,totalCost=88083.421,outputRows=5,outputHeapSize=249 B,partitions=1)\n",
    "          ->  ProjectRestrict(n=6,totalCost=20740.612,outputRows=1980401,outputHeapSize=94.118 MB,partitions=1)\n",
    "            ->  MergeJoin(n=4,totalCost=20740.612,outputRows=1980401,outputHeapSize=94.118 MB,partitions=1,preds=[(L_ORDERKEY[4:4] = O_ORDERKEY[4:1])])\n",
    "              ->  ProjectRestrict(n=3,totalCost=11385.304,outputRows=1980401,outputHeapSize=94.118 MB,partitions=1,preds=[(L_COMMITDATE[2:2] < L_RECEIPTDATE[2:3])])\n",
    "                ->  TableScan[LINEITEM(10448)](n=2,totalCost=11286.284,scannedRows=6001215,outputRows=6001215,outputHeapSize=94.118 MB,partitions=1)\n",
    "              ->  ProjectRestrict(n=1,totalCost=3004,outputRows=435343,outputHeapSize=13.839 MB,partitions=1)\n",
    "                ->  TableScan[ORDERS(10464)](n=0,totalCost=3004,scannedRows=1500000,outputRows=435343,outputHeapSize=13.839 MB,partitions=1,preds=[(O_ORDERDATE[0:2] < dataTypeServices: DATE ),(O_ORDERDATE[0:2] >= 1993-07-01)])\n",
    "```\n",
    "\n",
    "#### Before Collecting Statistics\n",
    "```\n",
    "Plan\n",
    "Cursor(n=10,rows=1388618,updateMode=,engine=OLAP (cost))\n",
    "  ->  ScrollInsensitive(n=10,totalCost=309826.015,outputRows=1388618,outputHeapSize=7.946 MB,partitions=1)\n",
    "    ->  OrderBy(n=11,totalCost=281954.786,outputRows=1388618,outputHeapSize=7.946 MB,partitions=1)\n",
    "      ->  ProjectRestrict(n=8,totalCost=127041.779,outputRows=1388618,outputHeapSize=7.946 MB,partitions=1)\n",
    "        ->  GroupBy(n=7,totalCost=127041.779,outputRows=1388618,outputHeapSize=7.946 MB,partitions=1)\n",
    "          ->  ProjectRestrict(n=6,totalCost=15197.56,outputRows=1388618,outputHeapSize=7.946 MB,partitions=1)\n",
    "            ->  MergeJoin(n=4,totalCost=15197.56,outputRows=1388618,outputHeapSize=7.946 MB,partitions=1,preds=[(L_ORDERKEY[4:4] = O_ORDERKEY[4:1])])\n",
    "              ->  ProjectRestrict(n=3,totalCost=8432.488,outputRows=1388618,outputHeapSize=7.946 MB,partitions=1,preds=[(L_COMMITDATE[2:2] < L_RECEIPTDATE[2:3])])\n",
    "                ->  TableScan[LINEITEM(10448)](n=2,totalCost=8419.864,scannedRows=4207932,outputRows=4207932,outputHeapSize=7.946 MB,partitions=1)\n",
    "              ->  ProjectRestrict(n=1,totalCost=2627.27,outputRows=410628,outputHeapSize=1.175 MB,partitions=1)\n",
    "                ->  TableScan[ORDERS(10464)](n=0,totalCost=2627.27,scannedRows=1311635,outputRows=410628,outputHeapSize=1.175 MB,partitions=1,preds=[(O_ORDERDATE[0:2] < dataTypeServices: DATE ),(O_ORDERDATE[0:2] >= 1993-07-01)])\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize by Adding Indexes\n",
    "\n",
    "Splice Machine tables have primary keys either implicit or explicitly defined. Data is stored in order of these keys.\n",
    "\n",
    "<div class=\"noteNote\">The primary key is not optimal for all queries.</div>\n",
    "\n",
    "Unlike HBase and other key-value stores, Splice Machine can use *secondary indexes* to improve the performance of data manipulation statements. In addition, `UNIQUE` indexes provide a form of data integrity checking.\n",
    "\n",
    "When tables are dropped, index will be dropped as well, hence we don't have to drop the indexes before create.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql \n",
    "create index O_CUST_IDX on ORDERS(\n",
    " O_CUSTKEY,\n",
    " O_ORDERKEY\n",
    " );\n",
    " \n",
    " create index O_DATE_PRI_KEY_IDX on ORDERS(\n",
    " O_ORDERDATE,\n",
    " O_ORDERPRIORITY,\n",
    " O_ORDERKEY\n",
    " );\n",
    " \n",
    " create index L_SHIPDATE_IDX on LINEITEM(\n",
    " L_SHIPDATE,\n",
    " L_PARTKEY,\n",
    " L_EXTENDEDPRICE,\n",
    " L_DISCOUNT\n",
    " );\n",
    " \n",
    " create index L_PART_IDX on LINEITEM(\n",
    " L_PARTKEY,\n",
    " L_ORDERKEY,\n",
    " L_SUPPKEY,\n",
    " L_SHIPDATE,\n",
    " L_EXTENDEDPRICE,\n",
    " L_DISCOUNT,\n",
    " L_QUANTITY,\n",
    " L_SHIPMODE,\n",
    " L_SHIPINSTRUCT\n",
    " );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-analyze and Re-run the Explain Plan After Indexing\n",
    "\n",
    "Now that we've added indexes to our database, let's re-analyze the database and then re-run the `explain` plan for Query 4 one more time to see how indexing has affected our execution plan.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql \n",
    "analyze table LINEITEM;\n",
    "analyze table ORDERS;\n",
    "analyze table CUSTOMER;\n",
    "analyze table PARTSUPP;\n",
    "analyze table SUPPLIER;\n",
    "analyze table PART;\n",
    "analyze table REGION;\n",
    "analyze table NATION;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql \n",
    "-- QUERY 04\n",
    "explain select\n",
    "\to_orderpriority,\n",
    "\tcount(*) as order_count\n",
    "from\n",
    "\torders\n",
    "where\n",
    "\to_orderdate >= date('1993-07-01')\n",
    "\tand o_orderdate < add_months('1993-07-01',3)\n",
    "\tand exists (\n",
    "\t\tselect\n",
    "\t\t\t*\n",
    "\t\tfrom\n",
    "\t\t\tlineitem\n",
    "\t\twhere\n",
    "\t\t\tl_orderkey = o_orderkey\n",
    "\t\t\tand l_commitdate < l_receiptdate\n",
    "\t)\n",
    "group by\n",
    "\to_orderpriority\n",
    "order by\n",
    "\to_orderpriority\n",
    "-- END OF QUERY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Execution Plans\n",
    "\n",
    "We can now compare how the query will execute with indexing in place versus without indexes. You'll again notice that, among other differences, the `totalCost` values are lower for most operations because the optimizer was able to take advantage of the indexes we added.\n",
    "\n",
    "#### Query Plan After Indexing\n",
    "```\n",
    "Plan\n",
    "Cursor(n=10,rows=5,updateMode=,engine=OLAP (cost))\n",
    "  ->  ScrollInsensitive(n=10,totalCost=390724.547,outputRows=5,outputHeapSize=249 B,partitions=1)\n",
    "    ->  OrderBy(n=11,totalCost=390724.445,outputRows=5,outputHeapSize=249 B,partitions=1)\n",
    "      ->  ProjectRestrict(n=8,totalCost=195362.171,outputRows=5,outputHeapSize=249 B,partitions=1)\n",
    "        ->  GroupBy(n=7,totalCost=195362.171,outputRows=5,outputHeapSize=249 B,partitions=1)\n",
    "          ->  ProjectRestrict(n=6,totalCost=76721.518,outputRows=1980401,outputHeapSize=94.118 MB,partitions=1)\n",
    "            ->  MergeSortJoin(n=4,totalCost=76721.518,outputRows=1980401,outputHeapSize=94.118 MB,partitions=1,preds=[(L_ORDERKEY[4:4] = O_ORDERKEY[4:1])])\n",
    "              ->  ProjectRestrict(n=3,totalCost=11385.304,outputRows=1980401,outputHeapSize=94.118 MB,partitions=1,preds=[(L_COMMITDATE[2:2] < L_RECEIPTDATE[2:3])])\n",
    "                ->  TableScan[LINEITEM(10448)](n=2,totalCost=11286.284,scannedRows=6001215,outputRows=6001215,outputHeapSize=94.118 MB,partitions=1)\n",
    "              ->  ProjectRestrict(n=1,totalCost=662.35,outputRows=436198,outputHeapSize=13.866 MB,partitions=1)\n",
    "                ->  IndexScan[O_DATE_PRI_KEY_IDX(10593)](n=0,totalCost=662.35,scannedRows=495000,outputRows=436198,outputHeapSize=13.866 MB,partitions=1,baseTable=ORDERS(10464),preds=[(O_ORDERDATE[0:1] < dataTypeServices: DATE ),(O_ORDERDATE[0:1] >= 1993-07-01)])\n",
    "```\n",
    "\n",
    "#### Query Plan Before Indexing\n",
    "```\n",
    "Plan\n",
    "Cursor(n=10,rows=5,updateMode=,engine=OLAP (cost))\n",
    "  ->  ScrollInsensitive(n=10,totalCost=176167.046,outputRows=5,outputHeapSize=249 B,partitions=1)\n",
    "    ->  OrderBy(n=11,totalCost=176166.944,outputRows=5,outputHeapSize=249 B,partitions=1)\n",
    "      ->  ProjectRestrict(n=8,totalCost=88083.421,outputRows=5,outputHeapSize=249 B,partitions=1)\n",
    "        ->  GroupBy(n=7,totalCost=88083.421,outputRows=5,outputHeapSize=249 B,partitions=1)\n",
    "          ->  ProjectRestrict(n=6,totalCost=20740.612,outputRows=1980401,outputHeapSize=94.118 MB,partitions=1)\n",
    "            ->  MergeJoin(n=4,totalCost=20740.612,outputRows=1980401,outputHeapSize=94.118 MB,partitions=1,preds=[(L_ORDERKEY[4:4] = O_ORDERKEY[4:1])])\n",
    "              ->  ProjectRestrict(n=3,totalCost=11385.304,outputRows=1980401,outputHeapSize=94.118 MB,partitions=1,preds=[(L_COMMITDATE[2:2] < L_RECEIPTDATE[2:3])])\n",
    "                ->  TableScan[LINEITEM(10448)](n=2,totalCost=11286.284,scannedRows=6001215,outputRows=6001215,outputHeapSize=94.118 MB,partitions=1)\n",
    "              ->  ProjectRestrict(n=1,totalCost=3004,outputRows=435343,outputHeapSize=13.839 MB,partitions=1)\n",
    "                ->  TableScan[ORDERS(10464)](n=0,totalCost=3004,scannedRows=1500000,outputRows=435343,outputHeapSize=13.839 MB,partitions=1,preds=[(O_ORDERDATE[0:2] < dataTypeServices: DATE ),(O_ORDERDATE[0:2] >= 1993-07-01)])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running TPC-H Queries\n",
    "\n",
    "Now we'll run TPC-H Query 04 and Query 02, so you can see the database in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "-- QUERY 04\n",
    "select\n",
    "\to_orderpriority,\n",
    "\tcount(*) as order_count\n",
    "from\n",
    "\torders\n",
    "where\n",
    "\to_orderdate >= date('1993-07-01')\n",
    "\tand o_orderdate < add_months('1993-07-01',3)\n",
    "\tand exists (\n",
    "\t\tselect\n",
    "\t\t\t*\n",
    "\t\tfrom\n",
    "\t\t\tlineitem\n",
    "\t\twhere\n",
    "\t\t\tl_orderkey = o_orderkey\n",
    "\t\t\tand l_commitdate < l_receiptdate\n",
    "\t)\n",
    "group by\n",
    "\to_orderpriority\n",
    "order by\n",
    "\to_orderpriority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql \n",
    "-- QUERY 02\n",
    "select\n",
    "\ts_acctbal,\n",
    "\ts_name,\n",
    "\tn_name,\n",
    "\tp_partkey,\n",
    "\tp_mfgr,\n",
    "\ts_address,\n",
    "\ts_phone,\n",
    "\ts_comment\n",
    "from\n",
    "\tpart,\n",
    "\tsupplier,\n",
    "\tpartsupp,\n",
    "\tnation,\n",
    "\tregion\n",
    "where\n",
    "\tp_partkey = ps_partkey\n",
    "\tand s_suppkey = ps_suppkey\n",
    "\tand p_size = 15\n",
    "\tand p_type like '%BRASS'\n",
    "\tand s_nationkey = n_nationkey\n",
    "\tand n_regionkey = r_regionkey\n",
    "\tand r_name = 'EUROPE'\n",
    "\tand ps_supplycost = (\n",
    "\t\tselect\n",
    "\t\t\tmin(ps_supplycost)\n",
    "\t\tfrom\n",
    "\t\t\tpartsupp,\n",
    "\t\t\tsupplier,\n",
    "\t\t\tnation,\n",
    "\t\t\tregion\n",
    "\t\twhere\n",
    "\t\t\tp_partkey = ps_partkey\n",
    "\t\t\tand s_suppkey = ps_suppkey\n",
    "\t\t\tand s_nationkey = n_nationkey\n",
    "\t\t\tand n_regionkey = r_regionkey\n",
    "\t\t\tand r_name = 'EUROPE'\n",
    "\t)\n",
    "order by\n",
    "\ts_acctbal desc,\n",
    "\tn_name,\n",
    "\ts_name,\n",
    "\tp_partkey\n",
    "{limit 100}\n",
    "-- END OF QUERY\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transactional Workload\n",
    "\n",
    "Transactional workloads usually involves high concurrency of requests where each request deals with a small number of rows. There are limited use of joins or aggregations in these type of requests. Application CRUD operations are common transactional requests, fast lookup using primary or secondary index paths are also common. \n",
    "\n",
    "Splice Machine uses its OLTP engine to resolve transactional requests. The Splice Machine OLTP engine is powered by HBase which in well known for its support of high concurrency and high volume of requests with infinite scalability.\n",
    "\n",
    "Splice Machine also uses MVCC (multi-value concurrency control) which enables snapshot isolation and high concurrency while at the same time providing full ACID compliance (atomicity, consistency, integrity, durability).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CRUD Operations - Create Read Update Delete\n",
    "\n",
    "Notice how all of these simple operations use the OLTP engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%sql\n",
    "\n",
    "-- create\n",
    "EXPLAIN \n",
    "INSERT INTO ORDERS ( O_ORDERKEY, O_CUSTKEY, O_ORDERSTATUS, O_TOTALPRICE, O_ORDERDATE, O_ORDERPRIORITY, O_CLERK, O_SHIPPRIORITY, O_COMMENT)\n",
    "   VALUES (-1, 1, 'P', 999.99, CURRENT_DATE, '1-URGENT', 'JOHN', 1, 'SHIP DIRECT');\n",
    "\n",
    "INSERT INTO ORDERS ( O_ORDERKEY, O_CUSTKEY, O_ORDERSTATUS, O_TOTALPRICE, O_ORDERDATE, O_ORDERPRIORITY, O_CLERK, O_SHIPPRIORITY, O_COMMENT)\n",
    "   VALUES (-1, 1, 'P', 999.99, CURRENT_DATE, '1-URGENT', 'JOHN', 1, 'SHIP DIRECT');\n",
    "\n",
    "-- read\n",
    "EXPLAIN\n",
    "SELECT * FROM ORDERS WHERE O_ORDERKEY = -1;\n",
    "\n",
    "SELECT * FROM ORDERS WHERE O_ORDERKEY = -1;\n",
    "\n",
    "    \n",
    "-- update\n",
    "EXPLAIN\n",
    "UPDATE ORDERS SET O_ORDERSTATUS='D' WHERE O_ORDERKEY = -1;\n",
    "\n",
    "UPDATE ORDERS SET O_ORDERSTATUS='D' WHERE O_ORDERKEY = -1;\n",
    "\n",
    "-- delete\n",
    "EXPLAIN\n",
    "DELETE FROM ORDERS WHERE O_ORDERKEY = -1;\n",
    "\n",
    "DELETE FROM ORDERS WHERE O_ORDERKEY = -1;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OLTP - Indexed Path with Join and Aggregation\n",
    "\n",
    "Even more complex operations on large datasets can be made small enough to be processed by the OLTP engine by taking advantage of indexes.\n",
    "\n",
    "\n",
    "In this example we use a highly selective WHERE clause on LINEITEM which is joined to ORDERS to produce a:\n",
    "- <em>Product Revenue History</em> report \n",
    "\n",
    "Splice Machine resolves this request using the OLTP engine and results in subsecond response time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "EXPLAIN\n",
    "SELECT EXTRACT(YEAR FROM O_ORDERDATE) SALES_YEAR, SUM(O_TOTALPRICE) REVENUE\n",
    "FROM LINEITEM, ORDERS\n",
    "WHERE L_ORDERKEY=O_ORDERKEY\n",
    "  AND L_PARTKEY=49981\n",
    "GROUP BY 1\n",
    "ORDER BY 1;\n",
    "\n",
    "SELECT EXTRACT(YEAR FROM O_ORDERDATE) SALES_YEAR, SUM(O_TOTALPRICE) REVENUE\n",
    "FROM LINEITEM, ORDERS\n",
    "WHERE L_ORDERKEY=O_ORDERKEY\n",
    "  AND L_PARTKEY=49981\n",
    "GROUP BY 1\n",
    "ORDER BY 1;\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Glimpse at Splice Machine Benchmark Results\n",
    "\n",
    "Here are some micro-results from Splice Machine running TPC-H benchmarks:\n",
    "\n",
    "- 2ms single record lookups on primary keys at petabyte scale\n",
    "- 20ms single record updates at petabyte scale\n",
    "- 40-way OLTP indexed joins return in <100ms\n",
    "- 150-way OLAP style joins execute in under 2 minutes\n",
    "- 440-way join executes where others can’t parse\n",
    "- Ingestion at 80MB/sec/node\n",
    "- Can run TPC-C and TPC-H simultaneously\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where to Go Next\n",
    "\n",
    "The next notebook in this presentation introduces you to the <a href=\"./2.3%20Monitoring%20Queries.ipynb\">Splice Machine Database Console,</a> which you can use to monitor and control your currently running queries."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "804.5px",
    "left": "0px",
    "top": "110.5px",
    "width": "392.352px"
   },
   "toc_section_display": false,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
