{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Model Creation in Splice Machine\n",
    "#### Starting the Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "from pyspark.sql import SparkSession\n",
    "from splicemachine.spark import PySpliceContext\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "splice = PySpliceContext(spark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing MLflow Support\n",
    "<blockquote><p class='quotation'><span style='font-size:15px'> As explained in <a href='./7.2 Splice MLflow Support.ipynb'>7.2 Splice MLflow Support</a>, using MLflow on Splice Machine is extremely easy. Referencing our <a href='https://pysplice.readthedocs.io/en/dbaas-4100/splicemachine.mlflow_support.html'>documentation</a> for the available functionality.<br><footer>Splice Machine</footer>\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLFlow Setup\n",
    "from splicemachine.mlflow_support import *\n",
    "mlflow.register_splice_context(splice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting an experiment\n",
    "<blockquote><p class='quotation'><span style='font-size:15px'> Here we'll begin an experiment to keep track of our modeling efforts for this prediction task.<footer>Splice Machine</footer>\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: 'model_creation_demo' does not exist. Creating a new experiment\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment('model_creation_demo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting a run\n",
    "<blockquote><p class='quotation'><span style='font-size:15px'> Here we'll begin an experiment to keep track of our modeling efforts in this notebook specifically.<footer>Splice Machine</footer>\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ActiveRun: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#start our first MLFlow run\n",
    "from datetime import datetime\n",
    "\n",
    "tags = {'team': 'Splice Machine', 'purpose': 'fraud DEMO'}\n",
    "mlflow.start_run(tags=tags, run_name=f\"RF_run\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingesting Data\n",
    "<blockquote><p class='quotation'><span style='font-size:15px'> Ingesting the table created in <a href='./7.3 Data Exploration.ipynb'>7.3 Data Exploration</a>, we will begin constructing a very simple Machine Learning Model. <footer>Splice Machine</footer>\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query = \"SELECT * FROM cc_fraud_data\"\n",
    "df = splice.df(sql_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging our first Parameter \n",
    "<blockquote><p class='quotation'><span style='font-size:15px'> We're utilizing MLFlow to keep track of the query we used to ingest the data for this modeling effort. <footer>Splice Machine</footer>\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging our first parameter: the query we used to ingest our data\n",
    "mlflow.log_param(\"ingest_query\", sql_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting Our Features\n",
    "<blockquote>Here we'll select the features only most strongly correlated to our target<footer>Splice Machine</footer>\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          feature  correlation_to_target\n",
      "1                     TIME_OFFSET               0.861746\n",
      "2    ROLLING_AVG_DAILY_TRANS_AMNT               0.834575\n",
      "3                  MACD_TRANS_CNT               0.826945\n",
      "4   ROLLING_AVG_WEEKLY_TRANS_AMNT               0.752052\n",
      "5     ROLLING_AVG_DAILY_TRANS_CNT               0.739858\n",
      "6        EXPECTED_DAILY_TRANS_CNT               0.708627\n",
      "7                AROON_TRANS_AMNT               0.705022\n",
      "8       EXPECTED_DAILY_TRANS_AMNT               0.696459\n",
      "9                   RSI_TRANS_CNT               0.683260\n",
      "10                DAILY_TRANS_CNT               0.663161\n",
      "11     EXPECTED_WEEKLY_TRANS_AMNT               0.626029\n",
      "12   ROLLING_AVG_WEEKLY_TRANS_CNT               0.567841\n",
      "13                AROON_TRANS_CNT               0.545996\n",
      "14      EXPECTED_WEEKLY_TRANS_CNT               0.538239\n",
      "15               WEEKLY_TRANS_CNT               0.513323\n",
      "16              WEEKLY_TRANS_AMNT               0.475171\n",
      "17               DAILY_TRANS_AMNT               0.445158\n",
      "18                   CREDIT_SCORE               0.435387\n",
      "19                CURRENT_BALANCE               0.251664\n",
      "20                  ADX_TRANS_CNT               0.191480\n",
      "21                   CREDIT_LIMIT               0.145593\n",
      "22                 ADX_TRANS_AMNT               0.124552\n",
      "23                   MACD_BALANCE               0.097921\n",
      "24                    RSI_BALANCE               0.088247\n",
      "25                  AROON_BALANCE               0.086883\n",
      "26            ROLLING_AVG_BALANCE               0.072767\n",
      "27                MACD_TRANS_AMNT               0.071346\n",
      "28                    ADX_BALANCE               0.056237\n",
      "29                 RSI_TRANS_AMNT               0.052941\n",
      "30                         AMOUNT               0.042056\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pdf = df.filter(df.CLASS_RESULT == 0).limit(900).toPandas()\\\n",
    "        .append(df.filter(df.CLASS_RESULT == 1).limit(100).toPandas())\n",
    "pdf = pdf.apply(pd.to_numeric)\n",
    "corr = pdf.corr()\n",
    "\n",
    "most_correlated = corr.abs()['CLASS_RESULT'].sort_values(ascending=False).reset_index()\n",
    "most_correlated = most_correlated.iloc[1:].rename({\"index\":\"feature\",\"CLASS_RESULT\":\"correlation_to_target\"}, axis = 1)\n",
    "print(most_correlated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TIME_OFFSET', 'ROLLING_AVG_DAILY_TRANS_AMNT', 'MACD_TRANS_CNT', 'ROLLING_AVG_WEEKLY_TRANS_AMNT', 'ROLLING_AVG_DAILY_TRANS_CNT', 'EXPECTED_DAILY_TRANS_CNT', 'AROON_TRANS_AMNT', 'EXPECTED_DAILY_TRANS_AMNT', 'RSI_TRANS_CNT', 'DAILY_TRANS_CNT', 'EXPECTED_WEEKLY_TRANS_AMNT', 'ROLLING_AVG_WEEKLY_TRANS_CNT', 'AROON_TRANS_CNT', 'EXPECTED_WEEKLY_TRANS_CNT', 'WEEKLY_TRANS_CNT', 'WEEKLY_TRANS_AMNT', 'DAILY_TRANS_AMNT', 'CREDIT_SCORE', 'CURRENT_BALANCE', 'ADX_TRANS_CNT', 'CREDIT_LIMIT', 'ADX_TRANS_AMNT', 'MACD_BALANCE', 'RSI_BALANCE', 'AROON_BALANCE', 'ROLLING_AVG_BALANCE', 'MACD_TRANS_AMNT', 'ADX_BALANCE', 'RSI_TRANS_AMNT']\n"
     ]
    }
   ],
   "source": [
    "CORRELATION_CUTOFF = 0.05\n",
    "#Logging this in mlflow\n",
    "mlflow.log_param(\"correlation_cutoff\", CORRELATION_CUTOFF)\n",
    "\n",
    "feature_cols = list(most_correlated[most_correlated['correlation_to_target']>CORRELATION_CUTOFF]['feature'])\n",
    "print(feature_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a Machine Learning Pipeline\n",
    "\n",
    "<blockquote>We'll use Spark's <code>Pipeline</code> class to define a set of <code>Transformers</code> that get your dataset ready for modeling<br>\n",
    "We'll then use <code>mlflow</code> to <code>log</code> our Pipeline stages. Both <code>log_pipeline_stages</code> and <code>log_feature_transformations</code> are custom Splice Machine functions for tracking Spark Pipelines. </blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Transformer RandomForestClassifier_6be804c5bc8a could not be parsed. If this is a model, this is expected.\n",
      "Warning: Transformer RandomForestClassifier_6be804c5bc8a could not be parsed. If this is a model, this is expected.\n",
      "CPU times: user 91.8 ms, sys: 4.56 ms, total: 96.4 ms\n",
      "Wall time: 1.14 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from pyspark.ml.feature import StandardScaler, VectorAssembler\n",
    "from pyspark.ml import Pipeline,PipelineModel\n",
    "from pyspark.ml.classification import RandomForestClassifier, MultilayerPerceptronClassifier\n",
    "\n",
    "\"\"\"\n",
    "The preprocessing stages for this example are: \n",
    "1) Vector assembling the feature columns \n",
    "2) Standardizing our feature columns\n",
    "\"\"\"\n",
    "max_depth = 5  \n",
    "num_trees = 20\n",
    "\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol='features')\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol='scaledFeatures')\n",
    "rf = RandomForestClassifier(featuresCol = 'scaledFeatures', labelCol = 'CLASS_RESULT', maxDepth = max_depth, numTrees = num_trees)\n",
    "\n",
    "# Pipeline to preprocess and model our data\n",
    "mlpipe = Pipeline(stages=[assembler,scaler, rf])\n",
    "\n",
    "# Custom Splice functions to add granularity and governance to your Spark Pipeline Models\n",
    "mlflow.log_pipeline_stages(mlpipe)\n",
    "mlflow.log_feature_transformations(mlpipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separating our data for performance evaluation \n",
    "<blockquote> We are using a simple, single train/ test split to assess the performance of our simple model. Of note, we are not invesitgated the class balances, and we are using untuned hyperparameters to predict the target variable. These can be adjusted as an exercise. <footer>Splice Machine</footer>\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder, CrossValidatorModel\n",
    "from splicemachine.stats import *\n",
    "\n",
    "#splitting our data into a training and testing set\n",
    "(train, test) = df.randomSplit([0.8, 0.2])\n",
    "\n",
    "mlflow.lp(\"train_ratio\", 0.80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting our model \n",
    "<blockquote> Training our model and logging executing time using Splcie's custom <code>with mlflow.timer('timer_name')</code> block function to track the time it takes to complete a block. Everything in the block will be timed, and then logged to mlflow under the timer name provided to the function. <footer>Splice Machine</footer>\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with mlflow.timer('training'):\n",
    "    fitted_model = mlpipe.fit(train)\n",
    "# Log the parameters of the best model\n",
    "mlflow.log_model_params(fitted_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessing our Model Performance\n",
    "<blockquote> Making predicitons on the test set, evaluating performance, and logging this to MLFlow <footer>Splice Machine</footer>\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current areaUnderROC: 0.8835821074497563\n",
      "Current areaUnderPR: 0.7292677480397618\n",
      "+-----+----+-------+\n",
      "|     |True|  False|\n",
      "+-----+----+-------+\n",
      "| True|33.0|    7.0|\n",
      "|False|10.0|25205.0|\n",
      "+-----+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Inference\n",
    "predictions = fitted_model.transform(test)\n",
    "\n",
    "#Performance Evaluation\n",
    "binary_evaluator = SpliceBinaryClassificationEvaluator(spark, labelCol = \"CLASS_RESULT\")\n",
    "binary_evaluator.input(predictions)\n",
    "performance_metrics = binary_evaluator.get_results(as_dict = True)\n",
    "\n",
    "#Logging Performance\n",
    "mlflow.log_metrics(performance_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging Artifacts of this Run\n",
    "<blockquote> We can store the notebook associated with a particular run as well as the fitted model created by this run <footer>Splice Machine</footer>\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving artifact of size: 18.99 KB to Splice Machine DB\n",
      "Saving artifact of size: 80.927 KB to Splice Machine DB\n"
     ]
    }
   ],
   "source": [
    "# Store the notebook for easy retrieval\n",
    "mlflow.log_artifact('7.5 Model Creation.ipynb', 'training_notebook')\n",
    "#Log the best model\n",
    "mlflow.log_model(fitted_model, 'rf_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finish our run\n",
    "<blockquote>Now we'll end our run, and view the results in the <a href=\"/mlflow\">MLFlow UI</a>. We can look at our different runs, the parameters, metrics, tags and artifacts logged, and download our notebook directly. You'll know the run is complete fom the small green check mark on the leftmost side of the run</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fantastic!\n",
    "<blockquote> \n",
    "This basically shows how our platform can be used to train and evaluate machine learning models! <br>\n",
    "    Next Up: <a href='./7.6 Data Exploration.ipynb'>Using MLManager to Deploy Machine Learning Models</a>\n",
    "<footer>Splice Machine</footer>\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "220px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
