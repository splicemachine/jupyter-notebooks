{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "#s {\n",
    "}\n",
    "h1, h2, h3, h4, h5, h6, table, button, a, p, blockquote {\n",
    "font-family:Geneva;\n",
    "}\n",
    "\n",
    ".log {\n",
    "transition: all .2s ease-in-out;\n",
    "}\n",
    "\n",
    ".log:hover {a\n",
    "transform: scale(1.05);\n",
    "}\n",
    "</style>\n",
    "<div id='s' style='width:90%'>\n",
    "<center><img class='log' src='https://splicemachine.com/wp-content/uploads/splice-logo-1.png' width='20%' style='z-index:5'></center>\n",
    "<center><h1 class='log' style='font-size:40px; color:black;'>Welcome to Splice Machine MLManager</h1></center>\n",
    "<center><h2 class = 'log' style='font-size:25px; color:grey;'>The data platform for intelligent applications</center>\n",
    "<center><img class='log' src='https://splice-demo.s3.amazonaws.com/splice-machine-data-science-process-h2o.png' width='40%' style='z-index:5'></center>\n",
    "</div>\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this notebook, we're going to take a look at using MLManager with [H2O](https://www.h2o.ai/) + [Spark](https://spark.apache.org/)\n",
    "<h2 style='font-size:25px;  font-weight:bold'>What is <a href=http://docs.h2o.ai/sparkling-water/2.1/latest-stable/doc/pysparkling.html>PySparkling Water?</a> What is <a href=https://splicemachine.com/product/ml-manager/>MLManager?</a></h2>\n",
    "<style>\n",
    "blockquote{\n",
    "  font-size: 15px;\n",
    "  background: #f9f9f9;\n",
    "  border-left: 10px solid #ccc;\n",
    "  margin: .5em 10px;\n",
    "  padding: 30em, 10px;\n",
    "  quotes: \"\\201C\"\"\\201D\"\"\\2018\"\"\\2019\";\n",
    "  padding: 10px 20px;\n",
    "  line-height: 1.4;\n",
    "}\n",
    "\n",
    "blockquote:before {\n",
    "  content: open-quote;\n",
    "  display: inline;\n",
    "  height: 0;\n",
    "  line-height: 0;\n",
    "  left: -10px;\n",
    "  position: relative;\n",
    "  top: 30px;\n",
    "  bottom:30px;\n",
    "  color: #ccc;\n",
    "  font-size: 3em;\n",
    "    display:none;\n",
    "\n",
    "}\n",
    "\n",
    "p{\n",
    "  margin: 0;\n",
    "}\n",
    "\n",
    "footer{\n",
    "  margin:0;\n",
    "  text-align: right;\n",
    "  font-size: 1em;\n",
    "  font-style: italic;\n",
    "}\n",
    "</style>\n",
    "<blockquote><p class='quotation'><b><br><span style='font-size:25px'>PySparkling</span></b> <br><br>PySparkling Water is an awesome H2O extension that allows you to run H2O clusters on top of existing Spark clusters. With Splice Machine, this integration is taken care of for you, so it's simple to start modeling with your new favorite library</i></br><footer>Splice Machine</footer></blockquote><br>\n",
    "<blockquote><p class='quotation'><b><br><span style='font-size:25px'>MLManager (+MLFlow)</span></b><br><br>As a data scientist constantly creating new models and testing new features, it is necessary to effectively track and manage those different ML runs. MLManager + MLFlow allows you to track entire <code>experiments</code> and individual <code>run</code> parameters and metrics. The way you organize your flow is unique to you, and the intuitive Python API allows you to organize your development process and run with it.<br>\n",
    "     <center><img class='log' src='https://s3.amazonaws.com/splice-demo/mlflow+ui.png' width='40%' style='z-index:5'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's get started\n",
    "## In this notebook, we will see how to use Spark, H2O and MLManager to predict sentiment analysis of Amazon reviews, tracking everything in the [MLFlow UI](/mlflow) and deploy our models to production\n",
    "This is an adaptation of the original [H2O Demo](http://docs.h2o.ai/h2o-tutorials/latest-stable/h2o-world-2017/nlp/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important imports and setup\n",
    "* Create our Spark Session\n",
    "* Create our Native Spark Data Source\n",
    "* Create our PySparkling Water cluster\n",
    "* Import our MLManager functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://www.github.com/splicemachine/pysplice@DBAAS-3990\n",
      "  Cloning https://www.github.com/splicemachine/pysplice (to revision DBAAS-3990) to /tmp/pip-req-build-p0zbcnu1\n",
      "  Running command git clone -q https://www.github.com/splicemachine/pysplice /tmp/pip-req-build-p0zbcnu1\n",
      "  Running command git checkout -b DBAAS-3990 --track origin/DBAAS-3990\n",
      "  Switched to a new branch 'DBAAS-3990'\n",
      "  Branch 'DBAAS-3990' set up to track remote branch 'DBAAS-3990' from 'origin'.\n",
      "Requirement already satisfied, skipping upgrade: py4j==0.10.8.1 in /opt/conda/lib/python3.7/site-packages (from splicemachine==2.0.0) (0.10.8.1)\n",
      "Requirement already satisfied, skipping upgrade: pytest==5.1.3 in /opt/conda/lib/python3.7/site-packages (from splicemachine==2.0.0) (5.1.3)\n",
      "Requirement already satisfied, skipping upgrade: mlflow==1.6.0 in /opt/conda/lib/python3.7/site-packages (from splicemachine==2.0.0) (1.6.0)\n",
      "Requirement already satisfied, skipping upgrade: mleap==0.15.0 in /opt/conda/lib/python3.7/site-packages (from splicemachine==2.0.0) (0.15.0)\n",
      "Requirement already satisfied, skipping upgrade: graphviz==0.13 in /opt/conda/lib/python3.7/site-packages (from splicemachine==2.0.0) (0.13)\n",
      "Requirement already satisfied, skipping upgrade: requests in /opt/conda/lib/python3.7/site-packages (from splicemachine==2.0.0) (2.23.0)\n",
      "Requirement already satisfied, skipping upgrade: gorilla==0.3.0 in /opt/conda/lib/python3.7/site-packages (from splicemachine==2.0.0) (0.3.0)\n",
      "Requirement already satisfied, skipping upgrade: tqdm==4.43.0 in /opt/conda/lib/python3.7/site-packages (from splicemachine==2.0.0) (4.43.0)\n",
      "Requirement already satisfied, skipping upgrade: pyspark-dist-explore==0.1.8 in /opt/conda/lib/python3.7/site-packages (from splicemachine==2.0.0) (0.1.8)\n",
      "Requirement already satisfied, skipping upgrade: numpy==1.18.2 in /opt/conda/lib/python3.7/site-packages (from splicemachine==2.0.0) (1.18.2)\n",
      "Requirement already satisfied, skipping upgrade: pandas==1.0.3 in /opt/conda/lib/python3.7/site-packages (from splicemachine==2.0.0) (1.0.3)\n",
      "Requirement already satisfied, skipping upgrade: scipy==1.4.1 in /opt/conda/lib/python3.7/site-packages (from splicemachine==2.0.0) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata>=0.12; python_version < \"3.8\" in /opt/conda/lib/python3.7/site-packages (from pytest==5.1.3->splicemachine==2.0.0) (1.6.0)\n",
      "Requirement already satisfied, skipping upgrade: py>=1.5.0 in /opt/conda/lib/python3.7/site-packages (from pytest==5.1.3->splicemachine==2.0.0) (1.8.1)\n",
      "Requirement already satisfied, skipping upgrade: atomicwrites>=1.0 in /opt/conda/lib/python3.7/site-packages (from pytest==5.1.3->splicemachine==2.0.0) (1.4.0)\n",
      "Requirement already satisfied, skipping upgrade: packaging in /opt/conda/lib/python3.7/site-packages (from pytest==5.1.3->splicemachine==2.0.0) (20.4)\n",
      "Requirement already satisfied, skipping upgrade: more-itertools>=4.0.0 in /opt/conda/lib/python3.7/site-packages (from pytest==5.1.3->splicemachine==2.0.0) (8.3.0)\n",
      "Requirement already satisfied, skipping upgrade: wcwidth in /opt/conda/lib/python3.7/site-packages (from pytest==5.1.3->splicemachine==2.0.0) (0.1.9)\n",
      "Requirement already satisfied, skipping upgrade: pluggy<1.0,>=0.12 in /opt/conda/lib/python3.7/site-packages (from pytest==5.1.3->splicemachine==2.0.0) (0.13.1)\n",
      "Requirement already satisfied, skipping upgrade: attrs>=17.4.0 in /opt/conda/lib/python3.7/site-packages (from pytest==5.1.3->splicemachine==2.0.0) (19.3.0)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.6.0 in /opt/conda/lib/python3.7/site-packages (from mlflow==1.6.0->splicemachine==2.0.0) (3.9.1)\n",
      "Requirement already satisfied, skipping upgrade: databricks-cli>=0.8.7 in /opt/conda/lib/python3.7/site-packages (from mlflow==1.6.0->splicemachine==2.0.0) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: docker>=4.0.0 in /opt/conda/lib/python3.7/site-packages (from mlflow==1.6.0->splicemachine==2.0.0) (4.2.0)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil in /opt/conda/lib/python3.7/site-packages (from mlflow==1.6.0->splicemachine==2.0.0) (2.8.1)\n",
      "Requirement already satisfied, skipping upgrade: cloudpickle in /opt/conda/lib/python3.7/site-packages (from mlflow==1.6.0->splicemachine==2.0.0) (1.2.2)\n",
      "Requirement already satisfied, skipping upgrade: simplejson in /opt/conda/lib/python3.7/site-packages (from mlflow==1.6.0->splicemachine==2.0.0) (3.17.0)\n",
      "Requirement already satisfied, skipping upgrade: querystring-parser in /opt/conda/lib/python3.7/site-packages (from mlflow==1.6.0->splicemachine==2.0.0) (1.2.4)\n",
      "Requirement already satisfied, skipping upgrade: alembic in /opt/conda/lib/python3.7/site-packages (from mlflow==1.6.0->splicemachine==2.0.0) (1.4.2)\n",
      "Requirement already satisfied, skipping upgrade: click>=7.0 in /opt/conda/lib/python3.7/site-packages (from mlflow==1.6.0->splicemachine==2.0.0) (7.1.2)\n",
      "Requirement already satisfied, skipping upgrade: prometheus-flask-exporter in /opt/conda/lib/python3.7/site-packages (from mlflow==1.6.0->splicemachine==2.0.0) (0.13.0)\n",
      "Requirement already satisfied, skipping upgrade: sqlparse in /opt/conda/lib/python3.7/site-packages (from mlflow==1.6.0->splicemachine==2.0.0) (0.3.1)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /opt/conda/lib/python3.7/site-packages (from mlflow==1.6.0->splicemachine==2.0.0) (1.14.0)\n",
      "Requirement already satisfied, skipping upgrade: Flask in /opt/conda/lib/python3.7/site-packages (from mlflow==1.6.0->splicemachine==2.0.0) (1.1.2)\n",
      "Requirement already satisfied, skipping upgrade: gunicorn; platform_system != \"Windows\" in /opt/conda/lib/python3.7/site-packages (from mlflow==1.6.0->splicemachine==2.0.0) (20.0.4)\n",
      "Requirement already satisfied, skipping upgrade: sqlalchemy in /opt/conda/lib/python3.7/site-packages (from mlflow==1.6.0->splicemachine==2.0.0) (1.3.8)\n",
      "Requirement already satisfied, skipping upgrade: gitpython>=2.1.0 in /opt/conda/lib/python3.7/site-packages (from mlflow==1.6.0->splicemachine==2.0.0) (3.1.2)\n",
      "Requirement already satisfied, skipping upgrade: entrypoints in /opt/conda/lib/python3.7/site-packages (from mlflow==1.6.0->splicemachine==2.0.0) (0.3)\n",
      "Requirement already satisfied, skipping upgrade: pyyaml in /opt/conda/lib/python3.7/site-packages (from mlflow==1.6.0->splicemachine==2.0.0) (5.3.1)\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn>=0.18.dev0 in /opt/conda/lib/python3.7/site-packages (from mleap==0.15.0->splicemachine==2.0.0) (0.21.3)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->splicemachine==2.0.0) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->splicemachine==2.0.0) (2.9)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->splicemachine==2.0.0) (1.25.9)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->splicemachine==2.0.0) (2020.4.5.1)\n",
      "Requirement already satisfied, skipping upgrade: matplotlib in /opt/conda/lib/python3.7/site-packages (from pyspark-dist-explore==0.1.8->splicemachine==2.0.0) (3.1.1)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /opt/conda/lib/python3.7/site-packages (from pandas==1.0.3->splicemachine==2.0.0) (2020.1)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=0.12; python_version < \"3.8\"->pytest==5.1.3->splicemachine==2.0.0) (3.1.0)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->pytest==5.1.3->splicemachine==2.0.0) (2.4.7)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /opt/conda/lib/python3.7/site-packages (from protobuf>=3.6.0->mlflow==1.6.0->splicemachine==2.0.0) (46.4.0.post20200518)\n",
      "Requirement already satisfied, skipping upgrade: tabulate>=0.7.7 in /opt/conda/lib/python3.7/site-packages (from databricks-cli>=0.8.7->mlflow==1.6.0->splicemachine==2.0.0) (0.8.7)\n",
      "Requirement already satisfied, skipping upgrade: configparser>=0.3.5 in /opt/conda/lib/python3.7/site-packages (from databricks-cli>=0.8.7->mlflow==1.6.0->splicemachine==2.0.0) (5.0.0)\n",
      "Requirement already satisfied, skipping upgrade: websocket-client>=0.32.0 in /opt/conda/lib/python3.7/site-packages (from docker>=4.0.0->mlflow==1.6.0->splicemachine==2.0.0) (0.57.0)\n",
      "Requirement already satisfied, skipping upgrade: Mako in /opt/conda/lib/python3.7/site-packages (from alembic->mlflow==1.6.0->splicemachine==2.0.0) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: python-editor>=0.3 in /opt/conda/lib/python3.7/site-packages (from alembic->mlflow==1.6.0->splicemachine==2.0.0) (1.0.4)\n",
      "Requirement already satisfied, skipping upgrade: prometheus-client in /opt/conda/lib/python3.7/site-packages (from prometheus-flask-exporter->mlflow==1.6.0->splicemachine==2.0.0) (0.7.1)\n",
      "Requirement already satisfied, skipping upgrade: Jinja2>=2.10.1 in /opt/conda/lib/python3.7/site-packages (from Flask->mlflow==1.6.0->splicemachine==2.0.0) (2.11.2)\n",
      "Requirement already satisfied, skipping upgrade: itsdangerous>=0.24 in /opt/conda/lib/python3.7/site-packages (from Flask->mlflow==1.6.0->splicemachine==2.0.0) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: Werkzeug>=0.15 in /opt/conda/lib/python3.7/site-packages (from Flask->mlflow==1.6.0->splicemachine==2.0.0) (1.0.1)\n",
      "Requirement already satisfied, skipping upgrade: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.7/site-packages (from gitpython>=2.1.0->mlflow==1.6.0->splicemachine==2.0.0) (4.0.5)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.18.dev0->mleap==0.15.0->splicemachine==2.0.0) (0.15.1)\n",
      "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->pyspark-dist-explore==0.1.8->splicemachine==2.0.0) (1.2.0)\n",
      "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->pyspark-dist-explore==0.1.8->splicemachine==2.0.0) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: MarkupSafe>=0.9.2 in /opt/conda/lib/python3.7/site-packages (from Mako->alembic->mlflow==1.6.0->splicemachine==2.0.0) (1.1.1)\n",
      "Requirement already satisfied, skipping upgrade: smmap<4,>=3.0.1 in /opt/conda/lib/python3.7/site-packages (from gitdb<5,>=4.0.1->gitpython>=2.1.0->mlflow==1.6.0->splicemachine==2.0.0) (3.0.4)\n",
      "Building wheels for collected packages: splicemachine\n",
      "  Building wheel for splicemachine (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for splicemachine: filename=splicemachine-2.0.0-py3-none-any.whl size=54523 sha256=a8d02a84f8732678b24b45d55550879c15e0d895ea98b5ad3bd7ebf7bff88551\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ivntjyu6/wheels/0c/58/ec/d4dd5d3e14310dcd82c132198196b6973a4139393dee4ddd79\n",
      "Successfully built splicemachine\n",
      "Installing collected packages: splicemachine\n",
      "  Attempting uninstall: splicemachine\n",
      "    Found existing installation: splicemachine 2.0.0\n",
      "    Uninstalling splicemachine-2.0.0:\n",
      "      Successfully uninstalled splicemachine-2.0.0\n",
      "Successfully installed splicemachine-2.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade git+https://www.github.com/splicemachine/pysplice@DBAAS-3990"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to H2O server at http://10.128.25.130:54321 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>12 secs</td></tr>\n",
       "<tr><td>H2O cluster timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O data parsing timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.28.1.2</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>2 months and 16 days </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>sparkling-water-jovyan_spark-application-1591147790767</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>2</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>7.667 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>32</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>10</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://10.128.25.130:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O API Extensions:</td>\n",
       "<td>XGBoost, Algos, Amazon S3, Sparkling Water REST API Extensions, AutoML, Core V3, TargetEncoder, Core V4</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>3.7.6 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  -------------------------------------------------------------------------------------------------------\n",
       "H2O cluster uptime:         12 secs\n",
       "H2O cluster timezone:       UTC\n",
       "H2O data parsing timezone:  UTC\n",
       "H2O cluster version:        3.28.1.2\n",
       "H2O cluster version age:    2 months and 16 days\n",
       "H2O cluster name:           sparkling-water-jovyan_spark-application-1591147790767\n",
       "H2O cluster total nodes:    2\n",
       "H2O cluster free memory:    7.667 Gb\n",
       "H2O cluster total cores:    32\n",
       "H2O cluster allowed cores:  10\n",
       "H2O cluster status:         locked, healthy\n",
       "H2O connection url:         http://10.128.25.130:54321\n",
       "H2O connection proxy:\n",
       "H2O internal security:      False\n",
       "H2O API Extensions:         XGBoost, Algos, Amazon S3, Sparkling Water REST API Extensions, AutoML, Core V3, TargetEncoder, Core V4\n",
       "Python version:             3.7.6 final\n",
       "--------------------------  -------------------------------------------------------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sparkling Water Context:\n",
      " * Sparkling Water Version: 3.28.1.2-1-2.4\n",
      " * H2O name: sparkling-water-jovyan_spark-application-1591147790767\n",
      " * cluster size: 2\n",
      " * list of used nodes:\n",
      "  (executorId, host, port)\n",
      "  ------------------------\n",
      "  (1,10.128.24.155,54321)\n",
      "  (2,10.128.30.180,54321)\n",
      "  ------------------------\n",
      "\n",
      "  Open H2O Flow in browser: http://10.128.25.130:54321 (CMD + click in Mac OSX)\n",
      "\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from splicemachine.spark import PySpliceContext\n",
    "from splicemachine.mlflow_support import *\n",
    "from pysparkling import *\n",
    "import h2o\n",
    "\n",
    "# Spark Session\n",
    "spark = SparkSession.builder.config('spark.driver.memoryOverhead',1000).config('spark.driver.memory','2g').getOrCreate()\n",
    "#spark.scheduler.minRegisteredResourcesRatio=1\n",
    "# Native Spark Data Source\n",
    "splice = PySpliceContext(spark)\n",
    "# Register Splice so we can access database functions\n",
    "mlflow.register_splice_context(splice)\n",
    "# Create H2O Cluster\n",
    "conf = H2OConf().setInternalClusterMode()\n",
    "hc = H2OContext.getOrCreate(conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Great! Now let's import our data\n",
    "<style>\n",
    "blockquote{\n",
    "  font-size: 15px;\n",
    "  background: #f9f9f9;\n",
    "  border-left: 10px solid #ccc;\n",
    "  margin: .5em 10px;\n",
    "  padding: 30em, 10px;\n",
    "  quotes: \"\\201C\"\"\\201D\"\"\\2018\"\"\\2019\";\n",
    "  padding: 10px 20px;\n",
    "  line-height: 1.4;\n",
    "}\n",
    "\n",
    "blockquote:before {\n",
    "  content: open-quote;\n",
    "  display: inline;\n",
    "  height: 0;\n",
    "  line-height: 0;\n",
    "  left: -10px;\n",
    "  position: relative;\n",
    "  top: 30px;\n",
    "  bottom:30px;\n",
    "  color: #ccc;\n",
    "  font-size: 3em;\n",
    "    display:none;\n",
    "\n",
    "}\n",
    "\n",
    "p{\n",
    "  margin: 0;\n",
    "}\n",
    "\n",
    "footer{\n",
    "  margin:0;\n",
    "  text-align: right;\n",
    "  font-size: 1em;\n",
    "  font-style: italic;\n",
    "}\n",
    "</style>\n",
    "<blockquote><p class='quotation'><b><br><span style='font-size:25px'>Importing Data</span></b> <br><br>There are a few easy ways to get data into Splice Machine, and we'll demonstrate 2 of them here. You can use the built-in <code>%%sql</code> magic to import data directly from external sources, such as S3, or you can use H2O to directly read the data from S3, create a table from that dataframe, and insert the data directly using the <code>PySpliceContext</code> you created in the cell above. </i></br><footer>Splice Machine</footer></blockquote><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 1: Direct Import from SQL\n",
    "<style>\n",
    "blockquote{\n",
    "  font-size: 15px;\n",
    "  background: #f9f9f9;\n",
    "  border-left: 10px solid #ccc;\n",
    "  margin: .5em 10px;\n",
    "  padding: 30em, 10px;\n",
    "  quotes: \"\\201C\"\"\\201D\"\"\\2018\"\"\\2019\";\n",
    "  padding: 10px 20px;\n",
    "  line-height: 1.4;\n",
    "}\n",
    "\n",
    "blockquote:before {\n",
    "  content: open-quote;\n",
    "  display: inline;\n",
    "  height: 0;\n",
    "  line-height: 0;\n",
    "  left: -10px;\n",
    "  position: relative;\n",
    "  top: 30px;\n",
    "  bottom:30px;\n",
    "  color: #ccc;\n",
    "  font-size: 3em;\n",
    "    display:none;\n",
    "\n",
    "}\n",
    "\n",
    "p{\n",
    "  margin: 0;\n",
    "}\n",
    "\n",
    "footer{\n",
    "  margin:0;\n",
    "  text-align: right;\n",
    "  font-size: 1em;\n",
    "  font-style: italic;\n",
    "}\n",
    "</style>\n",
    "<blockquote><p class='quotation'><b><br><span style='font-size:25px'>SQL Import</span></b> <br><br>This method is simple: Create your table, point it to a an S3 location, and run the import command</i></br><footer>Splice Machine</footer></blockquote><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sql started successfully\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6a22e1e-da0e-40b5-bf23-e8c9b2b2bc27",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f00c84d8-9ebb-4a50-ae1c-27f4851e9d35",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd59a605-5a91-4e44-8d50-5b2a25c7e0fb",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS AMAZON_REVIEWS;\n",
    "CREATE TABLE AMAZON_REVIEWS(\n",
    "    PRODUCTID VARCHAR(250),\n",
    "    USERID VARCHAR(250),\n",
    "    SUMMARY VARCHAR(500),\n",
    "    SCORE INT,\n",
    "    HELPFULNESSDENOMINATOR BIGINT,\n",
    "    ID INT,\n",
    "    PROFILENAME VARCHAR(500),\n",
    "    HELPFULNESSNUMERATOR BIGINT,\n",
    "    REVIEW_TIME BIGINT,\n",
    "    REVIEW VARCHAR(15000)\n",
    ");\n",
    "\n",
    "\n",
    "-- Import the data\n",
    "call SYSCS_UTIL.IMPORT_DATA (\n",
    "     null,\n",
    "     'AMAZON_REVIEWS',\n",
    "     null,\n",
    "     's3a://splice-demo/AmazonReviews.csv',\n",
    "     ',',\n",
    "     null,\n",
    "     null,\n",
    "     null,\n",
    "     null,\n",
    "     -1,\n",
    "     's3a://splice-demo/bad',\n",
    "     null, \n",
    "     null);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sql started successfully\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55ddb81d-c44f-45ab-bf80-4230756219e6",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%sql\n",
    "select top 10 * from AMAZON_REVIEWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows:99999\n",
      "Cols:10\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>       </th><th>PRODUCTID  </th><th>USERID        </th><th>SUMMARY                     </th><th>SCORE            </th><th>HELPFULNESSDENOMINATOR  </th><th>ID               </th><th>PROFILENAME               </th><th>HELPFULNESSNUMERATOR  </th><th>REVIEW_TIME       </th><th>REVIEW                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>type   </td><td>string     </td><td>string        </td><td>string                      </td><td>int              </td><td>int                     </td><td>int              </td><td>string                    </td><td>int                   </td><td>int               </td><td>string                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   </td></tr>\n",
       "<tr><td>mins   </td><td>NaN        </td><td>NaN           </td><td>NaN                         </td><td>1.0              </td><td>0.0                     </td><td>3.0              </td><td>NaN                       </td><td>0.0                   </td><td>940809600.0       </td><td>NaN                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      </td></tr>\n",
       "<tr><td>mean   </td><td>NaN        </td><td>NaN           </td><td>NaN                         </td><td>4.186101861018622</td><td>2.236472364723646       </td><td>284618.2923129272</td><td>NaN                       </td><td>1.745467454674538     </td><td>1296171870.3266754</td><td>NaN                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      </td></tr>\n",
       "<tr><td>maxs   </td><td>NaN        </td><td>NaN           </td><td>NaN                         </td><td>5.0              </td><td>878.0                   </td><td>568436.0         </td><td>NaN                       </td><td>866.0                 </td><td>1351209600.0      </td><td>NaN                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      </td></tr>\n",
       "<tr><td>sigma  </td><td>NaN        </td><td>NaN           </td><td>NaN                         </td><td>1.309542187819562</td><td>8.805400733729012       </td><td>164159.3591659332</td><td>NaN                       </td><td>8.171450255812875     </td><td>48107386.40835959 </td><td>NaN                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      </td></tr>\n",
       "<tr><td>zeros  </td><td>0          </td><td>0             </td><td>0                           </td><td>0                </td><td>47593                   </td><td>0                </td><td>0                         </td><td>53553                 </td><td>0                 </td><td>0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </td></tr>\n",
       "<tr><td>missing</td><td>0          </td><td>0             </td><td>0                           </td><td>0                </td><td>0                       </td><td>0                </td><td>0                         </td><td>0                     </td><td>0                 </td><td>0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </td></tr>\n",
       "<tr><td>0      </td><td>B00141QYSQ </td><td>A1YS02UZZGRDCT</td><td>Do Not Buy                  </td><td>1.0              </td><td>2.0                     </td><td>41471.0          </td><td>Evan Eberhardt            </td><td>2.0                   </td><td>1348358400.0      </td><td>These are made in China (do not buy ANY pet food from China).  Dogswell has been using propylene glycol to soften their treats (what are they thinkng?).  Do not purchase or support this company in any way until they clean up their act.  And for whatever reason Amazon doesn&#x27;t allow returns of this item, so I had to toss mine out.  Bad business all around on this one.                                                                                                                                                                                                                                                                                                                                                                                         </td></tr>\n",
       "<tr><td>1      </td><td>B001EO69SS </td><td>A19Q6EHPUDOMBE</td><td>Nuitrition not included.    </td><td>1.0              </td><td>2.0                     </td><td>335387.0         </td><td>Voltaire                  </td><td>2.0                   </td><td>1321747200.0      </td><td>I purchased this thinking &quot;the Italians are good with food, this should be delicious.&quot;  If you know anything about food, it looses its nutrition the more it&#x27;s cooked.  This product comes pre-cooked, par-boiled.  Black rice is a rich, nutty, food that is so filling it&#x27;s like a whole meal.  Foodies love it because it balance out the usual plate of protein, vegetables, and starch with flavorful starch.  It can be eaten alone, with milk as a breakfast, with beans in the forest or as a centerpiece of exotic meal.&lt;br /&gt;However, the reason we love this stuff is because it&#x27;s high in vitamins.  Not this stuff.  Par-boiling then drying it out destroys much of the vitamins and flavor.&lt;br /&gt;&lt;br /&gt;Stay far, far away if you want vitamins and flavor.</td></tr>\n",
       "<tr><td>2      </td><td>B0007A0AQM </td><td>A29OX3XJ0QDI02</td><td>Doesn&#x27;t like                </td><td>1.0              </td><td>6.0                     </td><td>143590.0         </td><td>Mocha272                  </td><td>4.0                   </td><td>1316044800.0      </td><td>My dog refuses to eat it and it smells pretty bad. I can&#x27;t recommend it as treat when my dog refuses to touch it.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </td></tr>\n",
       "<tr><td>3      </td><td>B001E6EEE2 </td><td>A3N5KI8UTFHNW7</td><td>Good, but way too pricey!!!!</td><td>4.0              </td><td>3.0                     </td><td>22511.0          </td><td>D. MILLER &quot;Online Shopper&quot;</td><td>2.0                   </td><td>1294790400.0      </td><td>I love Cocoa Krispies and it was nice to find them in bulk via online. When I bought this item, it was a very good price. I no longer order from here because price went up almost 3 times from when I first ordered. I don&#x27;t recommend anyone buy at this price. Walmart has in stores for less than $3 a box same size.                                                                                                                                                                                                                                                                                                                                                                                                                                                </td></tr>\n",
       "<tr><td>4      </td><td>B000YT7TEC </td><td>AH50RZ8LC8AKM </td><td>Awesome price               </td><td>5.0              </td><td>0.0                     </td><td>209316.0         </td><td>Sally J. Herron           </td><td>0.0                   </td><td>1247270400.0      </td><td>I love these to take on trips and to use in chex mix. Awesome price compared to the store price.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         </td></tr>\n",
       "<tr><td>5      </td><td>B0027VO330 </td><td>A13A943ZWQVT0Z</td><td>Meh                         </td><td>1.0              </td><td>5.0                     </td><td>41849.0          </td><td>A. Gordon &quot;A. Gord.&quot;      </td><td>1.0                   </td><td>1294876800.0      </td><td>Wasn&#x27;t very good. I have been eating Classico sauce on my spaghetti for years and thought that I would try something different... this sauce was very runny and had a dull flavor. I figured it would be better than Classico (which is half the cost of this), but I was very disappointed. The hype and chef&#x27;s name on the jar is just to get you to buy it, it&#x27;s really not worth it.                                                                                                                                                                                                                                                                                                                                                                                 </td></tr>\n",
       "<tr><td>6      </td><td>B003D4IYSU </td><td>AYJVOH54PYZ92 </td><td>Great fruit tea!            </td><td>5.0              </td><td>2.0                     </td><td>207489.0         </td><td>dmac                      </td><td>2.0                   </td><td>1319932800.0      </td><td>Love Stash teas and love the value found here on Amazon.  I had been purchasing from the Stash website before finding the same products here at a much better price minus the fussy packaging.  If you like Stash teas, I recommend signing up for the auto delivery option which can be set for up to 6 months apart and reduces the price of the item.&lt;br /&gt;&lt;br /&gt;I tend to like white tea and the peach flavor is mild so I don&#x27;t get that fake peach taste you find in some tea.  It&#x27;s a good balance with the white tea.  I have a small 4 cup drip coffee maker and put 2 bags in the filter basket and about 2 T sugar in the carafe and end up with a few great cups of tea.                                                                                     </td></tr>\n",
       "<tr><td>7      </td><td>B002GWMD7I </td><td>A24UY2BFLGK163</td><td>Remarkably well Balanced    </td><td>4.0              </td><td>0.0                     </td><td>491645.0         </td><td>Peter Besenbruch          </td><td>0.0                   </td><td>1320883200.0      </td><td>This is a dark roast, but not overdone. It has an acid taste, but is not overly bitter. I have tried others, but I keep coming back to this one. For the price, you can&#x27;t beat it.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       </td></tr>\n",
       "<tr><td>8      </td><td>B001ELL86Y </td><td>A1CKAF9L5DVLW7</td><td>GREAT FLAVOR!               </td><td>5.0              </td><td>0.0                     </td><td>39482.0          </td><td>KIRKJ                     </td><td>0.0                   </td><td>1278806400.0      </td><td>THIS SELECTION WAS GREAT FOR THE MONEY.I  HAVE HAD MORE EXPENSIVE BRANDS BUT THIS IS JUST AS GOOD. I HAVE ALSO COMPARED PRICES EVERYWHERE FOR THE K CUPS AND AMAZON IS BY FAR THE CHEAPEST WAY TO GO!!                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   </td></tr>\n",
       "<tr><td>9      </td><td>B004W7TB3Y </td><td>A3N7IG2EQPMLXL</td><td>great taste                 </td><td>5.0              </td><td>0.0                     </td><td>442645.0         </td><td>Ali Jafar Al Moamen       </td><td>0.0                   </td><td>1345593600.0      </td><td>as i expected its a great taste and healthy and good shipment packing great fair value, i will order it again ,thank u starbux                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get data from table into Spark Dataframe\n",
    "df2 = splice.df('select * from REPLACE_ME_DBSCHEMA.amazon_reviews')\n",
    "hdf = hc.asH2OFrame(df2)\n",
    "hdf.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 2: Import from H2O\n",
    "<style>\n",
    "blockquote{\n",
    "  font-size: 15px;\n",
    "  background: #f9f9f9;\n",
    "  border-left: 10px solid #ccc;\n",
    "  margin: .5em 10px;\n",
    "  padding: 30em, 10px;\n",
    "  quotes: \"\\201C\"\"\\201D\"\"\\2018\"\"\\2019\";\n",
    "  padding: 10px 20px;\n",
    "  line-height: 1.4;\n",
    "}\n",
    "\n",
    "blockquote:before {\n",
    "  content: open-quote;\n",
    "  display: inline;\n",
    "  height: 0;\n",
    "  line-height: 0;\n",
    "  left: -10px;\n",
    "  position: relative;\n",
    "  top: 30px;\n",
    "  bottom:30px;\n",
    "  color: #ccc;\n",
    "  font-size: 3em;\n",
    "    display:none;\n",
    "\n",
    "}\n",
    "\n",
    "p{\n",
    "  margin: 0;\n",
    "}\n",
    "\n",
    "footer{\n",
    "  margin:0;\n",
    "  text-align: right;\n",
    "  font-size: 1em;\n",
    "  font-style: italic;\n",
    "}\n",
    "</style>\n",
    "<blockquote><p class='quotation'><b><br><span style='font-size:25px'>H2O Import</span></b> <br><br>This method is also straightforward, and may be preferable to Data Scientists: Import your data using H2O, and then use the <code>PySpliceContext</code> to create the table from the dataframe and insert the data directly. You'll notice that this method doesn't directly involve any SQL.</i></br><footer>Splice Machine</footer></blockquote><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>ProductId  </th><th>UserId        </th><th>Summary                               </th><th style=\"text-align: right;\">  Score</th><th style=\"text-align: right;\">  HelpfulnessDenominator</th><th style=\"text-align: right;\">    Id</th><th>ProfileName                                     </th><th style=\"text-align: right;\">  HelpfulnessNumerator</th><th style=\"text-align: right;\">       Time</th><th>Text                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>B00141QYSQ </td><td>A1YS02UZZGRDCT</td><td>Do Not Buy                            </td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">                       2</td><td style=\"text-align: right;\"> 41471</td><td>Evan Eberhardt                                  </td><td style=\"text-align: right;\">                     2</td><td style=\"text-align: right;\">1.34836e+09</td><td>These are made in China (do not buy ANY pet food from China).  Dogswell has been using propylene glycol to soften their treats (what are they thinkng?).  Do not purchase or support this company in any way until they clean up their act.  And for whatever reason Amazon doesn&#x27;t allow returns of this item, so I had to toss mine out.  Bad business all around on this one.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            </td></tr>\n",
       "<tr><td>B0089SPEO2 </td><td>A3JOYNYL458QHP</td><td>Less lemon and less zing              </td><td style=\"text-align: right;\">      3</td><td style=\"text-align: right;\">                       0</td><td style=\"text-align: right;\"> 28582</td><td>coleridge                                       </td><td style=\"text-align: right;\">                     0</td><td style=\"text-align: right;\">1.32391e+09</td><td>Everything is ok, except it just isn&#x27;t as good as it is in the bags.  Just considerably more bland -- less lemon and less zing.  Boring.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </td></tr>\n",
       "<tr><td>B001PMCDK2 </td><td>A14TTMM0Z03Y2W</td><td>my cat goes crazy for these!          </td><td style=\"text-align: right;\">      5</td><td style=\"text-align: right;\">                       0</td><td style=\"text-align: right;\">389965</td><td>Lindsay S. Bradford                             </td><td style=\"text-align: right;\">                     0</td><td style=\"text-align: right;\">1.3106e+09 </td><td>Best cat treat ever. There isn&#x27;t anything comparable to the love my cat has for these treats, he snubs away any other kind now.&lt;br /&gt;I know he likes to manipulate me with his cattiness but these treats are my way of manipulating him to come sit on my lap and have some chill time. :)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 </td></tr>\n",
       "<tr><td>B002Q8JOSI </td><td>A17UQD2RSSQH5X</td><td>My dogs tell me these treats are YUMMY</td><td style=\"text-align: right;\">      5</td><td style=\"text-align: right;\">                       1</td><td style=\"text-align: right;\">212536</td><td>in the dark                                     </td><td style=\"text-align: right;\">                     1</td><td style=\"text-align: right;\">1.31613e+09</td><td>My two Corgis were thoroughly spoiled by my late husband (I spent a year and a half dieting them down a combined total of 25 pounds!)&lt;br /&gt;&lt;br /&gt;They are accustomed to the finest of fare, and they absolutely love the Wellness brand of treats.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          </td></tr>\n",
       "<tr><td>B00176G870 </td><td>A2F2MZW8EOGH5J</td><td>Yummy to the tummy                    </td><td style=\"text-align: right;\">      5</td><td style=\"text-align: right;\">                       0</td><td style=\"text-align: right;\">115971</td><td>daemoncycler &quot;When you arrive at a fork in th...</td><td style=\"text-align: right;\">                     0</td><td style=\"text-align: right;\">1.33479e+09</td><td>We used to have drive down to the specialty pet food store for this product.  So glad we discovered Amazon.  As far as I can tell it is no more expensive &amp; in some cases less - Prime membership is awesome.  Loving Pets treats are some of the best according to my dog.  They do not develop that nasty smell like some dog treats do.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  </td></tr>\n",
       "<tr><td>B001CHFUGY </td><td>A2M8VROSDPU4JT</td><td>Very good coffee                      </td><td style=\"text-align: right;\">      5</td><td style=\"text-align: right;\">                       1</td><td style=\"text-align: right;\">434484</td><td>Officefan &quot;Officefankt&quot;                         </td><td style=\"text-align: right;\">                     1</td><td style=\"text-align: right;\">1.27725e+09</td><td>I really liked this coffee, it was just as good as everyone claimed it was.  Strong, bold and flavorful!  I would recommend!                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                </td></tr>\n",
       "<tr><td>B0041CIR62 </td><td>A16I6WJUEBJ1C3</td><td>okay but not as healthy as it appears </td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">                       1</td><td style=\"text-align: right;\">138997</td><td>doctorsirena &quot;doctorsirena&quot;                     </td><td style=\"text-align: right;\">                     1</td><td style=\"text-align: right;\">1.34369e+09</td><td>I am always looking for healthier, whole grain versions of foods I enjoy.  Unfortunately, these Peacock brand noodles are yet another food masquerading as healthy.  The product title in big letters on the front says &quot;Brown Rice Vermicelli&quot;, making the consumer think &quot;this is made with brown rice, so it should be a healthy choice&quot;.  But the first indication that it is not is when looking at the fiber content on the nutrition facts - only 0.6g per 2oz serving.  Then onto the ingredients list to see why so low... contains brown rice, sago starch and water.  The sago starch comes from palms and must not have much (if any) fiber.&lt;br /&gt;&lt;br /&gt;The Annie Chun&#x27;s Maifun Brown Rice Noodles (sold on Amazon and in my local healthy grocer) has become one of my staples and is my frame of reference when comparing to the Peacock brand.  The Annie Chun&#x27;s product is made with 100% whole grain, with ingredients brown rice flour and water.  Per 2oz serving, it has 4g fiber and pretty much the same calories and other nutrients as the Peacock brand.&lt;br /&gt;&lt;br /&gt;If you do try this Peacock brand noodles and have not used rice noodles before, you will need to seek guidance elsewhere on preparation.  As others have pointed out, the Peacock package gives almost no directions on how to prepare the product, aside from a brief mention in the recipes (in the header text it does say that they are &quot;easy-to-cook&quot; but does not say how).  It also contains a very strange recipe for rice noodles: Aglio Olio style - this is an Italian recipe for noodles with olive oil/garlic/sprinkled with grated cheese that I think would not be very tasty.  The second recipe appears to be for a soup with veggie strips.  Neither recipe gives amounts or much direction.  In comparison, the Annie Chun&#x27;s package gives clear, specific directions on rice noodle preparation and two recipes.&lt;br /&gt;&lt;br /&gt;I use rice noodles = maifun = rice sticks = sometimes called vermicelli for making the Vietnamese salad &quot;bun tofu&quot;, to serve with stir-fried veggies or in lettuce rolls.  They can also be used in spring rolls/egg rolls.  When cooking with thin rice noodles, be careful not to oversoak/overcook/overmix or they tend to disintegrate.  Asian rice noodle vermicelli (maifun) are not the same as Italian vermicelli and are not readily interchangeable.  If making an Italian recipe, the best results would be expected from Italian pasta and not maifun.&lt;br /&gt;&lt;br /&gt;A few final notes...  Both Peacock and Annie Chun&#x27;s brown rice noodles are gluten free.  The Peacock is made in Singapore and the Annie Chun&#x27;s in Thailand.  The Peacock noodles do taste fine (kind of bland), but so do the Annie Chun&#x27;s.  At this time, they are both approximately the same price.  Peacock come in an plastic bag with some noodle crushage upon shipping; Annie Chun&#x27;s are perfect upon removal from their cellophane bag in a box.  Overall, I highly recommend the Annie Chun&#x27;s Maifun as a healthier option over the Peacock brand.  On a related note, the Annie Chun&#x27;s soba and brown rice pad thai noodles are also excellent.&lt;br /&gt;&lt;br /&gt;Rating for this product: 2.5 stars rounded down to 2 stars.</td></tr>\n",
       "<tr><td>B001R3BQFW </td><td>AM50E42AFUVNL </td><td>Taste great.                          </td><td style=\"text-align: right;\">      5</td><td style=\"text-align: right;\">                       0</td><td style=\"text-align: right;\">126555</td><td>T. Higley &quot;Tina&quot;                                </td><td style=\"text-align: right;\">                     0</td><td style=\"text-align: right;\">1.32356e+09</td><td>I have tried many different drink mix, this is the best tasting by far. It does not have the after taste of the sweetener and I really like it, it is pretty strong, so I use a big water bottle (20 oz) for one tube, it still a little stronger than I like, but it is just my taste.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     </td></tr>\n",
       "<tr><td>B005HGAV8I </td><td>A2I5KDNOESGJ1H</td><td>variety galore                        </td><td style=\"text-align: right;\">      5</td><td style=\"text-align: right;\">                       1</td><td style=\"text-align: right;\">438837</td><td>TJ                                              </td><td style=\"text-align: right;\">                     1</td><td style=\"text-align: right;\">1.33402e+09</td><td>This is my favorite item to order for my Keurig. There are so many flavors, my finicky palate never gets bored!  The only downside is there are probably 5-6 decaf varieties.  I don&#x27;t drink decaf (I REQUIRE copious amounts of caffeine), so they sit on the shelf...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     </td></tr>\n",
       "<tr><td>B000GFYRHQ </td><td>A3A7YUR6FS6ZCI</td><td>Bigelow Earl Grey Green Tea           </td><td style=\"text-align: right;\">      5</td><td style=\"text-align: right;\">                       0</td><td style=\"text-align: right;\">245379</td><td>Tea Lover                                       </td><td style=\"text-align: right;\">                     0</td><td style=\"text-align: right;\">1.17841e+09</td><td>Tastes like Earl Grey, but it&#x27;s green tea so it&#x27;s healthier.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"https://splice-demo.s3.amazonaws.com/AmazonReviews.csv\"\n",
    "# Load data into H2O\n",
    "reviews = h2o.import_file(data_path)\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## H2O offers great functions to convert H2OFrames into Pandas and Spark DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+--------------------+-----+----------------------+------+--------------------+--------------------+----------+--------------------+\n",
      "| ProductId|        UserId|             Summary|Score|HelpfulnessDenominator|    Id|         ProfileName|HelpfulnessNumerator|      Time|                Text|\n",
      "+----------+--------------+--------------------+-----+----------------------+------+--------------------+--------------------+----------+--------------------+\n",
      "|B006BXV130|A188JOXWF4EY1R|Enjoyed by my Family|    4|                     0|223710|Ann B. Hibbard \"a...|                   0|1331596800|I had no idea wha...|\n",
      "|B001D0IZBW| AMBU96SBSZW3I|Best Decaf I've T...|    5|                     0|531064|         Maryann Oda|                   0|1293580800|This is by far th...|\n",
      "|B004RZA6XA| AUEK6KM2T5XZ5|     Excellent stuff|    5|                     0| 91641|       W. J. Regotti|                   0|1343347200|Great in water an...|\n",
      "|B002QWP8H0|A1TGNK1ISA9P3C|Saw a difference ...|    5|                     0|355747|           Christine|                   0|1327968000|I have an Old Eng...|\n",
      "|B00503DOWS|A1PW5SQLR0Z6IH|Too expensive and...|    2|                    14|407162|    Natalie S \"ns65\"|                  10|1313539200|I was excited to ...|\n",
      "|B001M0AKE8|A3E2N9MZG07V83|    Dinosaur Oatmeal|    5|                     0|504115|              Baxter|                   0|1347840000|My Children reall...|\n",
      "|B0016CUFF6|A1XJOUAG97V08L|          Love this!|    5|                     0|355262|                  CW|                   0|1349913600|This is my favori...|\n",
      "|B003DNL9RY|A39OV17Z3K78HF|       Good Drinking|    5|                     1|140292|                Boca|                   1|1332633600|I've been a long ...|\n",
      "|B0019FGRJI|A3AKU3G4JE80Q5|Petit Beurre Bisc...|    5|                     0|274174|     Chris Kimberley|                   0|1298678400|Lu Petit Beurre a...|\n",
      "|B000PDY3HI|A1AG3MZPK25F23|        Disappointed|    3|                     3|364412|Darleen Michael B...|                   2|1283385600|I was very excite...|\n",
      "|B002S4AQOQ|A1XGFW5016CGQI|FINALLY, ANOTHER ...|    5|                     0|296568|              Cathio|                   0|1329696000|I have have 10 to...|\n",
      "|B0001KBT9K|A2L4UEUW9972BC|          Overpriced|    2|                     0|182255|              Imants|                   0|1344384000|This product is H...|\n",
      "|B0027Z5J6G|A2SYCQMWL6B51F|Weak.  All bag, n...|    1|                    10| 50875|Lorin K. Walker \"...|                   3|1297209600|This is actually ...|\n",
      "|B00009OLE2| AH1UWMIGT56YX|    Bait and switch?|    1|                     9| 17406|   TessFromWA \"Tess\"|                   6|1325030400|At first glance I...|\n",
      "|B000BYM4WM| ASP03W8VQDBD5|          Doggy Gold|    5|                     2|409590|     Samuel A. Nadel|                   2|1242864000|These chicken tre...|\n",
      "|B001FA1EFO| A1IUL785XKEAD|Chocolate...of co...|    5|                     0|295204|         Mary Newell|                   0|1304035200|We were tired of ...|\n",
      "|B004ECNAWU|A24P7YW10FO6VZ|Weird and wonderf...|    4|                     1|269450| Nan Hawthorne \"Nan\"|                   1|1301184000|I received this a...|\n",
      "|B00153B3KW| AVJJ2D4G5I0Z4|Tastes a bit gros...|    4|                     2|476668|Michael A. Behr \"...|                   2|1273104000|So far I've lost ...|\n",
      "|B003O7DYA4|A3BEU5IC66PG0V|BEST RUB FOR CHIC...|    5|                     0| 81931|               v law|                   0|1286928000|I love this stuff...|\n",
      "|B003DNL9IS|A36MPYOSOWKMU9|          good drink|    5|                     0|269950|              driver|                   0|1337990400|I agree it's a go...|\n",
      "+----------+--------------+--------------------+-----+----------------------+------+--------------------+--------------------+----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "<class 'pyspark.sql.dataframe.DataFrame'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Score</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Id</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>Time</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B00141QYSQ</td>\n",
       "      <td>A1YS02UZZGRDCT</td>\n",
       "      <td>Do Not Buy</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>41471</td>\n",
       "      <td>Evan Eberhardt</td>\n",
       "      <td>2</td>\n",
       "      <td>1348358400</td>\n",
       "      <td>These are made in China (do not buy ANY pet fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B0089SPEO2</td>\n",
       "      <td>A3JOYNYL458QHP</td>\n",
       "      <td>Less lemon and less zing</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>28582</td>\n",
       "      <td>coleridge</td>\n",
       "      <td>0</td>\n",
       "      <td>1323907200</td>\n",
       "      <td>Everything is ok, except it just isn't as good...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B001PMCDK2</td>\n",
       "      <td>A14TTMM0Z03Y2W</td>\n",
       "      <td>my cat goes crazy for these!</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>389965</td>\n",
       "      <td>Lindsay S. Bradford</td>\n",
       "      <td>0</td>\n",
       "      <td>1310601600</td>\n",
       "      <td>Best cat treat ever. There isn't anything comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B002Q8JOSI</td>\n",
       "      <td>A17UQD2RSSQH5X</td>\n",
       "      <td>My dogs tell me these treats are YUMMY</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>212536</td>\n",
       "      <td>in the dark</td>\n",
       "      <td>1</td>\n",
       "      <td>1316131200</td>\n",
       "      <td>My two Corgis were thoroughly spoiled by my la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B00176G870</td>\n",
       "      <td>A2F2MZW8EOGH5J</td>\n",
       "      <td>Yummy to the tummy</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>115971</td>\n",
       "      <td>daemoncycler \"When you arrive at a fork in th...</td>\n",
       "      <td>0</td>\n",
       "      <td>1334793600</td>\n",
       "      <td>We used to have drive down to the specialty pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>B001CHFUGY</td>\n",
       "      <td>A2M8VROSDPU4JT</td>\n",
       "      <td>Very good coffee</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>434484</td>\n",
       "      <td>Officefan \"Officefankt\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1277251200</td>\n",
       "      <td>I really liked this coffee, it was just as goo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>B0041CIR62</td>\n",
       "      <td>A16I6WJUEBJ1C3</td>\n",
       "      <td>okay but not as healthy as it appears</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>138997</td>\n",
       "      <td>doctorsirena \"doctorsirena\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1343692800</td>\n",
       "      <td>I am always looking for healthier, whole grain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>B001R3BQFW</td>\n",
       "      <td>AM50E42AFUVNL</td>\n",
       "      <td>Taste great.</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>126555</td>\n",
       "      <td>T. Higley \"Tina\"</td>\n",
       "      <td>0</td>\n",
       "      <td>1323561600</td>\n",
       "      <td>I have tried many different drink mix, this is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>B005HGAV8I</td>\n",
       "      <td>A2I5KDNOESGJ1H</td>\n",
       "      <td>variety galore</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>438837</td>\n",
       "      <td>TJ</td>\n",
       "      <td>1</td>\n",
       "      <td>1334016000</td>\n",
       "      <td>This is my favorite item to order for my Keuri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>B000GFYRHQ</td>\n",
       "      <td>A3A7YUR6FS6ZCI</td>\n",
       "      <td>Bigelow Earl Grey Green Tea</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>245379</td>\n",
       "      <td>Tea Lover</td>\n",
       "      <td>0</td>\n",
       "      <td>1178409600</td>\n",
       "      <td>Tastes like Earl Grey, but it's green tea so i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ProductId          UserId                                 Summary  Score  \\\n",
       "0  B00141QYSQ  A1YS02UZZGRDCT                              Do Not Buy      1   \n",
       "1  B0089SPEO2  A3JOYNYL458QHP                Less lemon and less zing      3   \n",
       "2  B001PMCDK2  A14TTMM0Z03Y2W            my cat goes crazy for these!      5   \n",
       "3  B002Q8JOSI  A17UQD2RSSQH5X  My dogs tell me these treats are YUMMY      5   \n",
       "4  B00176G870  A2F2MZW8EOGH5J                      Yummy to the tummy      5   \n",
       "5  B001CHFUGY  A2M8VROSDPU4JT                        Very good coffee      5   \n",
       "6  B0041CIR62  A16I6WJUEBJ1C3   okay but not as healthy as it appears      2   \n",
       "7  B001R3BQFW   AM50E42AFUVNL                            Taste great.      5   \n",
       "8  B005HGAV8I  A2I5KDNOESGJ1H                          variety galore      5   \n",
       "9  B000GFYRHQ  A3A7YUR6FS6ZCI             Bigelow Earl Grey Green Tea      5   \n",
       "\n",
       "   HelpfulnessDenominator      Id  \\\n",
       "0                       2   41471   \n",
       "1                       0   28582   \n",
       "2                       0  389965   \n",
       "3                       1  212536   \n",
       "4                       0  115971   \n",
       "5                       1  434484   \n",
       "6                       1  138997   \n",
       "7                       0  126555   \n",
       "8                       1  438837   \n",
       "9                       0  245379   \n",
       "\n",
       "                                        ProfileName  HelpfulnessNumerator  \\\n",
       "0                                    Evan Eberhardt                     2   \n",
       "1                                         coleridge                     0   \n",
       "2                               Lindsay S. Bradford                     0   \n",
       "3                                       in the dark                     1   \n",
       "4  daemoncycler \"When you arrive at a fork in th...                     0   \n",
       "5                           Officefan \"Officefankt\"                     1   \n",
       "6                       doctorsirena \"doctorsirena\"                     1   \n",
       "7                                  T. Higley \"Tina\"                     0   \n",
       "8                                                TJ                     1   \n",
       "9                                         Tea Lover                     0   \n",
       "\n",
       "         Time                                               Text  \n",
       "0  1348358400  These are made in China (do not buy ANY pet fo...  \n",
       "1  1323907200  Everything is ok, except it just isn't as good...  \n",
       "2  1310601600  Best cat treat ever. There isn't anything comp...  \n",
       "3  1316131200  My two Corgis were thoroughly spoiled by my la...  \n",
       "4  1334793600  We used to have drive down to the specialty pe...  \n",
       "5  1277251200  I really liked this coffee, it was just as goo...  \n",
       "6  1343692800  I am always looking for healthier, whole grain...  \n",
       "7  1323561600  I have tried many different drink mix, this is...  \n",
       "8  1334016000  This is my favorite item to order for my Keuri...  \n",
       "9  1178409600  Tastes like Earl Grey, but it's green tea so i...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# Spark DataFrame\n",
    "df = hc.asSparkFrame(reviews, copyMetadata=False)\n",
    "df.limit(100).show()\n",
    "del df._h2o_frame\n",
    "print(type(df))\n",
    "# Pandas DataFrame\n",
    "pdf = reviews.head().as_data_frame()\n",
    "display(pdf)\n",
    "print(type(pdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nice!\n",
    "<style>\n",
    "blockquote{\n",
    "  font-size: 15px;\n",
    "  background: #f9f9f9;\n",
    "  border-left: 10px solid #ccc;\n",
    "  margin: .5em 10px;\n",
    "  padding: 30em, 10px;\n",
    "  quotes: \"\\201C\"\"\\201D\"\"\\2018\"\"\\2019\";\n",
    "  padding: 10px 20px;\n",
    "  line-height: 1.4;\n",
    "}\n",
    "\n",
    "blockquote:before {\n",
    "  content: open-quote;\n",
    "  display: inline;\n",
    "  height: 0;\n",
    "  line-height: 0;\n",
    "  left: -10px;\n",
    "  position: relative;\n",
    "  top: 30px;\n",
    "  bottom:30px;\n",
    "  color: #ccc;\n",
    "  font-size: 3em;\n",
    "    display:none;\n",
    "\n",
    "}\n",
    "\n",
    "p{\n",
    "  margin: 0;\n",
    "}\n",
    "\n",
    "footer{\n",
    "  margin:0;\n",
    "  text-align: right;\n",
    "  font-size: 1em;\n",
    "  font-style: italic;\n",
    "}\n",
    "</style>\n",
    "<blockquote><p class='quotation'><b><br><span style='font-size:25px'>Create Table and Insert Data</span></b> <br><br>Now that we have our Spark DataFrame, we can create a table and insert data using <code>splice.createTable</code> and <code>splice.insert</code><br><b>Note: </b>If your code is hanging on the <code>insert</code> your cluser may be out of memory. Try configuring your Spark or H2O cluster with more memory. Read about that <a href=https://docs.h2o.ai/sparkling-water/2.1/latest-stable/doc/configuration/configuration_properties.html>here</a> and <a href=https://spark.apache.org/docs/latest/configuration.html#available-properties>here</a></footer></blockquote><br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method createTable in module splicemachine.spark.context:\n",
      "\n",
      "createTable(dataframe, schema_table_name, primary_keys=None, create_table_options=None, to_upper=False, drop_table=False) method of splicemachine.spark.context.PySpliceContext instance\n",
      "    Creates a schema.table from a dataframe\n",
      "    :param dataframe: The Spark DataFrame to base the table off\n",
      "    :param schema_table_name: str The schema.table to create\n",
      "    :param primary_keys: List[str] the primary keys. Default None\n",
      "    :param create_table_options: str The additional table-level SQL options default None\n",
      "    :param to_upper: bool If the dataframe columns should be converted to uppercase before table creation\n",
      "                        If False, the table will be created with lower case columns. Default False\n",
      "    :param drop_table: bool whether to drop the table if it exists. Default False. If False and the table exists,\n",
      "                       the function will throw an exception.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "Help on method insert in module splicemachine.spark.context:\n",
      "\n",
      "insert(dataframe, schema_table_name, to_upper=False) method of splicemachine.spark.context.PySpliceContext instance\n",
      "    Insert a dataframe into a table (schema.table).\n",
      "    \n",
      "    :param dataframe: (DF) The dataframe you would like to insert\n",
      "    :param schema_table_name: (string) The table in which you would like to insert the DF\n",
      "    :param to_upper: bool If the dataframe columns should be converted to uppercase before table creation\n",
      "                        If False, the table will be created with lower case columns. Default False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(splice.createTable)\n",
    "print('----------------------------------------------------------------------------------------------------------------')\n",
    "help(splice.insert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Droping table splice.AMAZON_REVIEWS_H2O\n"
     ]
    }
   ],
   "source": [
    "# Create the table\n",
    "schema = 'splice'\n",
    "df = df.withColumnRenamed('Time', 'Review_Time')\n",
    "df = df.withColumnRenamed('Text', 'Review')\n",
    "splice.createTable(df, f'{schema}.AMAZON_REVIEWS_H2O', to_upper=True, drop_table=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we can insert our dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting... Done.\n"
     ]
    }
   ],
   "source": [
    "print('Inserting... ', end='')\n",
    "splice.insert(df, f'{schema}.AMAZON_REVIEWS_H2O',to_upper=True) # Use to_upper to give the SQL table uppercase columns\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sql started successfully\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8654636d-b2f1-4516-b7bc-8ad756914c7c",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%sql\n",
    "select top 10 varchar(Summary) Summary, Score, HelpfulnessDenominator, Id  from AMAZON_REVIEWS_H2O;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Awesome! Let's get modeling\n",
    "<style>\n",
    "blockquote{\n",
    "  font-size: 15px;\n",
    "  background: #f9f9f9;\n",
    "  border-left: 10px solid #ccc;\n",
    "  margin: .5em 10px;\n",
    "  padding: 30em, 10px;\n",
    "  quotes: \"\\201C\"\"\\201D\"\"\\2018\"\"\\2019\";\n",
    "  padding: 10px 20px;\n",
    "  line-height: 1.4;\n",
    "}\n",
    "\n",
    "blockquote:before {\n",
    "  content: open-quote;\n",
    "  display: inline;\n",
    "  height: 0;\n",
    "  line-height: 0;\n",
    "  left: -10px;\n",
    "  position: relative;\n",
    "  top: 30px;\n",
    "  bottom:30px;\n",
    "  color: #ccc;\n",
    "  font-size: 3em;\n",
    "    display:none;\n",
    "\n",
    "}\n",
    "\n",
    "p{\n",
    "  margin: 0;\n",
    "}\n",
    "\n",
    "footer{\n",
    "  margin:0;\n",
    "  text-align: right;\n",
    "  font-size: 1em;\n",
    "  font-style: italic;\n",
    "}\n",
    "</style>\n",
    "<blockquote><p class='quotation'><b><br><span style='font-size:25px'>Modeling</span></b> <br><br>We're going to try three different ways to approach this problem, and track it all with MLManager. \n",
    "    <ol>\n",
    "        <li>No Text Model: We will try to predict the customer reviews without using the text from the review. Just the Numeric Columns</li>\n",
    "        <li>Using the reviews: We will use Word2Vec to create vectors from the text of the reviews. We will then train a model on that word embedding feature-vector</li>\n",
    "        <li>Using the review summaries: We will use Word2Vec to create vectors from the text of the review summaries</li>\n",
    "    </ol>\n",
    "    Which do you think will perform the best?\n",
    "    </i></br><footer>Splice Machine</footer></blockquote><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Attempt\n",
    "Let's create a simple model using the non-review columns\n",
    "<br>\n",
    "<blockquote>\n",
    "    First, let's start our mlflow experiment! We can start a run and log import parameters, tags, and metrics as they come<br>\n",
    "Next, we can turn this into a binary-classification problem by turning score into a positive or negative review. We will say that 4 and 5 start reviews are positive, but you can change this and try other things!\n",
    "</br><footer>Splice Machine</footer></blockquote><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  PositiveReview</th><th style=\"text-align: right;\">  Count</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">               0</td><td style=\"text-align: right;\">  21791</td></tr>\n",
       "<tr><td style=\"text-align: right;\">               1</td><td style=\"text-align: right;\">  78209</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set our mlflow experiment\n",
    "mlflow.set_experiment('Sentiment Analysis')\n",
    "# Look at our dataframe\n",
    "reviews[\"PositiveReview\"] = (reviews[\"Score\"] >= 4).ifelse(\"1\", \"0\")\n",
    "reviews[\"PositiveReview\"].table()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's see our Data Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PILLOW_VERSION is deprecated and will be removed in a future release. Use __version__ instead.\n",
      "pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 792x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from pyspark.sql.types import FloatType, IntegerType\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pdf = reviews[['ProductId', 'UserId', 'HelpfulnessNumerator', 'HelpfulnessDenominator', 'Time','PositiveReview']].as_data_frame()\n",
    "corr = pdf.corr()\n",
    "\n",
    "ticks = [i for i in range(len(corr.columns))]\n",
    "# Generate a mask for the upper triangle\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "# Color Scheme\n",
    "cmap = \"coolwarm\"\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr,  cmap=cmap, vmax=.3, center=0,\n",
    "            square=False, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
    "\n",
    "plt.xticks(ticks, corr.columns)\n",
    "plt.yticks(ticks, corr.columns)\n",
    "plt.title('Sentiment Data correlation heatmap')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can see some of our features have decent correlation (remember that we aren't using the reviews yet). Let's try a basic model\n",
    "### First, let's log some important information in our <code>run</code>\n",
    "<blockquote>H2O Has a <a href=https://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science.html>lot</a> of algorithms, so we'll use a Gradient Boosting Estimator<br>We'll log some things like our feature vector, label, train/test/validation split, training time, and even the model and notebook themselves directly to <a href='/mlflow'>mlflow</a></blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Code Block train_time... gbm Model Build progress: |███████████████████████████████████████████████| 100%\n",
      "Done.\n",
      "Code Block train_time:\n",
      "Ran in 6.196 secs\n",
      "Ran in 0.103 mins\n",
      "Saving artifact of size: 1582.229 KB to Splice Machine DB\n",
      "Saving artifact of size: 790.302 KB to Splice Machine DB\n",
      "CPU times: user 590 ms, sys: 112 ms, total: 701 ms\n",
      "Wall time: 9.85 s\n",
      "Model Details\n",
      "=============\n",
      "H2OGradientBoostingEstimator :  Gradient Boosting Machine\n",
      "Model Key:  gbm_baseline.hex\n",
      "\n",
      "\n",
      "Model Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>number_of_trees</th>\n",
       "      <th>number_of_internal_trees</th>\n",
       "      <th>model_size_in_bytes</th>\n",
       "      <th>min_depth</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>mean_depth</th>\n",
       "      <th>min_leaves</th>\n",
       "      <th>max_leaves</th>\n",
       "      <th>mean_leaves</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>25639.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>29.96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     number_of_trees  number_of_internal_trees  model_size_in_bytes  \\\n",
       "0               50.0                      50.0              25639.0   \n",
       "\n",
       "   min_depth  max_depth  mean_depth  min_leaves  max_leaves  mean_leaves  \n",
       "0        5.0        5.0         5.0        17.0        32.0        29.96  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.13621599071684365\n",
      "RMSE: 0.36907450564465116\n",
      "LogLoss: 0.43573871604371306\n",
      "Mean Per-Class Error: 0.30294909803326386\n",
      "AUC: 0.7651849136166377\n",
      "AUCPR: 0.9060825299118951\n",
      "Gini: 0.5303698272332753\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5351257536653036: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>Error</th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4329.0</td>\n",
       "      <td>11053.0</td>\n",
       "      <td>0.7186</td>\n",
       "      <td>(11053.0/15382.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1489.0</td>\n",
       "      <td>53198.0</td>\n",
       "      <td>0.0272</td>\n",
       "      <td>(1489.0/54687.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total</td>\n",
       "      <td>5818.0</td>\n",
       "      <td>64251.0</td>\n",
       "      <td>0.179</td>\n",
       "      <td>(12542.0/70069.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0        1   Error                Rate\n",
       "0      0  4329.0  11053.0  0.7186   (11053.0/15382.0)\n",
       "1      1  1489.0  53198.0  0.0272    (1489.0/54687.0)\n",
       "2  Total  5818.0  64251.0   0.179   (12542.0/70069.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>threshold</th>\n",
       "      <th>value</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>max f1</td>\n",
       "      <td>0.535126</td>\n",
       "      <td>0.894550</td>\n",
       "      <td>263.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max f2</td>\n",
       "      <td>0.233941</td>\n",
       "      <td>0.949338</td>\n",
       "      <td>352.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>max f0point5</td>\n",
       "      <td>0.744480</td>\n",
       "      <td>0.866401</td>\n",
       "      <td>174.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>max accuracy</td>\n",
       "      <td>0.600052</td>\n",
       "      <td>0.821761</td>\n",
       "      <td>238.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max precision</td>\n",
       "      <td>0.961058</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>max recall</td>\n",
       "      <td>0.082435</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>395.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>max specificity</td>\n",
       "      <td>0.961058</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>max absolute_mcc</td>\n",
       "      <td>0.687098</td>\n",
       "      <td>0.404484</td>\n",
       "      <td>198.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>max min_per_class_accuracy</td>\n",
       "      <td>0.812741</td>\n",
       "      <td>0.686452</td>\n",
       "      <td>121.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max mean_per_class_accuracy</td>\n",
       "      <td>0.789146</td>\n",
       "      <td>0.697051</td>\n",
       "      <td>144.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>max tns</td>\n",
       "      <td>0.961058</td>\n",
       "      <td>15382.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>max fns</td>\n",
       "      <td>0.961058</td>\n",
       "      <td>54682.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>max fps</td>\n",
       "      <td>0.055468</td>\n",
       "      <td>15382.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>max tps</td>\n",
       "      <td>0.082435</td>\n",
       "      <td>54687.000000</td>\n",
       "      <td>395.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>max tnr</td>\n",
       "      <td>0.961058</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>max fnr</td>\n",
       "      <td>0.961058</td>\n",
       "      <td>0.999909</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>max fpr</td>\n",
       "      <td>0.055468</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>max tpr</td>\n",
       "      <td>0.082435</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>395.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         metric  threshold         value    idx\n",
       "0                        max f1   0.535126      0.894550  263.0\n",
       "1                        max f2   0.233941      0.949338  352.0\n",
       "2                  max f0point5   0.744480      0.866401  174.0\n",
       "3                  max accuracy   0.600052      0.821761  238.0\n",
       "4                 max precision   0.961058      1.000000    0.0\n",
       "5                    max recall   0.082435      1.000000  395.0\n",
       "6               max specificity   0.961058      1.000000    0.0\n",
       "7              max absolute_mcc   0.687098      0.404484  198.0\n",
       "8    max min_per_class_accuracy   0.812741      0.686452  121.0\n",
       "9   max mean_per_class_accuracy   0.789146      0.697051  144.0\n",
       "10                      max tns   0.961058  15382.000000    0.0\n",
       "11                      max fns   0.961058  54682.000000    0.0\n",
       "12                      max fps   0.055468  15382.000000  399.0\n",
       "13                      max tps   0.082435  54687.000000  395.0\n",
       "14                      max tnr   0.961058      1.000000    0.0\n",
       "15                      max fnr   0.961058      0.999909    0.0\n",
       "16                      max fpr   0.055468      1.000000  399.0\n",
       "17                      max tpr   0.082435      1.000000  395.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate: 78.05 %, avg score: 78.04 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>cumulative_data_fraction</th>\n",
       "      <th>lower_threshold</th>\n",
       "      <th>lift</th>\n",
       "      <th>cumulative_lift</th>\n",
       "      <th>response_rate</th>\n",
       "      <th>score</th>\n",
       "      <th>cumulative_response_rate</th>\n",
       "      <th>cumulative_score</th>\n",
       "      <th>capture_rate</th>\n",
       "      <th>cumulative_capture_rate</th>\n",
       "      <th>gain</th>\n",
       "      <th>cumulative_gain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0.010104</td>\n",
       "      <td>0.924989</td>\n",
       "      <td>1.252318</td>\n",
       "      <td>1.252318</td>\n",
       "      <td>0.977401</td>\n",
       "      <td>0.932727</td>\n",
       "      <td>0.977401</td>\n",
       "      <td>0.932727</td>\n",
       "      <td>0.012654</td>\n",
       "      <td>0.012654</td>\n",
       "      <td>25.231810</td>\n",
       "      <td>25.231810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>0.020009</td>\n",
       "      <td>0.918158</td>\n",
       "      <td>1.257273</td>\n",
       "      <td>1.254771</td>\n",
       "      <td>0.981268</td>\n",
       "      <td>0.921049</td>\n",
       "      <td>0.979315</td>\n",
       "      <td>0.926947</td>\n",
       "      <td>0.012453</td>\n",
       "      <td>0.025107</td>\n",
       "      <td>25.727263</td>\n",
       "      <td>25.477063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>0.030013</td>\n",
       "      <td>0.912926</td>\n",
       "      <td>1.241062</td>\n",
       "      <td>1.250201</td>\n",
       "      <td>0.968616</td>\n",
       "      <td>0.915329</td>\n",
       "      <td>0.975749</td>\n",
       "      <td>0.923074</td>\n",
       "      <td>0.012416</td>\n",
       "      <td>0.037523</td>\n",
       "      <td>24.106228</td>\n",
       "      <td>25.020118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>0.040003</td>\n",
       "      <td>0.909535</td>\n",
       "      <td>1.233683</td>\n",
       "      <td>1.246076</td>\n",
       "      <td>0.962857</td>\n",
       "      <td>0.911191</td>\n",
       "      <td>0.972529</td>\n",
       "      <td>0.920107</td>\n",
       "      <td>0.012325</td>\n",
       "      <td>0.049847</td>\n",
       "      <td>23.368327</td>\n",
       "      <td>24.607612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "      <td>0.050022</td>\n",
       "      <td>0.906824</td>\n",
       "      <td>1.231994</td>\n",
       "      <td>1.243256</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.908034</td>\n",
       "      <td>0.970328</td>\n",
       "      <td>0.917689</td>\n",
       "      <td>0.012343</td>\n",
       "      <td>0.062190</td>\n",
       "      <td>23.199368</td>\n",
       "      <td>24.325562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>6</td>\n",
       "      <td>0.100558</td>\n",
       "      <td>0.898139</td>\n",
       "      <td>1.181768</td>\n",
       "      <td>1.212355</td>\n",
       "      <td>0.922338</td>\n",
       "      <td>0.902074</td>\n",
       "      <td>0.946211</td>\n",
       "      <td>0.909841</td>\n",
       "      <td>0.059722</td>\n",
       "      <td>0.121912</td>\n",
       "      <td>18.176758</td>\n",
       "      <td>21.235452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>7</td>\n",
       "      <td>0.150009</td>\n",
       "      <td>0.890913</td>\n",
       "      <td>1.185132</td>\n",
       "      <td>1.203380</td>\n",
       "      <td>0.924964</td>\n",
       "      <td>0.894299</td>\n",
       "      <td>0.939207</td>\n",
       "      <td>0.904718</td>\n",
       "      <td>0.058606</td>\n",
       "      <td>0.180518</td>\n",
       "      <td>18.513170</td>\n",
       "      <td>20.338039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td>8</td>\n",
       "      <td>0.200046</td>\n",
       "      <td>0.879700</td>\n",
       "      <td>1.181871</td>\n",
       "      <td>1.198000</td>\n",
       "      <td>0.922419</td>\n",
       "      <td>0.885376</td>\n",
       "      <td>0.935007</td>\n",
       "      <td>0.899880</td>\n",
       "      <td>0.059137</td>\n",
       "      <td>0.239655</td>\n",
       "      <td>18.187058</td>\n",
       "      <td>19.800025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td>9</td>\n",
       "      <td>0.300019</td>\n",
       "      <td>0.862340</td>\n",
       "      <td>1.147384</td>\n",
       "      <td>1.181134</td>\n",
       "      <td>0.895503</td>\n",
       "      <td>0.870691</td>\n",
       "      <td>0.921844</td>\n",
       "      <td>0.890153</td>\n",
       "      <td>0.114707</td>\n",
       "      <td>0.354362</td>\n",
       "      <td>14.738447</td>\n",
       "      <td>18.113394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "      <td>0.400006</td>\n",
       "      <td>0.840339</td>\n",
       "      <td>1.126555</td>\n",
       "      <td>1.167491</td>\n",
       "      <td>0.879246</td>\n",
       "      <td>0.850196</td>\n",
       "      <td>0.911196</td>\n",
       "      <td>0.880166</td>\n",
       "      <td>0.112641</td>\n",
       "      <td>0.467003</td>\n",
       "      <td>12.655500</td>\n",
       "      <td>16.749116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td></td>\n",
       "      <td>11</td>\n",
       "      <td>0.500164</td>\n",
       "      <td>0.826897</td>\n",
       "      <td>1.090671</td>\n",
       "      <td>1.152108</td>\n",
       "      <td>0.851240</td>\n",
       "      <td>0.833673</td>\n",
       "      <td>0.899190</td>\n",
       "      <td>0.870855</td>\n",
       "      <td>0.109240</td>\n",
       "      <td>0.576243</td>\n",
       "      <td>9.067077</td>\n",
       "      <td>15.210779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.599994</td>\n",
       "      <td>0.813086</td>\n",
       "      <td>1.057073</td>\n",
       "      <td>1.136295</td>\n",
       "      <td>0.825018</td>\n",
       "      <td>0.819678</td>\n",
       "      <td>0.886849</td>\n",
       "      <td>0.862340</td>\n",
       "      <td>0.105528</td>\n",
       "      <td>0.681771</td>\n",
       "      <td>5.707347</td>\n",
       "      <td>13.629549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0.699996</td>\n",
       "      <td>0.796119</td>\n",
       "      <td>1.038258</td>\n",
       "      <td>1.122290</td>\n",
       "      <td>0.810333</td>\n",
       "      <td>0.805523</td>\n",
       "      <td>0.875917</td>\n",
       "      <td>0.854223</td>\n",
       "      <td>0.103827</td>\n",
       "      <td>0.785598</td>\n",
       "      <td>3.825753</td>\n",
       "      <td>12.228978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>0.799997</td>\n",
       "      <td>0.755841</td>\n",
       "      <td>0.978464</td>\n",
       "      <td>1.104311</td>\n",
       "      <td>0.763665</td>\n",
       "      <td>0.780332</td>\n",
       "      <td>0.861886</td>\n",
       "      <td>0.844987</td>\n",
       "      <td>0.097848</td>\n",
       "      <td>0.883446</td>\n",
       "      <td>-2.153645</td>\n",
       "      <td>10.431118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td></td>\n",
       "      <td>15</td>\n",
       "      <td>0.899999</td>\n",
       "      <td>0.583556</td>\n",
       "      <td>0.784636</td>\n",
       "      <td>1.068791</td>\n",
       "      <td>0.612388</td>\n",
       "      <td>0.671134</td>\n",
       "      <td>0.834163</td>\n",
       "      <td>0.825669</td>\n",
       "      <td>0.078465</td>\n",
       "      <td>0.961911</td>\n",
       "      <td>-21.536402</td>\n",
       "      <td>6.879115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td></td>\n",
       "      <td>16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.051334</td>\n",
       "      <td>0.380889</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.297274</td>\n",
       "      <td>0.372603</td>\n",
       "      <td>0.780474</td>\n",
       "      <td>0.780362</td>\n",
       "      <td>0.038089</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-61.911052</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      group  cumulative_data_fraction  lower_threshold      lift  \\\n",
       "0         1                  0.010104         0.924989  1.252318   \n",
       "1         2                  0.020009         0.918158  1.257273   \n",
       "2         3                  0.030013         0.912926  1.241062   \n",
       "3         4                  0.040003         0.909535  1.233683   \n",
       "4         5                  0.050022         0.906824  1.231994   \n",
       "5         6                  0.100558         0.898139  1.181768   \n",
       "6         7                  0.150009         0.890913  1.185132   \n",
       "7         8                  0.200046         0.879700  1.181871   \n",
       "8         9                  0.300019         0.862340  1.147384   \n",
       "9        10                  0.400006         0.840339  1.126555   \n",
       "10       11                  0.500164         0.826897  1.090671   \n",
       "11       12                  0.599994         0.813086  1.057073   \n",
       "12       13                  0.699996         0.796119  1.038258   \n",
       "13       14                  0.799997         0.755841  0.978464   \n",
       "14       15                  0.899999         0.583556  0.784636   \n",
       "15       16                  1.000000         0.051334  0.380889   \n",
       "\n",
       "    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n",
       "0          1.252318       0.977401  0.932727                  0.977401   \n",
       "1          1.254771       0.981268  0.921049                  0.979315   \n",
       "2          1.250201       0.968616  0.915329                  0.975749   \n",
       "3          1.246076       0.962857  0.911191                  0.972529   \n",
       "4          1.243256       0.961538  0.908034                  0.970328   \n",
       "5          1.212355       0.922338  0.902074                  0.946211   \n",
       "6          1.203380       0.924964  0.894299                  0.939207   \n",
       "7          1.198000       0.922419  0.885376                  0.935007   \n",
       "8          1.181134       0.895503  0.870691                  0.921844   \n",
       "9          1.167491       0.879246  0.850196                  0.911196   \n",
       "10         1.152108       0.851240  0.833673                  0.899190   \n",
       "11         1.136295       0.825018  0.819678                  0.886849   \n",
       "12         1.122290       0.810333  0.805523                  0.875917   \n",
       "13         1.104311       0.763665  0.780332                  0.861886   \n",
       "14         1.068791       0.612388  0.671134                  0.834163   \n",
       "15         1.000000       0.297274  0.372603                  0.780474   \n",
       "\n",
       "    cumulative_score  capture_rate  cumulative_capture_rate       gain  \\\n",
       "0           0.932727      0.012654                 0.012654  25.231810   \n",
       "1           0.926947      0.012453                 0.025107  25.727263   \n",
       "2           0.923074      0.012416                 0.037523  24.106228   \n",
       "3           0.920107      0.012325                 0.049847  23.368327   \n",
       "4           0.917689      0.012343                 0.062190  23.199368   \n",
       "5           0.909841      0.059722                 0.121912  18.176758   \n",
       "6           0.904718      0.058606                 0.180518  18.513170   \n",
       "7           0.899880      0.059137                 0.239655  18.187058   \n",
       "8           0.890153      0.114707                 0.354362  14.738447   \n",
       "9           0.880166      0.112641                 0.467003  12.655500   \n",
       "10          0.870855      0.109240                 0.576243   9.067077   \n",
       "11          0.862340      0.105528                 0.681771   5.707347   \n",
       "12          0.854223      0.103827                 0.785598   3.825753   \n",
       "13          0.844987      0.097848                 0.883446  -2.153645   \n",
       "14          0.825669      0.078465                 0.961911 -21.536402   \n",
       "15          0.780362      0.038089                 1.000000 -61.911052   \n",
       "\n",
       "    cumulative_gain  \n",
       "0         25.231810  \n",
       "1         25.477063  \n",
       "2         25.020118  \n",
       "3         24.607612  \n",
       "4         24.325562  \n",
       "5         21.235452  \n",
       "6         20.338039  \n",
       "7         19.800025  \n",
       "8         18.113394  \n",
       "9         16.749116  \n",
       "10        15.210779  \n",
       "11        13.629549  \n",
       "12        12.228978  \n",
       "13        10.431118  \n",
       "14         6.879115  \n",
       "15         0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on validation data. **\n",
      "\n",
      "MSE: 0.14010161942162935\n",
      "RMSE: 0.37430150870872714\n",
      "LogLoss: 0.44731859995415363\n",
      "Mean Per-Class Error: 0.33506928943763836\n",
      "AUC: 0.7253435703790653\n",
      "AUCPR: 0.8884157242391383\n",
      "Gini: 0.45068714075813054\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5293909234372814: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>Error</th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>815.0</td>\n",
       "      <td>2394.0</td>\n",
       "      <td>0.746</td>\n",
       "      <td>(2394.0/3209.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>351.0</td>\n",
       "      <td>11467.0</td>\n",
       "      <td>0.0297</td>\n",
       "      <td>(351.0/11818.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total</td>\n",
       "      <td>1166.0</td>\n",
       "      <td>13861.0</td>\n",
       "      <td>0.1827</td>\n",
       "      <td>(2745.0/15027.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0        1   Error               Rate\n",
       "0      0   815.0   2394.0   0.746    (2394.0/3209.0)\n",
       "1      1   351.0  11467.0  0.0297    (351.0/11818.0)\n",
       "2  Total  1166.0  13861.0  0.1827   (2745.0/15027.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>threshold</th>\n",
       "      <th>value</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>max f1</td>\n",
       "      <td>0.529391</td>\n",
       "      <td>0.893103</td>\n",
       "      <td>270.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max f2</td>\n",
       "      <td>0.223306</td>\n",
       "      <td>0.950538</td>\n",
       "      <td>361.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>max f0point5</td>\n",
       "      <td>0.676740</td>\n",
       "      <td>0.861144</td>\n",
       "      <td>207.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>max accuracy</td>\n",
       "      <td>0.547632</td>\n",
       "      <td>0.817795</td>\n",
       "      <td>264.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max precision</td>\n",
       "      <td>0.955967</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>max recall</td>\n",
       "      <td>0.100830</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>394.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>max specificity</td>\n",
       "      <td>0.955967</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>max absolute_mcc</td>\n",
       "      <td>0.628474</td>\n",
       "      <td>0.363205</td>\n",
       "      <td>227.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>max min_per_class_accuracy</td>\n",
       "      <td>0.815424</td>\n",
       "      <td>0.650670</td>\n",
       "      <td>122.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max mean_per_class_accuracy</td>\n",
       "      <td>0.758485</td>\n",
       "      <td>0.664931</td>\n",
       "      <td>171.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>max tns</td>\n",
       "      <td>0.955967</td>\n",
       "      <td>3209.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>max fns</td>\n",
       "      <td>0.955967</td>\n",
       "      <td>11814.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>max fps</td>\n",
       "      <td>0.070035</td>\n",
       "      <td>3209.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>max tps</td>\n",
       "      <td>0.100830</td>\n",
       "      <td>11818.000000</td>\n",
       "      <td>394.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>max tnr</td>\n",
       "      <td>0.955967</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>max fnr</td>\n",
       "      <td>0.955967</td>\n",
       "      <td>0.999662</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>max fpr</td>\n",
       "      <td>0.070035</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>max tpr</td>\n",
       "      <td>0.100830</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>394.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         metric  threshold         value    idx\n",
       "0                        max f1   0.529391      0.893103  270.0\n",
       "1                        max f2   0.223306      0.950538  361.0\n",
       "2                  max f0point5   0.676740      0.861144  207.0\n",
       "3                  max accuracy   0.547632      0.817795  264.0\n",
       "4                 max precision   0.955967      1.000000    0.0\n",
       "5                    max recall   0.100830      1.000000  394.0\n",
       "6               max specificity   0.955967      1.000000    0.0\n",
       "7              max absolute_mcc   0.628474      0.363205  227.0\n",
       "8    max min_per_class_accuracy   0.815424      0.650670  122.0\n",
       "9   max mean_per_class_accuracy   0.758485      0.664931  171.0\n",
       "10                      max tns   0.955967   3209.000000    0.0\n",
       "11                      max fns   0.955967  11814.000000    0.0\n",
       "12                      max fps   0.070035   3209.000000  399.0\n",
       "13                      max tps   0.100830  11818.000000  394.0\n",
       "14                      max tnr   0.955967      1.000000    0.0\n",
       "15                      max fnr   0.955967      0.999662    0.0\n",
       "16                      max fpr   0.070035      1.000000  399.0\n",
       "17                      max tpr   0.100830      1.000000  394.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate: 78.65 %, avg score: 78.26 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>cumulative_data_fraction</th>\n",
       "      <th>lower_threshold</th>\n",
       "      <th>lift</th>\n",
       "      <th>cumulative_lift</th>\n",
       "      <th>response_rate</th>\n",
       "      <th>score</th>\n",
       "      <th>cumulative_response_rate</th>\n",
       "      <th>cumulative_score</th>\n",
       "      <th>capture_rate</th>\n",
       "      <th>cumulative_capture_rate</th>\n",
       "      <th>gain</th>\n",
       "      <th>cumulative_gain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0.010248</td>\n",
       "      <td>0.925587</td>\n",
       "      <td>1.180711</td>\n",
       "      <td>1.180711</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.932862</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.932862</td>\n",
       "      <td>0.012100</td>\n",
       "      <td>0.012100</td>\n",
       "      <td>18.071102</td>\n",
       "      <td>18.071102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>0.020031</td>\n",
       "      <td>0.918965</td>\n",
       "      <td>1.159086</td>\n",
       "      <td>1.170150</td>\n",
       "      <td>0.911565</td>\n",
       "      <td>0.921641</td>\n",
       "      <td>0.920266</td>\n",
       "      <td>0.927382</td>\n",
       "      <td>0.011339</td>\n",
       "      <td>0.023439</td>\n",
       "      <td>15.908628</td>\n",
       "      <td>17.015010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>0.030013</td>\n",
       "      <td>0.914012</td>\n",
       "      <td>1.229150</td>\n",
       "      <td>1.189773</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.916564</td>\n",
       "      <td>0.935698</td>\n",
       "      <td>0.923784</td>\n",
       "      <td>0.012269</td>\n",
       "      <td>0.035708</td>\n",
       "      <td>22.915045</td>\n",
       "      <td>18.977328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>0.040061</td>\n",
       "      <td>0.910137</td>\n",
       "      <td>1.187327</td>\n",
       "      <td>1.189160</td>\n",
       "      <td>0.933775</td>\n",
       "      <td>0.911782</td>\n",
       "      <td>0.935216</td>\n",
       "      <td>0.920773</td>\n",
       "      <td>0.011931</td>\n",
       "      <td>0.047639</td>\n",
       "      <td>18.732733</td>\n",
       "      <td>18.915976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "      <td>0.050043</td>\n",
       "      <td>0.907199</td>\n",
       "      <td>1.186766</td>\n",
       "      <td>1.188682</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.908498</td>\n",
       "      <td>0.934840</td>\n",
       "      <td>0.918325</td>\n",
       "      <td>0.011846</td>\n",
       "      <td>0.059486</td>\n",
       "      <td>18.676595</td>\n",
       "      <td>18.868227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>6</td>\n",
       "      <td>0.100020</td>\n",
       "      <td>0.898441</td>\n",
       "      <td>1.169948</td>\n",
       "      <td>1.179321</td>\n",
       "      <td>0.920107</td>\n",
       "      <td>0.902651</td>\n",
       "      <td>0.927478</td>\n",
       "      <td>0.910493</td>\n",
       "      <td>0.058470</td>\n",
       "      <td>0.117956</td>\n",
       "      <td>16.994760</td>\n",
       "      <td>17.932117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>7</td>\n",
       "      <td>0.149997</td>\n",
       "      <td>0.891179</td>\n",
       "      <td>1.171641</td>\n",
       "      <td>1.176762</td>\n",
       "      <td>0.921438</td>\n",
       "      <td>0.894593</td>\n",
       "      <td>0.925466</td>\n",
       "      <td>0.905196</td>\n",
       "      <td>0.058555</td>\n",
       "      <td>0.176510</td>\n",
       "      <td>17.164072</td>\n",
       "      <td>17.676216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td>8</td>\n",
       "      <td>0.200173</td>\n",
       "      <td>0.880322</td>\n",
       "      <td>1.113015</td>\n",
       "      <td>1.160783</td>\n",
       "      <td>0.875332</td>\n",
       "      <td>0.885700</td>\n",
       "      <td>0.912899</td>\n",
       "      <td>0.900309</td>\n",
       "      <td>0.055847</td>\n",
       "      <td>0.232357</td>\n",
       "      <td>11.301467</td>\n",
       "      <td>16.078290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td>9</td>\n",
       "      <td>0.300060</td>\n",
       "      <td>0.862415</td>\n",
       "      <td>1.128371</td>\n",
       "      <td>1.149993</td>\n",
       "      <td>0.887408</td>\n",
       "      <td>0.870917</td>\n",
       "      <td>0.904413</td>\n",
       "      <td>0.890524</td>\n",
       "      <td>0.112709</td>\n",
       "      <td>0.345067</td>\n",
       "      <td>12.837079</td>\n",
       "      <td>14.999324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "      <td>0.400013</td>\n",
       "      <td>0.841646</td>\n",
       "      <td>1.098836</td>\n",
       "      <td>1.137210</td>\n",
       "      <td>0.864181</td>\n",
       "      <td>0.850913</td>\n",
       "      <td>0.894360</td>\n",
       "      <td>0.880627</td>\n",
       "      <td>0.109832</td>\n",
       "      <td>0.454899</td>\n",
       "      <td>9.883646</td>\n",
       "      <td>13.721043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td></td>\n",
       "      <td>11</td>\n",
       "      <td>0.500033</td>\n",
       "      <td>0.828395</td>\n",
       "      <td>1.074417</td>\n",
       "      <td>1.124650</td>\n",
       "      <td>0.844977</td>\n",
       "      <td>0.834816</td>\n",
       "      <td>0.884482</td>\n",
       "      <td>0.871463</td>\n",
       "      <td>0.107463</td>\n",
       "      <td>0.562362</td>\n",
       "      <td>7.441742</td>\n",
       "      <td>12.465015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.599987</td>\n",
       "      <td>0.813924</td>\n",
       "      <td>1.033651</td>\n",
       "      <td>1.109490</td>\n",
       "      <td>0.812916</td>\n",
       "      <td>0.820910</td>\n",
       "      <td>0.872560</td>\n",
       "      <td>0.863041</td>\n",
       "      <td>0.103317</td>\n",
       "      <td>0.665679</td>\n",
       "      <td>3.365124</td>\n",
       "      <td>10.949040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0.700007</td>\n",
       "      <td>0.797481</td>\n",
       "      <td>1.030426</td>\n",
       "      <td>1.098193</td>\n",
       "      <td>0.810379</td>\n",
       "      <td>0.806804</td>\n",
       "      <td>0.863675</td>\n",
       "      <td>0.855006</td>\n",
       "      <td>0.103063</td>\n",
       "      <td>0.768743</td>\n",
       "      <td>3.042553</td>\n",
       "      <td>9.819327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>0.799960</td>\n",
       "      <td>0.759055</td>\n",
       "      <td>1.016720</td>\n",
       "      <td>1.088013</td>\n",
       "      <td>0.799601</td>\n",
       "      <td>0.782696</td>\n",
       "      <td>0.855669</td>\n",
       "      <td>0.845971</td>\n",
       "      <td>0.101625</td>\n",
       "      <td>0.870367</td>\n",
       "      <td>1.672002</td>\n",
       "      <td>8.801335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td></td>\n",
       "      <td>15</td>\n",
       "      <td>0.899980</td>\n",
       "      <td>0.588211</td>\n",
       "      <td>0.855304</td>\n",
       "      <td>1.062151</td>\n",
       "      <td>0.672655</td>\n",
       "      <td>0.676076</td>\n",
       "      <td>0.835330</td>\n",
       "      <td>0.827090</td>\n",
       "      <td>0.085547</td>\n",
       "      <td>0.955915</td>\n",
       "      <td>-14.469605</td>\n",
       "      <td>6.215101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td></td>\n",
       "      <td>16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.067556</td>\n",
       "      <td>0.440765</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.346640</td>\n",
       "      <td>0.382432</td>\n",
       "      <td>0.786451</td>\n",
       "      <td>0.782615</td>\n",
       "      <td>0.044085</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-55.923506</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      group  cumulative_data_fraction  lower_threshold      lift  \\\n",
       "0         1                  0.010248         0.925587  1.180711   \n",
       "1         2                  0.020031         0.918965  1.159086   \n",
       "2         3                  0.030013         0.914012  1.229150   \n",
       "3         4                  0.040061         0.910137  1.187327   \n",
       "4         5                  0.050043         0.907199  1.186766   \n",
       "5         6                  0.100020         0.898441  1.169948   \n",
       "6         7                  0.149997         0.891179  1.171641   \n",
       "7         8                  0.200173         0.880322  1.113015   \n",
       "8         9                  0.300060         0.862415  1.128371   \n",
       "9        10                  0.400013         0.841646  1.098836   \n",
       "10       11                  0.500033         0.828395  1.074417   \n",
       "11       12                  0.599987         0.813924  1.033651   \n",
       "12       13                  0.700007         0.797481  1.030426   \n",
       "13       14                  0.799960         0.759055  1.016720   \n",
       "14       15                  0.899980         0.588211  0.855304   \n",
       "15       16                  1.000000         0.067556  0.440765   \n",
       "\n",
       "    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n",
       "0          1.180711       0.928571  0.932862                  0.928571   \n",
       "1          1.170150       0.911565  0.921641                  0.920266   \n",
       "2          1.189773       0.966667  0.916564                  0.935698   \n",
       "3          1.189160       0.933775  0.911782                  0.935216   \n",
       "4          1.188682       0.933333  0.908498                  0.934840   \n",
       "5          1.179321       0.920107  0.902651                  0.927478   \n",
       "6          1.176762       0.921438  0.894593                  0.925466   \n",
       "7          1.160783       0.875332  0.885700                  0.912899   \n",
       "8          1.149993       0.887408  0.870917                  0.904413   \n",
       "9          1.137210       0.864181  0.850913                  0.894360   \n",
       "10         1.124650       0.844977  0.834816                  0.884482   \n",
       "11         1.109490       0.812916  0.820910                  0.872560   \n",
       "12         1.098193       0.810379  0.806804                  0.863675   \n",
       "13         1.088013       0.799601  0.782696                  0.855669   \n",
       "14         1.062151       0.672655  0.676076                  0.835330   \n",
       "15         1.000000       0.346640  0.382432                  0.786451   \n",
       "\n",
       "    cumulative_score  capture_rate  cumulative_capture_rate       gain  \\\n",
       "0           0.932862      0.012100                 0.012100  18.071102   \n",
       "1           0.927382      0.011339                 0.023439  15.908628   \n",
       "2           0.923784      0.012269                 0.035708  22.915045   \n",
       "3           0.920773      0.011931                 0.047639  18.732733   \n",
       "4           0.918325      0.011846                 0.059486  18.676595   \n",
       "5           0.910493      0.058470                 0.117956  16.994760   \n",
       "6           0.905196      0.058555                 0.176510  17.164072   \n",
       "7           0.900309      0.055847                 0.232357  11.301467   \n",
       "8           0.890524      0.112709                 0.345067  12.837079   \n",
       "9           0.880627      0.109832                 0.454899   9.883646   \n",
       "10          0.871463      0.107463                 0.562362   7.441742   \n",
       "11          0.863041      0.103317                 0.665679   3.365124   \n",
       "12          0.855006      0.103063                 0.768743   3.042553   \n",
       "13          0.845971      0.101625                 0.870367   1.672002   \n",
       "14          0.827090      0.085547                 0.955915 -14.469605   \n",
       "15          0.782615      0.044085                 1.000000 -55.923506   \n",
       "\n",
       "    cumulative_gain  \n",
       "0         18.071102  \n",
       "1         17.015010  \n",
       "2         18.977328  \n",
       "3         18.915976  \n",
       "4         18.868227  \n",
       "5         17.932117  \n",
       "6         17.676216  \n",
       "7         16.078290  \n",
       "8         14.999324  \n",
       "9         13.721043  \n",
       "10        12.465015  \n",
       "11        10.949040  \n",
       "12         9.819327  \n",
       "13         8.801335  \n",
       "14         6.215101  \n",
       "15         0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>duration</th>\n",
       "      <th>number_of_trees</th>\n",
       "      <th>training_rmse</th>\n",
       "      <th>training_logloss</th>\n",
       "      <th>training_auc</th>\n",
       "      <th>training_pr_auc</th>\n",
       "      <th>training_lift</th>\n",
       "      <th>training_classification_error</th>\n",
       "      <th>validation_rmse</th>\n",
       "      <th>validation_logloss</th>\n",
       "      <th>validation_auc</th>\n",
       "      <th>validation_pr_auc</th>\n",
       "      <th>validation_lift</th>\n",
       "      <th>validation_classification_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>2020-06-03 01:33:00</td>\n",
       "      <td>0.299 sec</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.413926</td>\n",
       "      <td>0.526308</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.219526</td>\n",
       "      <td>0.409855</td>\n",
       "      <td>0.518726</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.213549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>2020-06-03 01:33:02</td>\n",
       "      <td>2.097 sec</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.386435</td>\n",
       "      <td>0.470508</td>\n",
       "      <td>0.722491</td>\n",
       "      <td>0.884999</td>\n",
       "      <td>1.227059</td>\n",
       "      <td>0.188900</td>\n",
       "      <td>0.385758</td>\n",
       "      <td>0.469681</td>\n",
       "      <td>0.705835</td>\n",
       "      <td>0.878798</td>\n",
       "      <td>1.157423</td>\n",
       "      <td>0.189858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>2020-06-03 01:33:03</td>\n",
       "      <td>3.070 sec</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.377717</td>\n",
       "      <td>0.453923</td>\n",
       "      <td>0.734573</td>\n",
       "      <td>0.889451</td>\n",
       "      <td>1.237656</td>\n",
       "      <td>0.184432</td>\n",
       "      <td>0.378298</td>\n",
       "      <td>0.455566</td>\n",
       "      <td>0.716284</td>\n",
       "      <td>0.883222</td>\n",
       "      <td>1.163496</td>\n",
       "      <td>0.184668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>2020-06-03 01:33:04</td>\n",
       "      <td>3.858 sec</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.373774</td>\n",
       "      <td>0.445501</td>\n",
       "      <td>0.748326</td>\n",
       "      <td>0.898008</td>\n",
       "      <td>1.248373</td>\n",
       "      <td>0.182235</td>\n",
       "      <td>0.375929</td>\n",
       "      <td>0.450681</td>\n",
       "      <td>0.721199</td>\n",
       "      <td>0.886699</td>\n",
       "      <td>1.162785</td>\n",
       "      <td>0.185200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>2020-06-03 01:33:04</td>\n",
       "      <td>4.468 sec</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.371823</td>\n",
       "      <td>0.441510</td>\n",
       "      <td>0.753473</td>\n",
       "      <td>0.900183</td>\n",
       "      <td>1.244874</td>\n",
       "      <td>0.180736</td>\n",
       "      <td>0.374793</td>\n",
       "      <td>0.448388</td>\n",
       "      <td>0.723046</td>\n",
       "      <td>0.887753</td>\n",
       "      <td>1.180711</td>\n",
       "      <td>0.185000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>2020-06-03 01:33:05</td>\n",
       "      <td>4.935 sec</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.369075</td>\n",
       "      <td>0.435739</td>\n",
       "      <td>0.765185</td>\n",
       "      <td>0.906083</td>\n",
       "      <td>1.252318</td>\n",
       "      <td>0.178995</td>\n",
       "      <td>0.374302</td>\n",
       "      <td>0.447319</td>\n",
       "      <td>0.725344</td>\n",
       "      <td>0.888416</td>\n",
       "      <td>1.180711</td>\n",
       "      <td>0.182671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               timestamp    duration  number_of_trees  training_rmse  \\\n",
       "0    2020-06-03 01:33:00   0.299 sec              0.0       0.413926   \n",
       "1    2020-06-03 01:33:02   2.097 sec             10.0       0.386435   \n",
       "2    2020-06-03 01:33:03   3.070 sec             20.0       0.377717   \n",
       "3    2020-06-03 01:33:04   3.858 sec             30.0       0.373774   \n",
       "4    2020-06-03 01:33:04   4.468 sec             40.0       0.371823   \n",
       "5    2020-06-03 01:33:05   4.935 sec             50.0       0.369075   \n",
       "\n",
       "   training_logloss  training_auc  training_pr_auc  training_lift  \\\n",
       "0          0.526308      0.500000         0.000000       1.000000   \n",
       "1          0.470508      0.722491         0.884999       1.227059   \n",
       "2          0.453923      0.734573         0.889451       1.237656   \n",
       "3          0.445501      0.748326         0.898008       1.248373   \n",
       "4          0.441510      0.753473         0.900183       1.244874   \n",
       "5          0.435739      0.765185         0.906083       1.252318   \n",
       "\n",
       "   training_classification_error  validation_rmse  validation_logloss  \\\n",
       "0                       0.219526         0.409855            0.518726   \n",
       "1                       0.188900         0.385758            0.469681   \n",
       "2                       0.184432         0.378298            0.455566   \n",
       "3                       0.182235         0.375929            0.450681   \n",
       "4                       0.180736         0.374793            0.448388   \n",
       "5                       0.178995         0.374302            0.447319   \n",
       "\n",
       "   validation_auc  validation_pr_auc  validation_lift  \\\n",
       "0        0.500000           0.000000         1.000000   \n",
       "1        0.705835           0.878798         1.157423   \n",
       "2        0.716284           0.883222         1.163496   \n",
       "3        0.721199           0.886699         1.162785   \n",
       "4        0.723046           0.887753         1.180711   \n",
       "5        0.725344           0.888416         1.180711   \n",
       "\n",
       "   validation_classification_error  \n",
       "0                         0.213549  \n",
       "1                         0.189858  \n",
       "2                         0.184668  \n",
       "3                         0.185200  \n",
       "4                         0.185000  \n",
       "5                         0.182671  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>relative_importance</th>\n",
       "      <th>scaled_importance</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HelpfulnessNumerator</td>\n",
       "      <td>5348.876465</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.421513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HelpfulnessDenominator</td>\n",
       "      <td>4189.913086</td>\n",
       "      <td>0.783326</td>\n",
       "      <td>0.330182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Time</td>\n",
       "      <td>1458.333862</td>\n",
       "      <td>0.272643</td>\n",
       "      <td>0.114922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ProductId</td>\n",
       "      <td>1350.541504</td>\n",
       "      <td>0.252491</td>\n",
       "      <td>0.106428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UserId</td>\n",
       "      <td>342.052032</td>\n",
       "      <td>0.063948</td>\n",
       "      <td>0.026955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 variable  relative_importance  scaled_importance  percentage\n",
       "0    HelpfulnessNumerator          5348.876465           1.000000    0.421513\n",
       "1  HelpfulnessDenominator          4189.913086           0.783326    0.330182\n",
       "2                    Time          1458.333862           0.272643    0.114922\n",
       "3               ProductId          1350.541504           0.252491    0.106428\n",
       "4                  UserId           342.052032           0.063948    0.026955"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from h2o.estimators import H2OGradientBoostingEstimator\n",
    "from splicemachine.mlflow_support.utilities import get_user\n",
    "\n",
    "RATIOS = [0.7,0.15]\n",
    "\n",
    "# Start our run to keep track of important information\n",
    "mlflow.start_run(run_name='simple_run')\n",
    "\n",
    "predictors = ['ProductId', 'UserId', 'HelpfulnessNumerator', 'HelpfulnessDenominator', 'Time']\n",
    "response = 'PositiveReview'\n",
    "\n",
    "# lp is short for log_param\n",
    "# lm is short for log_metric\n",
    "mlflow.lp('predictors', predictors)\n",
    "mlflow.lp('label', response)\n",
    "mlflow.lp('source data table', f'{get_user()}.AMAZON_REVIEWS')\n",
    "\n",
    "# Train Test Split\n",
    "train,test,valid = reviews.split_frame(ratios=RATIOS)\n",
    "# Log our ratios\n",
    "mlflow.lp('ratios',RATIOS)\n",
    "\n",
    "gbm_baseline = H2OGradientBoostingEstimator(stopping_metric = \"AUC\", stopping_tolerance = 0.001,\n",
    "                                            stopping_rounds = 5, score_tree_interval = 10,\n",
    "                                            model_id = \"gbm_baseline.hex\"\n",
    "                                           )\n",
    "\n",
    "mlflow.lp('model_type', gbm_baseline.__class__)\n",
    "\n",
    "# Code block to time training\n",
    "with mlflow.timer('train_time'):\n",
    "    gbm_baseline.train(x = predictors, y = response, \n",
    "                       training_frame = train, validation_frame = test\n",
    "                      )\n",
    "# Log the model params to mlflow\n",
    "mlflow.log_params(gbm_baseline.get_params())\n",
    "# Log the model to MLFlow\n",
    "mlflow.log_model(gbm_baseline, 'baseline_model')\n",
    "# Log the training notebook to MLFlow\n",
    "mlflow.log_artifact('MLManager H2O Demo.ipynb', 'training_notebook')\n",
    "gbm_baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You can see above that H2O gives you loads of details about your model. Let's inspect it a bit more and log some results to MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>number_of_trees</th>\n",
       "      <th>number_of_internal_trees</th>\n",
       "      <th>model_size_in_bytes</th>\n",
       "      <th>min_depth</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>mean_depth</th>\n",
       "      <th>min_leaves</th>\n",
       "      <th>max_leaves</th>\n",
       "      <th>mean_leaves</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>25639.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>29.96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     number_of_trees  number_of_internal_trees  model_size_in_bytes  \\\n",
       "0               50.0                      50.0              25639.0   \n",
       "\n",
       "   min_depth  max_depth  mean_depth  min_leaves  max_leaves  mean_leaves  \n",
       "0        5.0        5.0         5.0        17.0        32.0        29.96  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline  \n",
    "\n",
    "# Print and Log Model params\n",
    "params = dict(zip(gbm_baseline.summary().col_header[1:],\n",
    "                    gbm_baseline.summary().cell_values[0][1:]))\n",
    "print(gbm_baseline.summary())\n",
    "mlflow.log_params(params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC on Validation Data: 0.725\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<font size=\"+2\">See your metrics plot <a href=/mlflow/#/metric/training_auc?runs=[\"8526fc619d91\"]&experiment=1&plot_metric_keys=[\"training_logloss\",\"validation_logloss\",\"training_rmse\",\"validation_rmse\"]>here</a></font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "#Plot and Log Scoring history\n",
    "gbm_baseline.plot()\n",
    "print(\"AUC on Validation Data: \" + str(round(gbm_baseline.auc(valid = True), 3)))\n",
    "# Log training and validation metrics over time\n",
    "for step, row in gbm_baseline.scoring_history().iterrows():\n",
    "    row_dict = row.to_dict()\n",
    "    for r in row_dict:\n",
    "        if 'train' in r or 'valid' in r:\n",
    "            mlflow.log_metric(r, row_dict[r],step=step)\n",
    "\n",
    "cur_run = mlflow.current_run_id()\n",
    "cur_exp = mlflow.current_exp_id()\n",
    "link = f'/mlflow/#/metric/training_auc?runs=[\"{cur_run}\"]&experiment={cur_exp}&plot_metric_keys=[\"training_logloss\",\\\"validation_logloss\\\",\\\"training_rmse\\\",\\\"validation_rmse\\\"]'\n",
    "HTML(f'<font size=\"+2\">See your metrics plot <a href={link}>here</a></font>') \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5293909234372814: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>Error</th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>815.0</td>\n",
       "      <td>2394.0</td>\n",
       "      <td>0.746</td>\n",
       "      <td>(2394.0/3209.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>351.0</td>\n",
       "      <td>11467.0</td>\n",
       "      <td>0.0297</td>\n",
       "      <td>(351.0/11818.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total</td>\n",
       "      <td>1166.0</td>\n",
       "      <td>13861.0</td>\n",
       "      <td>0.1827</td>\n",
       "      <td>(2745.0/15027.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0        1   Error               Rate\n",
       "0      0   815.0   2394.0   0.746    (2394.0/3209.0)\n",
       "1      1   351.0  11467.0  0.0297    (351.0/11818.0)\n",
       "2  Total  1166.0  13861.0  0.1827   (2745.0/15027.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Print and Log Confusion Matrix\n",
    "print(gbm_baseline.confusion_matrix(valid = True))\n",
    "mlflow.lm('fpr', gbm_baseline.fpr(valid=True)[0][0])\n",
    "mlflow.lm('tpr', gbm_baseline.tpr(valid=True)[0][0])\n",
    "mlflow.lm('fnr', gbm_baseline.fnr(valid=True)[0][0])\n",
    "mlflow.lm('tnr', gbm_baseline.fnr(valid=True)[0][0])\n",
    "mlflow.lm('F0point5', gbm_baseline.F0point5(valid=True)[0][1])\n",
    "mlflow.lm('F1', gbm_baseline.F1(valid=True)[0][1])\n",
    "mlflow.lm('F2', gbm_baseline.F2(valid=True)[0][1])\n",
    "mlflow.lm('auc', gbm_baseline.auc(valid = True))\n",
    "mlflow.lp('threshold', gbm_baseline.F1(valid=True)[0][0]) # First element is the threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot and Log Variable Importance\n",
    "gbm_baseline.varimp_plot()\n",
    "for var in gbm_baseline.varimp():\n",
    "    mlflow.lm(f'varimp_{var[0]}',var[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PartialDependencePlot progress: |█████████████████████████████████████████| 100%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Partial Dependence Plot\n",
    "pdp_helpfulness = gbm_baseline.partial_plot(train, cols = [\"HelpfulnessNumerator\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# There is room for improvement \n",
    "## Let's now Tokenize words in the Review\n",
    "### But first, let's start our new run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['all', 'just', 'being', 'over', 'both', 'through', 'yourselves', 'its', 'before', 'o', 'hadn', 'herself', 'll', 'had', 'should', 'to', 'only', 'won', 'under', 'ours', 'has', 'do', 'them', 'his', 'very', 'they', 'not', 'during', 'now', 'him', 'nor', 'd', 'did', 'didn', 'this', 'she', 'each', 'further', 'where', 'few', 'because', 'doing', 'some', 'hasn', 'are', 'our', 'ourselves', 'out', 'what', 'for', 'while', 're', 'does', 'above', 'between', 'mustn', 't', 'be', 'we', 'who', 'were', 'here', 'shouldn', 'hers', 'by', 'on', 'about', 'couldn', 'of', 'against', 's', 'isn', 'or', 'own', 'into', 'yourself', 'down', 'mightn', 'wasn', 'your', 'from', 'her', 'their', 'aren', 'there', 'been', 'whom', 'too', 'wouldn', 'themselves', 'weren', 'was', 'until', 'more', 'himself', 'that', 'but', 'don', 'with', 'than', 'those', 'he', 'me', 'myself', 'ma', 'these', 'up', 'will', 'below', 'ain', 'can', 'theirs', 'my', 'and', 've', 'then', 'is', 'am', 'it', 'doesn', 'an', 'as', 'itself', 'at', 'have', 'in', 'any', 'if', 'again', 'no', 'when', 'same', 'how', 'other', 'which', 'you', 'shan', 'needn', 'haven', 'after', 'most', 'such', 'why', 'a', 'off', 'i', 'm', 'yours', 'so', 'y', 'the', 'having', 'once']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Start new mlflow run\n",
    "mlflow.start_run(run_name='review_tokenizer')\n",
    "mlflow.lp('source data table', f'{get_user()}.AMAZON_REVIEWS')\n",
    "# Get common stop words from H2O\n",
    "data_path = \"https://splice-demo.s3.amazonaws.com/stop_words.csv\"\n",
    "STOP_WORDS = pd.read_csv(data_path, header=0)\n",
    "STOP_WORDS = list(STOP_WORDS['STOP_WORD'])\n",
    "print(STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>Text                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>These are made in China (do not buy ANY pet food from China).  Dogswell has been using propylene glycol to soften their treats (what are they thinkng?).  Do not purchase or support this company in any way until they clean up their act.  And for whatever reason Amazon doesn&#x27;t allow returns of this item, so I had to toss mine out.  Bad business all around on this one.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            </td></tr>\n",
       "<tr><td>Everything is ok, except it just isn&#x27;t as good as it is in the bags.  Just considerably more bland -- less lemon and less zing.  Boring.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </td></tr>\n",
       "<tr><td>Best cat treat ever. There isn&#x27;t anything comparable to the love my cat has for these treats, he snubs away any other kind now.&lt;br /&gt;I know he likes to manipulate me with his cattiness but these treats are my way of manipulating him to come sit on my lap and have some chill time. :)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 </td></tr>\n",
       "<tr><td>My two Corgis were thoroughly spoiled by my late husband (I spent a year and a half dieting them down a combined total of 25 pounds!)&lt;br /&gt;&lt;br /&gt;They are accustomed to the finest of fare, and they absolutely love the Wellness brand of treats.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          </td></tr>\n",
       "<tr><td>We used to have drive down to the specialty pet food store for this product.  So glad we discovered Amazon.  As far as I can tell it is no more expensive &amp; in some cases less - Prime membership is awesome.  Loving Pets treats are some of the best according to my dog.  They do not develop that nasty smell like some dog treats do.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  </td></tr>\n",
       "<tr><td>I really liked this coffee, it was just as good as everyone claimed it was.  Strong, bold and flavorful!  I would recommend!                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                </td></tr>\n",
       "<tr><td>I am always looking for healthier, whole grain versions of foods I enjoy.  Unfortunately, these Peacock brand noodles are yet another food masquerading as healthy.  The product title in big letters on the front says &quot;Brown Rice Vermicelli&quot;, making the consumer think &quot;this is made with brown rice, so it should be a healthy choice&quot;.  But the first indication that it is not is when looking at the fiber content on the nutrition facts - only 0.6g per 2oz serving.  Then onto the ingredients list to see why so low... contains brown rice, sago starch and water.  The sago starch comes from palms and must not have much (if any) fiber.&lt;br /&gt;&lt;br /&gt;The Annie Chun&#x27;s Maifun Brown Rice Noodles (sold on Amazon and in my local healthy grocer) has become one of my staples and is my frame of reference when comparing to the Peacock brand.  The Annie Chun&#x27;s product is made with 100% whole grain, with ingredients brown rice flour and water.  Per 2oz serving, it has 4g fiber and pretty much the same calories and other nutrients as the Peacock brand.&lt;br /&gt;&lt;br /&gt;If you do try this Peacock brand noodles and have not used rice noodles before, you will need to seek guidance elsewhere on preparation.  As others have pointed out, the Peacock package gives almost no directions on how to prepare the product, aside from a brief mention in the recipes (in the header text it does say that they are &quot;easy-to-cook&quot; but does not say how).  It also contains a very strange recipe for rice noodles: Aglio Olio style - this is an Italian recipe for noodles with olive oil/garlic/sprinkled with grated cheese that I think would not be very tasty.  The second recipe appears to be for a soup with veggie strips.  Neither recipe gives amounts or much direction.  In comparison, the Annie Chun&#x27;s package gives clear, specific directions on rice noodle preparation and two recipes.&lt;br /&gt;&lt;br /&gt;I use rice noodles = maifun = rice sticks = sometimes called vermicelli for making the Vietnamese salad &quot;bun tofu&quot;, to serve with stir-fried veggies or in lettuce rolls.  They can also be used in spring rolls/egg rolls.  When cooking with thin rice noodles, be careful not to oversoak/overcook/overmix or they tend to disintegrate.  Asian rice noodle vermicelli (maifun) are not the same as Italian vermicelli and are not readily interchangeable.  If making an Italian recipe, the best results would be expected from Italian pasta and not maifun.&lt;br /&gt;&lt;br /&gt;A few final notes...  Both Peacock and Annie Chun&#x27;s brown rice noodles are gluten free.  The Peacock is made in Singapore and the Annie Chun&#x27;s in Thailand.  The Peacock noodles do taste fine (kind of bland), but so do the Annie Chun&#x27;s.  At this time, they are both approximately the same price.  Peacock come in an plastic bag with some noodle crushage upon shipping; Annie Chun&#x27;s are perfect upon removal from their cellophane bag in a box.  Overall, I highly recommend the Annie Chun&#x27;s Maifun as a healthier option over the Peacock brand.  On a related note, the Annie Chun&#x27;s soba and brown rice pad thai noodles are also excellent.&lt;br /&gt;&lt;br /&gt;Rating for this product: 2.5 stars rounded down to 2 stars.</td></tr>\n",
       "<tr><td>I have tried many different drink mix, this is the best tasting by far. It does not have the after taste of the sweetener and I really like it, it is pretty strong, so I use a big water bottle (20 oz) for one tube, it still a little stronger than I like, but it is just my taste.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     </td></tr>\n",
       "<tr><td>This is my favorite item to order for my Keurig. There are so many flavors, my finicky palate never gets bored!  The only downside is there are probably 5-6 decaf varieties.  I don&#x27;t drink decaf (I REQUIRE copious amounts of caffeine), so they sit on the shelf...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     </td></tr>\n",
       "<tr><td>Tastes like Earl Grey, but it&#x27;s green tea so it&#x27;s healthier.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect our reviews before tokenization\n",
    "reviews['Text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we can train our Word2Vec model\n",
    "<blockquote>We are going to use the popular Gensim word2vec implementation for scikit-learn. We use scikit-learn here because of it's implementation of <code>Pipelines</code> which allow us to create custom transformations on the data before training/running our model. This gives us the ultimate flexibility. We can also time how long it takes to train the word vectorizer, and log the vector size so we can change it and see how performance changes. Then we can look at some word synonyms to see how well the tokenizer did</i></br><footer>Splice Machine</footer></blockquote><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize( reviews ):\n",
    "    review_tokens = []\n",
    "    for review in reviews[0]:\n",
    "        # Remove non-letters\n",
    "        review = re.sub(\"[^a-zA-Z]\",\" \", review)\n",
    "        review = review.lower().split()\n",
    "\n",
    "        stops = set(STOP_WORDS)\n",
    "        review = [w for w in review if w not in stops]\n",
    "        review_tokens.append(review)\n",
    "    return(review_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /opt/conda/lib/python3.7/site-packages (3.8.3)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /opt/conda/lib/python3.7/site-packages (from gensim) (2.0.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /opt/conda/lib/python3.7/site-packages (from gensim) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /opt/conda/lib/python3.7/site-packages (from gensim) (1.18.2)\n",
      "Requirement already satisfied: six>=1.5.0 in /opt/conda/lib/python3.7/site-packages (from gensim) (1.14.0)\n",
      "Requirement already satisfied: boto3 in /opt/conda/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (1.13.20)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (2.23.0)\n",
      "Requirement already satisfied: boto in /opt/conda/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (2.49.0)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim) (0.3.3)\n",
      "Requirement already satisfied: botocore<1.17.0,>=1.16.20 in /opt/conda/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim) (1.16.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (1.25.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (2020.4.5.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (2.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (3.0.4)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /opt/conda/lib/python3.7/site-packages (from botocore<1.17.0,>=1.16.20->boto3->smart-open>=1.8.1->gensim) (0.15.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.7/site-packages (from botocore<1.17.0,>=1.16.20->boto3->smart-open>=1.8.1->gensim) (2.8.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The usage of `cmp` is deprecated and will be removed on or after 2021-06-01.  Please use `eq` and `order` instead.\n",
      "`scipy.sparse.sparsetools` is deprecated!\n",
      "scipy.sparse.sparsetools is a private module for scipy.sparse, and should not be used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Code Block word2vec_train_time... [Pipeline] ...... (step 1 of 3) Processing preprocessor, total=   4.7s\n",
      "[Pipeline] .......... (step 2 of 3) Processing word2vec, total= 1.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default validate=True will be replaced by validate=False in 0.22.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ..... (step 3 of 3) Processing postprocessor, total=   0.0s\n",
      "Done.\n",
      "Code Block word2vec_train_time:\n",
      "Ran in 116.892 secs\n",
      "Ran in 1.948 mins\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline as skPipe\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from gensim.sklearn_api import W2VTransformer, D2VTransformer\n",
    "import pandas as pd\n",
    "\n",
    "pdf = reviews['Text'].as_data_frame().astype('string')\n",
    "\n",
    "word2vec_model = skPipe(verbose=True,\n",
    "                            steps = [\n",
    "                                ('preprocessor', FunctionTransformer(tokenize, validate=False)),\n",
    "                                ('word2vec', D2VTransformer()),\n",
    "                                ('postprocessor', FunctionTransformer(lambda X: X.astype('double')))\n",
    "                            ])\n",
    "with mlflow.timer('word2vec_train_time'):\n",
    "    # tokenize and build vocab\n",
    "    word2vec_model.fit([pdf.dropna()['Text']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we can use the Doc2Vec Model to see the most similar sentences of an input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector of input: [(97666, 0.4205482006072998), (89475, 0.3980906903743744), (93814, 0.3940778076648712), (17113, 0.385466992855072), (27381, 0.38422274589538574), (14167, 0.37888938188552856), (30906, 0.3760056495666504), (13332, 0.3750417232513428), (1222, 0.3709920644760132), (62971, 0.36697107553482056)]\n",
      "\n",
      "Input: Tastes like Earl Grey, but it's green tea so it's healthier.\n",
      "Output: I made macarons with these; the almond flour is very finely ground and perfectly suited for macaron-making!\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "doc2vec_model = deepcopy(word2vec_model.steps[1][1].gensim_model)\n",
    "\n",
    "# Tokenize our input\n",
    "inp = \"Tastes like Earl Grey, but it's green tea so it's healthier.\"\n",
    "tokens = tokenize([[inp]])\n",
    "new_vector = doc2vec_model.infer_vector(tokens[0])\n",
    "# Get our vectorized sentence\n",
    "sims = doc2vec_model.docvecs.most_similar([new_vector])\n",
    "print(f'Vector of input: {sims}\\n')\n",
    "# Get the most similar review\n",
    "index = sims[0][0]\n",
    "output = pdf.dropna()['Text'].iloc[index]\n",
    "\n",
    "print(f'Input: {inp}\\nOutput: {output}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model of size: 49232.019 KB to Splice Machine DB\n",
      "Prediction labels found. Using ['C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9', 'C10', 'C11', 'C12', 'C13', 'C14', 'C15', 'C16', 'C17', 'C18', 'C19', 'C20', 'C21', 'C22', 'C23', 'C24', 'C25', 'C26', 'C27', 'C28', 'C29', 'C30', 'C31', 'C32', 'C33', 'C34', 'C35', 'C36', 'C37', 'C38', 'C39', 'C40', 'C41', 'C42', 'C43', 'C44', 'C45', 'C46', 'C47', 'C48', 'C49', 'C50', 'C51', 'C52', 'C53', 'C54', 'C55', 'C56', 'C57', 'C58', 'C59', 'C60', 'C61', 'C62', 'C63', 'C64', 'C65', 'C66', 'C67', 'C68', 'C69', 'C70', 'C71', 'C72', 'C73', 'C74', 'C75', 'C76', 'C77', 'C78', 'C79', 'C80', 'C81', 'C82', 'C83', 'C84', 'C85', 'C86', 'C87', 'C88', 'C89', 'C90', 'C91', 'C92', 'C93', 'C94', 'C95', 'C96', 'C97', 'C98', 'C99', 'C100'] as labels for predictions [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99] respectively\n",
      "Deploying model 680761687f21 to table splice.sk_vec_pipe\n",
      "Creating data table ... \n",
      " CREATE TABLE splice.sk_vec_pipe (\n",
      "\tText VARCHAR(5000),\tMOMENT_KEY INT,\n",
      "\tPRIMARY KEY(MOMENT_KEY)\n",
      ")\n",
      "\n",
      "Done.\n",
      "Creating prediction table ... \n",
      "CREATE TABLE splice.sk_vec_pipe_PREDS (\n",
      "        \tCUR_USER VARCHAR(50) DEFAULT CURRENT_USER,\n",
      "        \tEVAL_TIME TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
      "        \tRUN_ID VARCHAR(50) DEFAULT '680761687f21',\n",
      "        \tMOMENT_KEY INT,\n",
      "\t\"C1\" DOUBLE,\n",
      "\t\"C2\" DOUBLE,\n",
      "\t\"C3\" DOUBLE,\n",
      "\t\"C4\" DOUBLE,\n",
      "\t\"C5\" DOUBLE,\n",
      "\t\"C6\" DOUBLE,\n",
      "\t\"C7\" DOUBLE,\n",
      "\t\"C8\" DOUBLE,\n",
      "\t\"C9\" DOUBLE,\n",
      "\t\"C10\" DOUBLE,\n",
      "\t\"C11\" DOUBLE,\n",
      "\t\"C12\" DOUBLE,\n",
      "\t\"C13\" DOUBLE,\n",
      "\t\"C14\" DOUBLE,\n",
      "\t\"C15\" DOUBLE,\n",
      "\t\"C16\" DOUBLE,\n",
      "\t\"C17\" DOUBLE,\n",
      "\t\"C18\" DOUBLE,\n",
      "\t\"C19\" DOUBLE,\n",
      "\t\"C20\" DOUBLE,\n",
      "\t\"C21\" DOUBLE,\n",
      "\t\"C22\" DOUBLE,\n",
      "\t\"C23\" DOUBLE,\n",
      "\t\"C24\" DOUBLE,\n",
      "\t\"C25\" DOUBLE,\n",
      "\t\"C26\" DOUBLE,\n",
      "\t\"C27\" DOUBLE,\n",
      "\t\"C28\" DOUBLE,\n",
      "\t\"C29\" DOUBLE,\n",
      "\t\"C30\" DOUBLE,\n",
      "\t\"C31\" DOUBLE,\n",
      "\t\"C32\" DOUBLE,\n",
      "\t\"C33\" DOUBLE,\n",
      "\t\"C34\" DOUBLE,\n",
      "\t\"C35\" DOUBLE,\n",
      "\t\"C36\" DOUBLE,\n",
      "\t\"C37\" DOUBLE,\n",
      "\t\"C38\" DOUBLE,\n",
      "\t\"C39\" DOUBLE,\n",
      "\t\"C40\" DOUBLE,\n",
      "\t\"C41\" DOUBLE,\n",
      "\t\"C42\" DOUBLE,\n",
      "\t\"C43\" DOUBLE,\n",
      "\t\"C44\" DOUBLE,\n",
      "\t\"C45\" DOUBLE,\n",
      "\t\"C46\" DOUBLE,\n",
      "\t\"C47\" DOUBLE,\n",
      "\t\"C48\" DOUBLE,\n",
      "\t\"C49\" DOUBLE,\n",
      "\t\"C50\" DOUBLE,\n",
      "\t\"C51\" DOUBLE,\n",
      "\t\"C52\" DOUBLE,\n",
      "\t\"C53\" DOUBLE,\n",
      "\t\"C54\" DOUBLE,\n",
      "\t\"C55\" DOUBLE,\n",
      "\t\"C56\" DOUBLE,\n",
      "\t\"C57\" DOUBLE,\n",
      "\t\"C58\" DOUBLE,\n",
      "\t\"C59\" DOUBLE,\n",
      "\t\"C60\" DOUBLE,\n",
      "\t\"C61\" DOUBLE,\n",
      "\t\"C62\" DOUBLE,\n",
      "\t\"C63\" DOUBLE,\n",
      "\t\"C64\" DOUBLE,\n",
      "\t\"C65\" DOUBLE,\n",
      "\t\"C66\" DOUBLE,\n",
      "\t\"C67\" DOUBLE,\n",
      "\t\"C68\" DOUBLE,\n",
      "\t\"C69\" DOUBLE,\n",
      "\t\"C70\" DOUBLE,\n",
      "\t\"C71\" DOUBLE,\n",
      "\t\"C72\" DOUBLE,\n",
      "\t\"C73\" DOUBLE,\n",
      "\t\"C74\" DOUBLE,\n",
      "\t\"C75\" DOUBLE,\n",
      "\t\"C76\" DOUBLE,\n",
      "\t\"C77\" DOUBLE,\n",
      "\t\"C78\" DOUBLE,\n",
      "\t\"C79\" DOUBLE,\n",
      "\t\"C80\" DOUBLE,\n",
      "\t\"C81\" DOUBLE,\n",
      "\t\"C82\" DOUBLE,\n",
      "\t\"C83\" DOUBLE,\n",
      "\t\"C84\" DOUBLE,\n",
      "\t\"C85\" DOUBLE,\n",
      "\t\"C86\" DOUBLE,\n",
      "\t\"C87\" DOUBLE,\n",
      "\t\"C88\" DOUBLE,\n",
      "\t\"C89\" DOUBLE,\n",
      "\t\"C90\" DOUBLE,\n",
      "\t\"C91\" DOUBLE,\n",
      "\t\"C92\" DOUBLE,\n",
      "\t\"C93\" DOUBLE,\n",
      "\t\"C94\" DOUBLE,\n",
      "\t\"C95\" DOUBLE,\n",
      "\t\"C96\" DOUBLE,\n",
      "\t\"C97\" DOUBLE,\n",
      "\t\"C98\" DOUBLE,\n",
      "\t\"C99\" DOUBLE,\n",
      "\t\"C100\" DOUBLE,\n",
      "\tPRIMARY KEY(MOMENT_KEY)\n",
      ")\n",
      "\n",
      "Done.\n",
      "Creating model prediction trigger ... \n",
      "CREATE TRIGGER runModel_splice_sk_vec_pipe_680761687f21\n",
      " \tAFTER INSERT\n",
      " \tON splice.sk_vec_pipe\n",
      " \tREFERENCING NEW AS NEWROW\n",
      " \tFOR EACH ROW\n",
      " \t\tINSERT INTO splice.sk_vec_pipe_PREDS(MOMENT_KEY,\"C1\",\"C2\",\"C3\",\"C4\",\"C5\",\"C6\",\"C7\",\"C8\",\"C9\",\"C10\",\"C11\",\"C12\",\"C13\",\"C14\",\"C15\",\"C16\",\"C17\",\"C18\",\"C19\",\"C20\",\"C21\",\"C22\",\"C23\",\"C24\",\"C25\",\"C26\",\"C27\",\"C28\",\"C29\",\"C30\",\"C31\",\"C32\",\"C33\",\"C34\",\"C35\",\"C36\",\"C37\",\"C38\",\"C39\",\"C40\",\"C41\",\"C42\",\"C43\",\"C44\",\"C45\",\"C46\",\"C47\",\"C48\",\"C49\",\"C50\",\"C51\",\"C52\",\"C53\",\"C54\",\"C55\",\"C56\",\"C57\",\"C58\",\"C59\",\"C60\",\"C61\",\"C62\",\"C63\",\"C64\",\"C65\",\"C66\",\"C67\",\"C68\",\"C69\",\"C70\",\"C71\",\"C72\",\"C73\",\"C74\",\"C75\",\"C76\",\"C77\",\"C78\",\"C79\",\"C80\",\"C81\",\"C82\",\"C83\",\"C84\",\"C85\",\"C86\",\"C87\",\"C88\",\"C89\",\"C90\",\"C91\",\"C92\",\"C93\",\"C94\",\"C95\",\"C96\",\"C97\",\"C98\",\"C99\",\"C100\") SELECT \tNEWROW.MOMENT_KEY, b.\"C1\",b.\"C2\",b.\"C3\",b.\"C4\",b.\"C5\",b.\"C6\",b.\"C7\",b.\"C8\",b.\"C9\",b.\"C10\",b.\"C11\",b.\"C12\",b.\"C13\",b.\"C14\",b.\"C15\",b.\"C16\",b.\"C17\",b.\"C18\",b.\"C19\",b.\"C20\",b.\"C21\",b.\"C22\",b.\"C23\",b.\"C24\",b.\"C25\",b.\"C26\",b.\"C27\",b.\"C28\",b.\"C29\",b.\"C30\",b.\"C31\",b.\"C32\",b.\"C33\",b.\"C34\",b.\"C35\",b.\"C36\",b.\"C37\",b.\"C38\",b.\"C39\",b.\"C40\",b.\"C41\",b.\"C42\",b.\"C43\",b.\"C44\",b.\"C45\",b.\"C46\",b.\"C47\",b.\"C48\",b.\"C49\",b.\"C50\",b.\"C51\",b.\"C52\",b.\"C53\",b.\"C54\",b.\"C55\",b.\"C56\",b.\"C57\",b.\"C58\",b.\"C59\",b.\"C60\",b.\"C61\",b.\"C62\",b.\"C63\",b.\"C64\",b.\"C65\",b.\"C66\",b.\"C67\",b.\"C68\",b.\"C69\",b.\"C70\",b.\"C71\",b.\"C72\",b.\"C73\",b.\"C74\",b.\"C75\",b.\"C76\",b.\"C77\",b.\"C78\",b.\"C79\",b.\"C80\",b.\"C81\",b.\"C82\",b.\"C83\",b.\"C84\",b.\"C85\",b.\"C86\",b.\"C87\",b.\"C88\",b.\"C89\",b.\"C90\",b.\"C91\",b.\"C92\",b.\"C93\",b.\"C94\",b.\"C95\",b.\"C96\",b.\"C97\",b.\"C98\",b.\"C99\",b.\"C100\" FROM new com.splicemachine.mlrunner.MLRunner('key_value', '680761687f21', TRIM(CAST(NEWROW.Text as CHAR(41))), 'Text VARCHAR(5000)', 'transform', 'None') as b (\"C1\" DOUBLE,\"C2\" DOUBLE,\"C3\" DOUBLE,\"C4\" DOUBLE,\"C5\" DOUBLE,\"C6\" DOUBLE,\"C7\" DOUBLE,\"C8\" DOUBLE,\"C9\" DOUBLE,\"C10\" DOUBLE,\"C11\" DOUBLE,\"C12\" DOUBLE,\"C13\" DOUBLE,\"C14\" DOUBLE,\"C15\" DOUBLE,\"C16\" DOUBLE,\"C17\" DOUBLE,\"C18\" DOUBLE,\"C19\" DOUBLE,\"C20\" DOUBLE,\"C21\" DOUBLE,\"C22\" DOUBLE,\"C23\" DOUBLE,\"C24\" DOUBLE,\"C25\" DOUBLE,\"C26\" DOUBLE,\"C27\" DOUBLE,\"C28\" DOUBLE,\"C29\" DOUBLE,\"C30\" DOUBLE,\"C31\" DOUBLE,\"C32\" DOUBLE,\"C33\" DOUBLE,\"C34\" DOUBLE,\"C35\" DOUBLE,\"C36\" DOUBLE,\"C37\" DOUBLE,\"C38\" DOUBLE,\"C39\" DOUBLE,\"C40\" DOUBLE,\"C41\" DOUBLE,\"C42\" DOUBLE,\"C43\" DOUBLE,\"C44\" DOUBLE,\"C45\" DOUBLE,\"C46\" DOUBLE,\"C47\" DOUBLE,\"C48\" DOUBLE,\"C49\" DOUBLE,\"C50\" DOUBLE,\"C51\" DOUBLE,\"C52\" DOUBLE,\"C53\" DOUBLE,\"C54\" DOUBLE,\"C55\" DOUBLE,\"C56\" DOUBLE,\"C57\" DOUBLE,\"C58\" DOUBLE,\"C59\" DOUBLE,\"C60\" DOUBLE,\"C61\" DOUBLE,\"C62\" DOUBLE,\"C63\" DOUBLE,\"C64\" DOUBLE,\"C65\" DOUBLE,\"C66\" DOUBLE,\"C67\" DOUBLE,\"C68\" DOUBLE,\"C69\" DOUBLE,\"C70\" DOUBLE,\"C71\" DOUBLE,\"C72\" DOUBLE,\"C73\" DOUBLE,\"C74\" DOUBLE,\"C75\" DOUBLE,\"C76\" DOUBLE,\"C77\" DOUBLE,\"C78\" DOUBLE,\"C79\" DOUBLE,\"C80\" DOUBLE,\"C81\" DOUBLE,\"C82\" DOUBLE,\"C83\" DOUBLE,\"C84\" DOUBLE,\"C85\" DOUBLE,\"C86\" DOUBLE,\"C87\" DOUBLE,\"C88\" DOUBLE,\"C89\" DOUBLE,\"C90\" DOUBLE,\"C91\" DOUBLE,\"C92\" DOUBLE,\"C93\" DOUBLE,\"C94\" DOUBLE,\"C95\" DOUBLE,\"C96\" DOUBLE,\"C97\" DOUBLE,\"C98\" DOUBLE,\"C99\" DOUBLE,\"C100\" DOUBLE)\n",
      "\n",
      "Done.\n",
      "Model Deployed.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "mlflow.end_run()\n",
    "mlflow.start_run()\n",
    "schema = 'REPLACE_ME_DBSCHEMA'\n",
    "splice._dropTableIfExists(f'{schema}.sk_vec_pipe')\n",
    "splice._dropTableIfExists(f'{schema}.sk_vec_pipe_preds')\n",
    "mlflow.deploy_db(word2vec_model, pdf, schema, 'sk_vec_pipe', [('MOMENT_KEY', 'INT')], run_id=mlflow.current_run_id(),\n",
    "                     classes = [f'C{i+1}' for i in range(100)], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ddce19b-d988-4c03-b4c5-1ca12a761775",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e3b0cbb-a291-43f3-88df-5427f904535c",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "insert into sk_vec_pipe values('I really liked this coffee. I recommend!', 2);\n",
    "select * from sk_vec_pipe_preds;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we can save this model and end our run\n",
    "<blockquote>We want to save this vectorizer as an <b>independent</b> <code>run</code>. This is because we may want to build more than 1 model that utilizes these word vectors. We don't want to duplicate those identical word vectors, so we can use the outputs for <b>more than one model</b>. This is the idea of a <i>feature store</i> where we use features from one dataset on multiple models. This is crucial to creating efficient ML workflow systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving artifact of size: 49232.019 KB to Splice Machine DB\n"
     ]
    }
   ],
   "source": [
    "mlflow.log_model(word2vec_model, 'word2vec_model')\n",
    "mlflow.lp('vector_size',100)\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's vectorize our reviews\n",
    "<blockquote>Now that we have a word embedding for each word in our vocabulary, we will aggregate the words for each review using the <code>transform</code> function.  This will give us one aggregated word embedding for each review.</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default validate=True will be replaced by validate=False in 0.22.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>ProductId  </th><th>UserId        </th><th>Summary                               </th><th style=\"text-align: right;\">  Score</th><th style=\"text-align: right;\">  HelpfulnessDenominator</th><th style=\"text-align: right;\">    Id</th><th>ProfileName                                     </th><th style=\"text-align: right;\">  HelpfulnessNumerator</th><th style=\"text-align: right;\">       Time</th><th>Text                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </th><th style=\"text-align: right;\">  PositiveReview</th><th style=\"text-align: right;\">          C1</th><th style=\"text-align: right;\">          C2</th><th style=\"text-align: right;\">          C3</th><th style=\"text-align: right;\">          C4</th><th style=\"text-align: right;\">          C5</th><th style=\"text-align: right;\">          C6</th><th style=\"text-align: right;\">          C7</th><th style=\"text-align: right;\">         C8</th><th style=\"text-align: right;\">          C9</th><th style=\"text-align: right;\">        C10</th><th style=\"text-align: right;\">         C11</th><th style=\"text-align: right;\">         C12</th><th style=\"text-align: right;\">        C13</th><th style=\"text-align: right;\">        C14</th><th style=\"text-align: right;\">         C15</th><th style=\"text-align: right;\">        C16</th><th style=\"text-align: right;\">         C17</th><th style=\"text-align: right;\">        C18</th><th style=\"text-align: right;\">         C19</th><th style=\"text-align: right;\">        C20</th><th style=\"text-align: right;\">         C21</th><th style=\"text-align: right;\">         C22</th><th style=\"text-align: right;\">         C23</th><th style=\"text-align: right;\">         C24</th><th style=\"text-align: right;\">        C25</th><th style=\"text-align: right;\">         C26</th><th style=\"text-align: right;\">         C27</th><th style=\"text-align: right;\">         C28</th><th style=\"text-align: right;\">         C29</th><th style=\"text-align: right;\">         C30</th><th style=\"text-align: right;\">        C31</th><th style=\"text-align: right;\">         C32</th><th style=\"text-align: right;\">         C33</th><th style=\"text-align: right;\">         C34</th><th style=\"text-align: right;\">         C35</th><th style=\"text-align: right;\">         C36</th><th style=\"text-align: right;\">         C37</th><th style=\"text-align: right;\">         C38</th><th style=\"text-align: right;\">         C39</th><th style=\"text-align: right;\">         C40</th><th style=\"text-align: right;\">         C41</th><th style=\"text-align: right;\">         C42</th><th style=\"text-align: right;\">         C43</th><th style=\"text-align: right;\">        C44</th><th style=\"text-align: right;\">         C45</th><th style=\"text-align: right;\">         C46</th><th style=\"text-align: right;\">        C47</th><th style=\"text-align: right;\">         C48</th><th style=\"text-align: right;\">         C49</th><th style=\"text-align: right;\">         C50</th><th style=\"text-align: right;\">         C51</th><th style=\"text-align: right;\">         C52</th><th style=\"text-align: right;\">         C53</th><th style=\"text-align: right;\">         C54</th><th style=\"text-align: right;\">         C55</th><th style=\"text-align: right;\">         C56</th><th style=\"text-align: right;\">         C57</th><th style=\"text-align: right;\">         C58</th><th style=\"text-align: right;\">         C59</th><th style=\"text-align: right;\">         C60</th><th style=\"text-align: right;\">         C61</th><th style=\"text-align: right;\">         C62</th><th style=\"text-align: right;\">        C63</th><th style=\"text-align: right;\">         C64</th><th style=\"text-align: right;\">         C65</th><th style=\"text-align: right;\">         C66</th><th style=\"text-align: right;\">         C67</th><th style=\"text-align: right;\">         C68</th><th style=\"text-align: right;\">         C69</th><th style=\"text-align: right;\">         C70</th><th style=\"text-align: right;\">         C71</th><th style=\"text-align: right;\">         C72</th><th style=\"text-align: right;\">         C73</th><th style=\"text-align: right;\">         C74</th><th style=\"text-align: right;\">        C75</th><th style=\"text-align: right;\">        C76</th><th style=\"text-align: right;\">         C77</th><th style=\"text-align: right;\">         C78</th><th style=\"text-align: right;\">         C79</th><th style=\"text-align: right;\">         C80</th><th style=\"text-align: right;\">        C81</th><th style=\"text-align: right;\">         C82</th><th style=\"text-align: right;\">         C83</th><th style=\"text-align: right;\">         C84</th><th style=\"text-align: right;\">        C85</th><th style=\"text-align: right;\">         C86</th><th style=\"text-align: right;\">         C87</th><th style=\"text-align: right;\">         C88</th><th style=\"text-align: right;\">         C89</th><th style=\"text-align: right;\">         C90</th><th style=\"text-align: right;\">         C91</th><th style=\"text-align: right;\">         C92</th><th style=\"text-align: right;\">         C93</th><th style=\"text-align: right;\">         C94</th><th style=\"text-align: right;\">         C95</th><th style=\"text-align: right;\">         C96</th><th style=\"text-align: right;\">         C97</th><th style=\"text-align: right;\">         C98</th><th style=\"text-align: right;\">         C99</th><th style=\"text-align: right;\">        C100</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>B00141QYSQ </td><td>A1YS02UZZGRDCT</td><td>Do Not Buy                            </td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">                       2</td><td style=\"text-align: right;\"> 41471</td><td>Evan Eberhardt                                  </td><td style=\"text-align: right;\">                     2</td><td style=\"text-align: right;\">1.34836e+09</td><td>These are made in China (do not buy ANY pet food from China).  Dogswell has been using propylene glycol to soften their treats (what are they thinkng?).  Do not purchase or support this company in any way until they clean up their act.  And for whatever reason Amazon doesn&#x27;t allow returns of this item, so I had to toss mine out.  Bad business all around on this one.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            </td><td style=\"text-align: right;\">               0</td><td style=\"text-align: right;\">-0.00133612 </td><td style=\"text-align: right;\"> 0.00147022 </td><td style=\"text-align: right;\"> 0.00489118 </td><td style=\"text-align: right;\">-0.000812136</td><td style=\"text-align: right;\">-0.00485834 </td><td style=\"text-align: right;\">-0.00096183 </td><td style=\"text-align: right;\">-0.000388682</td><td style=\"text-align: right;\"> 0.00303393</td><td style=\"text-align: right;\">-0.00361697 </td><td style=\"text-align: right;\"> 0.00307536</td><td style=\"text-align: right;\">-0.00387981 </td><td style=\"text-align: right;\"> 0.00410081 </td><td style=\"text-align: right;\">-0.004984  </td><td style=\"text-align: right;\"> 0.0047441 </td><td style=\"text-align: right;\">-0.00031778 </td><td style=\"text-align: right;\"> 0.00209467</td><td style=\"text-align: right;\"> 0.0014758  </td><td style=\"text-align: right;\">-0.00120933</td><td style=\"text-align: right;\"> 0.0047215  </td><td style=\"text-align: right;\"> 0.0016437 </td><td style=\"text-align: right;\">-0.00454923 </td><td style=\"text-align: right;\">-0.00384956 </td><td style=\"text-align: right;\"> 0.000442707</td><td style=\"text-align: right;\"> 0.003925   </td><td style=\"text-align: right;\"> 0.00152025</td><td style=\"text-align: right;\"> 0.00254895 </td><td style=\"text-align: right;\"> 0.000114834</td><td style=\"text-align: right;\"> 0.00252259 </td><td style=\"text-align: right;\"> 0.0012479  </td><td style=\"text-align: right;\">-0.00303425 </td><td style=\"text-align: right;\">-0.00091658</td><td style=\"text-align: right;\">-0.00284571 </td><td style=\"text-align: right;\"> 0.000826418</td><td style=\"text-align: right;\">-0.00438576 </td><td style=\"text-align: right;\"> 0.000907566</td><td style=\"text-align: right;\"> 0.000468217</td><td style=\"text-align: right;\">-0.00364127 </td><td style=\"text-align: right;\"> 0.00203741 </td><td style=\"text-align: right;\">-0.00200908 </td><td style=\"text-align: right;\">-0.00107813 </td><td style=\"text-align: right;\"> 0.00164739 </td><td style=\"text-align: right;\">-0.0020164  </td><td style=\"text-align: right;\"> 0.00389483 </td><td style=\"text-align: right;\">-0.00281134</td><td style=\"text-align: right;\"> 0.00082546 </td><td style=\"text-align: right;\">-0.0019652  </td><td style=\"text-align: right;\"> 0.0033707 </td><td style=\"text-align: right;\">-0.00118207 </td><td style=\"text-align: right;\">-0.00176637 </td><td style=\"text-align: right;\"> 0.00377917 </td><td style=\"text-align: right;\">-0.00494846 </td><td style=\"text-align: right;\"> 0.000215452</td><td style=\"text-align: right;\"> 0.00106531 </td><td style=\"text-align: right;\"> 0.000204757</td><td style=\"text-align: right;\">-0.000434755</td><td style=\"text-align: right;\"> 0.000962922</td><td style=\"text-align: right;\">-0.00171811 </td><td style=\"text-align: right;\">-0.0038728  </td><td style=\"text-align: right;\">-0.00498921 </td><td style=\"text-align: right;\">-0.00315165 </td><td style=\"text-align: right;\"> 0.00200525 </td><td style=\"text-align: right;\"> 0.00415614 </td><td style=\"text-align: right;\"> 0.00067918</td><td style=\"text-align: right;\">-0.00375062 </td><td style=\"text-align: right;\"> 0.00112005 </td><td style=\"text-align: right;\">-0.0043547  </td><td style=\"text-align: right;\">-0.00252379 </td><td style=\"text-align: right;\"> 0.00269816 </td><td style=\"text-align: right;\">-0.00406649 </td><td style=\"text-align: right;\"> 0.004808   </td><td style=\"text-align: right;\">-0.00021671 </td><td style=\"text-align: right;\">-0.00499647 </td><td style=\"text-align: right;\">-0.000111112</td><td style=\"text-align: right;\"> 0.00341148 </td><td style=\"text-align: right;\"> 0.00332737</td><td style=\"text-align: right;\">-0.00494905</td><td style=\"text-align: right;\"> 0.000501786</td><td style=\"text-align: right;\">-0.00410729 </td><td style=\"text-align: right;\">-0.00159208 </td><td style=\"text-align: right;\">-0.000411889</td><td style=\"text-align: right;\"> 0.00362065</td><td style=\"text-align: right;\"> 0.0037789  </td><td style=\"text-align: right;\">-0.00347411 </td><td style=\"text-align: right;\"> 0.00437522 </td><td style=\"text-align: right;\">-0.00145569</td><td style=\"text-align: right;\"> 0.000228353</td><td style=\"text-align: right;\">-0.00341161 </td><td style=\"text-align: right;\">-0.00488238 </td><td style=\"text-align: right;\"> 0.00195579 </td><td style=\"text-align: right;\">-0.00290785 </td><td style=\"text-align: right;\">-0.00302468 </td><td style=\"text-align: right;\"> 0.00458038 </td><td style=\"text-align: right;\"> 0.00488747 </td><td style=\"text-align: right;\"> 0.000711441</td><td style=\"text-align: right;\">-0.00188029 </td><td style=\"text-align: right;\"> 0.00468673 </td><td style=\"text-align: right;\">-0.00309895 </td><td style=\"text-align: right;\"> 0.00455    </td><td style=\"text-align: right;\"> 0.00236985 </td><td style=\"text-align: right;\"> 0.000381572</td></tr>\n",
       "<tr><td>B0089SPEO2 </td><td>A3JOYNYL458QHP</td><td>Less lemon and less zing              </td><td style=\"text-align: right;\">      3</td><td style=\"text-align: right;\">                       0</td><td style=\"text-align: right;\"> 28582</td><td>coleridge                                       </td><td style=\"text-align: right;\">                     0</td><td style=\"text-align: right;\">1.32391e+09</td><td>Everything is ok, except it just isn&#x27;t as good as it is in the bags.  Just considerably more bland -- less lemon and less zing.  Boring.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </td><td style=\"text-align: right;\">               0</td><td style=\"text-align: right;\">-0.00423355 </td><td style=\"text-align: right;\"> 0.00433418 </td><td style=\"text-align: right;\">-0.00481421 </td><td style=\"text-align: right;\"> 4.24921e-05</td><td style=\"text-align: right;\">-0.00155022 </td><td style=\"text-align: right;\"> 0.001619   </td><td style=\"text-align: right;\">-0.00281991 </td><td style=\"text-align: right;\"> 0.00124699</td><td style=\"text-align: right;\"> 0.00182601 </td><td style=\"text-align: right;\"> 0.00238784</td><td style=\"text-align: right;\">-0.000447347</td><td style=\"text-align: right;\"> 0.00418661 </td><td style=\"text-align: right;\">-0.00295085</td><td style=\"text-align: right;\"> 0.00359459</td><td style=\"text-align: right;\">-0.00123096 </td><td style=\"text-align: right;\">-0.00201871</td><td style=\"text-align: right;\"> 0.00152987 </td><td style=\"text-align: right;\"> 0.00467554</td><td style=\"text-align: right;\">-0.000164307</td><td style=\"text-align: right;\">-0.00327224</td><td style=\"text-align: right;\">-0.00194678 </td><td style=\"text-align: right;\"> 0.000861934</td><td style=\"text-align: right;\">-0.00120003 </td><td style=\"text-align: right;\">-0.000825984</td><td style=\"text-align: right;\">-0.00186494</td><td style=\"text-align: right;\"> 0.00421304 </td><td style=\"text-align: right;\"> 0.0044746  </td><td style=\"text-align: right;\">-0.00211432 </td><td style=\"text-align: right;\">-0.00440828 </td><td style=\"text-align: right;\">-0.0017909  </td><td style=\"text-align: right;\">-0.0015314 </td><td style=\"text-align: right;\"> 0.00283345 </td><td style=\"text-align: right;\"> 0.00310395 </td><td style=\"text-align: right;\"> 0.00403174 </td><td style=\"text-align: right;\">-0.00489491 </td><td style=\"text-align: right;\"> 0.00213809 </td><td style=\"text-align: right;\"> 0.000913146</td><td style=\"text-align: right;\">-0.00238531 </td><td style=\"text-align: right;\"> 0.00387899 </td><td style=\"text-align: right;\">-0.00458897 </td><td style=\"text-align: right;\">-0.00133196 </td><td style=\"text-align: right;\"> 0.00261265 </td><td style=\"text-align: right;\"> 0.00196682 </td><td style=\"text-align: right;\"> 0.00345367</td><td style=\"text-align: right;\"> 0.00218583 </td><td style=\"text-align: right;\"> 0.000903332</td><td style=\"text-align: right;\"> 0.00294384</td><td style=\"text-align: right;\"> 0.00129102 </td><td style=\"text-align: right;\">-0.00047666 </td><td style=\"text-align: right;\"> 0.00222886 </td><td style=\"text-align: right;\">-0.00331657 </td><td style=\"text-align: right;\"> 0.00278342 </td><td style=\"text-align: right;\">-0.00271497 </td><td style=\"text-align: right;\">-0.0046595  </td><td style=\"text-align: right;\">-0.0046353  </td><td style=\"text-align: right;\"> 0.00386287 </td><td style=\"text-align: right;\">-0.00114053 </td><td style=\"text-align: right;\">-0.00426029 </td><td style=\"text-align: right;\"> 0.00261225 </td><td style=\"text-align: right;\"> 0.00127662 </td><td style=\"text-align: right;\"> 0.00319961 </td><td style=\"text-align: right;\"> 0.0040739  </td><td style=\"text-align: right;\">-0.00304281</td><td style=\"text-align: right;\">-0.00283115 </td><td style=\"text-align: right;\">-0.00149188 </td><td style=\"text-align: right;\">-0.00360352 </td><td style=\"text-align: right;\"> 0.000537949</td><td style=\"text-align: right;\"> 0.00416024 </td><td style=\"text-align: right;\"> 0.00227099 </td><td style=\"text-align: right;\"> 0.000753228</td><td style=\"text-align: right;\">-0.00353955 </td><td style=\"text-align: right;\"> 0.00195869 </td><td style=\"text-align: right;\"> 0.00126945 </td><td style=\"text-align: right;\">-0.00219305 </td><td style=\"text-align: right;\"> 0.00383016</td><td style=\"text-align: right;\"> 0.00258473</td><td style=\"text-align: right;\">-0.00470925 </td><td style=\"text-align: right;\">-0.000743051</td><td style=\"text-align: right;\">-0.00449109 </td><td style=\"text-align: right;\">-0.000955942</td><td style=\"text-align: right;\"> 0.00494278</td><td style=\"text-align: right;\"> 0.00028845 </td><td style=\"text-align: right;\">-0.00149227 </td><td style=\"text-align: right;\">-0.00181637 </td><td style=\"text-align: right;\"> 0.00356655</td><td style=\"text-align: right;\"> 0.00393856 </td><td style=\"text-align: right;\">-0.000792113</td><td style=\"text-align: right;\">-0.00436264 </td><td style=\"text-align: right;\"> 0.000950215</td><td style=\"text-align: right;\"> 0.00213895 </td><td style=\"text-align: right;\">-0.000311588</td><td style=\"text-align: right;\">-0.00392099 </td><td style=\"text-align: right;\">-0.00155748 </td><td style=\"text-align: right;\">-0.00245845 </td><td style=\"text-align: right;\">-0.00485048 </td><td style=\"text-align: right;\"> 0.00354392 </td><td style=\"text-align: right;\"> 0.00365414 </td><td style=\"text-align: right;\">-0.00252022 </td><td style=\"text-align: right;\">-0.00360211 </td><td style=\"text-align: right;\">-0.00317446 </td></tr>\n",
       "<tr><td>B001PMCDK2 </td><td>A14TTMM0Z03Y2W</td><td>my cat goes crazy for these!          </td><td style=\"text-align: right;\">      5</td><td style=\"text-align: right;\">                       0</td><td style=\"text-align: right;\">389965</td><td>Lindsay S. Bradford                             </td><td style=\"text-align: right;\">                     0</td><td style=\"text-align: right;\">1.3106e+09 </td><td>Best cat treat ever. There isn&#x27;t anything comparable to the love my cat has for these treats, he snubs away any other kind now.&lt;br /&gt;I know he likes to manipulate me with his cattiness but these treats are my way of manipulating him to come sit on my lap and have some chill time. :)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 </td><td style=\"text-align: right;\">               1</td><td style=\"text-align: right;\"> 0.00218472 </td><td style=\"text-align: right;\">-0.0048684  </td><td style=\"text-align: right;\"> 0.00114528 </td><td style=\"text-align: right;\"> 0.00426338 </td><td style=\"text-align: right;\"> 0.000614743</td><td style=\"text-align: right;\"> 0.00313093 </td><td style=\"text-align: right;\">-0.000674778</td><td style=\"text-align: right;\"> 0.00122496</td><td style=\"text-align: right;\">-0.00253126 </td><td style=\"text-align: right;\"> 0.00267866</td><td style=\"text-align: right;\"> 0.00328795 </td><td style=\"text-align: right;\"> 0.00173304 </td><td style=\"text-align: right;\"> 0.00051186</td><td style=\"text-align: right;\">-0.00449441</td><td style=\"text-align: right;\"> 0.00207039 </td><td style=\"text-align: right;\">-0.00492256</td><td style=\"text-align: right;\"> 0.00214774 </td><td style=\"text-align: right;\"> 0.00170025</td><td style=\"text-align: right;\">-0.000302309</td><td style=\"text-align: right;\"> 0.00154342</td><td style=\"text-align: right;\"> 0.00384739 </td><td style=\"text-align: right;\">-0.00462316 </td><td style=\"text-align: right;\">-0.00169518 </td><td style=\"text-align: right;\"> 0.00242907 </td><td style=\"text-align: right;\"> 0.00339188</td><td style=\"text-align: right;\">-0.00432336 </td><td style=\"text-align: right;\"> 0.0025056  </td><td style=\"text-align: right;\">-0.00379441 </td><td style=\"text-align: right;\">-0.001994   </td><td style=\"text-align: right;\"> 0.0031262  </td><td style=\"text-align: right;\">-0.00264515</td><td style=\"text-align: right;\">-0.00138381 </td><td style=\"text-align: right;\"> 0.000195867</td><td style=\"text-align: right;\"> 0.000656964</td><td style=\"text-align: right;\"> 0.0015638  </td><td style=\"text-align: right;\"> 7.26355e-05</td><td style=\"text-align: right;\"> 0.00288833 </td><td style=\"text-align: right;\">-0.00303806 </td><td style=\"text-align: right;\"> 0.00227576 </td><td style=\"text-align: right;\"> 0.00265079 </td><td style=\"text-align: right;\"> 0.000642465</td><td style=\"text-align: right;\">-0.00431144 </td><td style=\"text-align: right;\"> 0.00426382 </td><td style=\"text-align: right;\"> 0.00115343</td><td style=\"text-align: right;\"> 0.0037074  </td><td style=\"text-align: right;\">-0.00187574 </td><td style=\"text-align: right;\"> 0.0049595 </td><td style=\"text-align: right;\"> 0.00119742 </td><td style=\"text-align: right;\">-0.00435375 </td><td style=\"text-align: right;\"> 0.000513003</td><td style=\"text-align: right;\">-0.000456898</td><td style=\"text-align: right;\">-0.00455355 </td><td style=\"text-align: right;\"> 0.00382519 </td><td style=\"text-align: right;\"> 0.000681561</td><td style=\"text-align: right;\">-0.00436569 </td><td style=\"text-align: right;\"> 0.00213935 </td><td style=\"text-align: right;\"> 0.00466667 </td><td style=\"text-align: right;\">-0.00332755 </td><td style=\"text-align: right;\"> 0.000789055</td><td style=\"text-align: right;\">-0.00338099 </td><td style=\"text-align: right;\"> 0.00455042 </td><td style=\"text-align: right;\"> 0.00491446 </td><td style=\"text-align: right;\"> 0.00167183</td><td style=\"text-align: right;\">-0.00454067 </td><td style=\"text-align: right;\">-0.00220229 </td><td style=\"text-align: right;\"> 0.00438717 </td><td style=\"text-align: right;\"> 0.000962619</td><td style=\"text-align: right;\">-0.00179936 </td><td style=\"text-align: right;\"> 0.000383052</td><td style=\"text-align: right;\"> 4.79465e-05</td><td style=\"text-align: right;\">-0.00326563 </td><td style=\"text-align: right;\">-0.00278722 </td><td style=\"text-align: right;\">-0.00459328 </td><td style=\"text-align: right;\">-0.000734924</td><td style=\"text-align: right;\">-0.00105086</td><td style=\"text-align: right;\">-0.00497   </td><td style=\"text-align: right;\"> 0.00428525 </td><td style=\"text-align: right;\"> 0.003993   </td><td style=\"text-align: right;\"> 0.00212568 </td><td style=\"text-align: right;\">-0.00274944 </td><td style=\"text-align: right;\"> 0.00412101</td><td style=\"text-align: right;\">-0.000983862</td><td style=\"text-align: right;\">-0.00296242 </td><td style=\"text-align: right;\">-0.00202511 </td><td style=\"text-align: right;\">-0.0035987 </td><td style=\"text-align: right;\">-0.00140065 </td><td style=\"text-align: right;\"> 0.00470268 </td><td style=\"text-align: right;\">-0.00369263 </td><td style=\"text-align: right;\">-0.00419198 </td><td style=\"text-align: right;\">-0.000203952</td><td style=\"text-align: right;\"> 0.000976817</td><td style=\"text-align: right;\"> 0.00415243 </td><td style=\"text-align: right;\">-0.000250589</td><td style=\"text-align: right;\">-0.00217692 </td><td style=\"text-align: right;\">-0.00191224 </td><td style=\"text-align: right;\">-0.00402548 </td><td style=\"text-align: right;\">-0.000348004</td><td style=\"text-align: right;\">-0.00100967 </td><td style=\"text-align: right;\"> 0.00208011 </td><td style=\"text-align: right;\">-0.00476021 </td></tr>\n",
       "<tr><td>B002Q8JOSI </td><td>A17UQD2RSSQH5X</td><td>My dogs tell me these treats are YUMMY</td><td style=\"text-align: right;\">      5</td><td style=\"text-align: right;\">                       1</td><td style=\"text-align: right;\">212536</td><td>in the dark                                     </td><td style=\"text-align: right;\">                     1</td><td style=\"text-align: right;\">1.31613e+09</td><td>My two Corgis were thoroughly spoiled by my late husband (I spent a year and a half dieting them down a combined total of 25 pounds!)&lt;br /&gt;&lt;br /&gt;They are accustomed to the finest of fare, and they absolutely love the Wellness brand of treats.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          </td><td style=\"text-align: right;\">               1</td><td style=\"text-align: right;\"> 0.000323188</td><td style=\"text-align: right;\"> 0.00220334 </td><td style=\"text-align: right;\">-0.00218276 </td><td style=\"text-align: right;\">-0.00120072 </td><td style=\"text-align: right;\">-0.00421617 </td><td style=\"text-align: right;\">-0.00294059 </td><td style=\"text-align: right;\"> 0.00184223 </td><td style=\"text-align: right;\">-0.00252994</td><td style=\"text-align: right;\"> 0.00232496 </td><td style=\"text-align: right;\"> 0.00195689</td><td style=\"text-align: right;\"> 0.00149886 </td><td style=\"text-align: right;\">-0.00158156 </td><td style=\"text-align: right;\"> 0.00326899</td><td style=\"text-align: right;\"> 0.00314697</td><td style=\"text-align: right;\"> 0.000400084</td><td style=\"text-align: right;\">-0.00208843</td><td style=\"text-align: right;\">-0.0036086  </td><td style=\"text-align: right;\"> 0.00319899</td><td style=\"text-align: right;\">-0.000950935</td><td style=\"text-align: right;\"> 0.00368954</td><td style=\"text-align: right;\">-0.00478883 </td><td style=\"text-align: right;\">-0.00175472 </td><td style=\"text-align: right;\"> 0.0015265  </td><td style=\"text-align: right;\">-0.000245147</td><td style=\"text-align: right;\">-0.00445939</td><td style=\"text-align: right;\"> 0.0024602  </td><td style=\"text-align: right;\">-0.000237154</td><td style=\"text-align: right;\"> 0.00177451 </td><td style=\"text-align: right;\"> 0.000359319</td><td style=\"text-align: right;\">-0.000548342</td><td style=\"text-align: right;\">-0.00293219</td><td style=\"text-align: right;\"> 0.00461495 </td><td style=\"text-align: right;\">-0.00358168 </td><td style=\"text-align: right;\">-0.00247723 </td><td style=\"text-align: right;\">-0.00351943 </td><td style=\"text-align: right;\">-0.00413436 </td><td style=\"text-align: right;\"> 0.00250237 </td><td style=\"text-align: right;\"> 0.000490383</td><td style=\"text-align: right;\">-0.00289888 </td><td style=\"text-align: right;\"> 0.00345961 </td><td style=\"text-align: right;\"> 0.00492328 </td><td style=\"text-align: right;\">-0.000570755</td><td style=\"text-align: right;\">-0.00342748 </td><td style=\"text-align: right;\"> 0.00403183</td><td style=\"text-align: right;\">-0.00334266 </td><td style=\"text-align: right;\">-0.000881613</td><td style=\"text-align: right;\">-0.00451009</td><td style=\"text-align: right;\"> 0.0001117  </td><td style=\"text-align: right;\"> 0.000714012</td><td style=\"text-align: right;\"> 0.00328952 </td><td style=\"text-align: right;\"> 0.00406179 </td><td style=\"text-align: right;\"> 0.00219107 </td><td style=\"text-align: right;\">-0.00464621 </td><td style=\"text-align: right;\"> 0.00344256 </td><td style=\"text-align: right;\"> 0.00241494 </td><td style=\"text-align: right;\"> 0.00301264 </td><td style=\"text-align: right;\">-9.07425e-05</td><td style=\"text-align: right;\">-0.00399501 </td><td style=\"text-align: right;\">-0.0026184  </td><td style=\"text-align: right;\"> 0.00239154 </td><td style=\"text-align: right;\">-0.000350161</td><td style=\"text-align: right;\">-0.000846761</td><td style=\"text-align: right;\">-0.0035514 </td><td style=\"text-align: right;\"> 0.00140566 </td><td style=\"text-align: right;\"> 0.00332168 </td><td style=\"text-align: right;\">-0.000524493</td><td style=\"text-align: right;\">-0.00395941 </td><td style=\"text-align: right;\"> 0.00399099 </td><td style=\"text-align: right;\"> 0.00293573 </td><td style=\"text-align: right;\"> 0.00422165 </td><td style=\"text-align: right;\"> 0.00338702 </td><td style=\"text-align: right;\"> 0.00463818 </td><td style=\"text-align: right;\">-0.000895692</td><td style=\"text-align: right;\"> 0.00258055 </td><td style=\"text-align: right;\"> 0.00241332</td><td style=\"text-align: right;\"> 0.00461612</td><td style=\"text-align: right;\"> 0.000565323</td><td style=\"text-align: right;\">-0.00282258 </td><td style=\"text-align: right;\">-0.000847788</td><td style=\"text-align: right;\">-0.00165681 </td><td style=\"text-align: right;\">-0.00358107</td><td style=\"text-align: right;\"> 0.00173625 </td><td style=\"text-align: right;\"> 0.00121695 </td><td style=\"text-align: right;\">-0.000686606</td><td style=\"text-align: right;\">-0.00270676</td><td style=\"text-align: right;\"> 0.004628   </td><td style=\"text-align: right;\">-0.00448403 </td><td style=\"text-align: right;\"> 0.00017295 </td><td style=\"text-align: right;\"> 0.00144735 </td><td style=\"text-align: right;\"> 0.0026011  </td><td style=\"text-align: right;\">-0.00496744 </td><td style=\"text-align: right;\">-0.000582625</td><td style=\"text-align: right;\"> 0.00288315 </td><td style=\"text-align: right;\"> 0.000126521</td><td style=\"text-align: right;\"> 0.00266959 </td><td style=\"text-align: right;\"> 0.00494883 </td><td style=\"text-align: right;\">-0.00499209 </td><td style=\"text-align: right;\"> 0.00125171 </td><td style=\"text-align: right;\"> 0.00436251 </td><td style=\"text-align: right;\"> 0.00286063 </td></tr>\n",
       "<tr><td>B00176G870 </td><td>A2F2MZW8EOGH5J</td><td>Yummy to the tummy                    </td><td style=\"text-align: right;\">      5</td><td style=\"text-align: right;\">                       0</td><td style=\"text-align: right;\">115971</td><td>daemoncycler &quot;When you arrive at a fork in th...</td><td style=\"text-align: right;\">                     0</td><td style=\"text-align: right;\">1.33479e+09</td><td>We used to have drive down to the specialty pet food store for this product.  So glad we discovered Amazon.  As far as I can tell it is no more expensive &amp; in some cases less - Prime membership is awesome.  Loving Pets treats are some of the best according to my dog.  They do not develop that nasty smell like some dog treats do.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  </td><td style=\"text-align: right;\">               1</td><td style=\"text-align: right;\">-0.00312483 </td><td style=\"text-align: right;\">-0.00307208 </td><td style=\"text-align: right;\"> 8.69586e-05</td><td style=\"text-align: right;\">-0.00322323 </td><td style=\"text-align: right;\">-0.00394788 </td><td style=\"text-align: right;\">-0.00332813 </td><td style=\"text-align: right;\">-0.00246299 </td><td style=\"text-align: right;\"> 0.00368839</td><td style=\"text-align: right;\"> 0.00092569 </td><td style=\"text-align: right;\"> 0.00390695</td><td style=\"text-align: right;\"> 0.00143158 </td><td style=\"text-align: right;\"> 0.0022721  </td><td style=\"text-align: right;\">-0.00200366</td><td style=\"text-align: right;\"> 0.00466131</td><td style=\"text-align: right;\"> 0.00265972 </td><td style=\"text-align: right;\">-0.00355359</td><td style=\"text-align: right;\"> 0.00280007 </td><td style=\"text-align: right;\">-0.00188804</td><td style=\"text-align: right;\"> 0.000368523</td><td style=\"text-align: right;\">-0.0033974 </td><td style=\"text-align: right;\"> 0.00211822 </td><td style=\"text-align: right;\"> 0.00392101 </td><td style=\"text-align: right;\">-0.000234908</td><td style=\"text-align: right;\">-0.00174195 </td><td style=\"text-align: right;\">-0.00484545</td><td style=\"text-align: right;\">-0.00101568 </td><td style=\"text-align: right;\">-0.00109717 </td><td style=\"text-align: right;\"> 0.00268263 </td><td style=\"text-align: right;\"> 0.00447134 </td><td style=\"text-align: right;\">-0.000242206</td><td style=\"text-align: right;\"> 0.00131456</td><td style=\"text-align: right;\"> 0.00396905 </td><td style=\"text-align: right;\"> 0.0036671  </td><td style=\"text-align: right;\"> 0.004398   </td><td style=\"text-align: right;\"> 0.00353331 </td><td style=\"text-align: right;\"> 0.00272421 </td><td style=\"text-align: right;\"> 0.00149926 </td><td style=\"text-align: right;\"> 0.00242483 </td><td style=\"text-align: right;\"> 0.0040605  </td><td style=\"text-align: right;\">-0.00393138 </td><td style=\"text-align: right;\"> 0.00418388 </td><td style=\"text-align: right;\">-0.00462514 </td><td style=\"text-align: right;\">-0.00223311 </td><td style=\"text-align: right;\"> 0.00190519</td><td style=\"text-align: right;\"> 0.0013173  </td><td style=\"text-align: right;\"> 0.000800496</td><td style=\"text-align: right;\"> 0.00393837</td><td style=\"text-align: right;\"> 0.00237388 </td><td style=\"text-align: right;\"> 0.00446276 </td><td style=\"text-align: right;\"> 0.00153924 </td><td style=\"text-align: right;\">-0.000955528</td><td style=\"text-align: right;\">-0.00421529 </td><td style=\"text-align: right;\">-0.00151442 </td><td style=\"text-align: right;\">-0.00098472 </td><td style=\"text-align: right;\"> 0.00412951 </td><td style=\"text-align: right;\">-0.00155734 </td><td style=\"text-align: right;\"> 0.00178775 </td><td style=\"text-align: right;\"> 0.000840708</td><td style=\"text-align: right;\"> 0.00296375 </td><td style=\"text-align: right;\">-0.00216849 </td><td style=\"text-align: right;\">-0.00306267 </td><td style=\"text-align: right;\">-0.00318433 </td><td style=\"text-align: right;\">-0.00131509</td><td style=\"text-align: right;\"> 2.87349e-05</td><td style=\"text-align: right;\"> 0.00476923 </td><td style=\"text-align: right;\">-0.000307039</td><td style=\"text-align: right;\">-0.00104119 </td><td style=\"text-align: right;\"> 0.00134939 </td><td style=\"text-align: right;\">-0.000690848</td><td style=\"text-align: right;\"> 0.00348609 </td><td style=\"text-align: right;\">-0.000596472</td><td style=\"text-align: right;\"> 0.00375184 </td><td style=\"text-align: right;\">-0.0019446  </td><td style=\"text-align: right;\">-0.00187058 </td><td style=\"text-align: right;\">-0.00252002</td><td style=\"text-align: right;\">-0.00183872</td><td style=\"text-align: right;\">-0.00358092 </td><td style=\"text-align: right;\">-0.00158317 </td><td style=\"text-align: right;\">-0.00419615 </td><td style=\"text-align: right;\">-0.000485016</td><td style=\"text-align: right;\">-0.00411301</td><td style=\"text-align: right;\">-0.00384276 </td><td style=\"text-align: right;\"> 0.00328924 </td><td style=\"text-align: right;\">-0.0030864  </td><td style=\"text-align: right;\">-0.00201846</td><td style=\"text-align: right;\">-0.000268742</td><td style=\"text-align: right;\"> 0.000954128</td><td style=\"text-align: right;\"> 0.00125243 </td><td style=\"text-align: right;\"> 0.00133101 </td><td style=\"text-align: right;\"> 0.00098418 </td><td style=\"text-align: right;\"> 0.00408316 </td><td style=\"text-align: right;\">-0.00286019 </td><td style=\"text-align: right;\"> 0.00469033 </td><td style=\"text-align: right;\"> 0.0023258  </td><td style=\"text-align: right;\">-0.00058062 </td><td style=\"text-align: right;\">-0.00304638 </td><td style=\"text-align: right;\">-8.08962e-05</td><td style=\"text-align: right;\">-0.00467948 </td><td style=\"text-align: right;\"> 0.000448454</td><td style=\"text-align: right;\"> 0.00056008 </td></tr>\n",
       "<tr><td>B001CHFUGY </td><td>A2M8VROSDPU4JT</td><td>Very good coffee                      </td><td style=\"text-align: right;\">      5</td><td style=\"text-align: right;\">                       1</td><td style=\"text-align: right;\">434484</td><td>Officefan &quot;Officefankt&quot;                         </td><td style=\"text-align: right;\">                     1</td><td style=\"text-align: right;\">1.27725e+09</td><td>I really liked this coffee, it was just as good as everyone claimed it was.  Strong, bold and flavorful!  I would recommend!                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                </td><td style=\"text-align: right;\">               1</td><td style=\"text-align: right;\"> 0.000805001</td><td style=\"text-align: right;\"> 0.00279391 </td><td style=\"text-align: right;\"> 0.00342956 </td><td style=\"text-align: right;\"> 0.00307927 </td><td style=\"text-align: right;\"> 0.00453435 </td><td style=\"text-align: right;\"> 0.00458108 </td><td style=\"text-align: right;\"> 0.00186245 </td><td style=\"text-align: right;\"> 0.00136024</td><td style=\"text-align: right;\">-0.00135663 </td><td style=\"text-align: right;\"> 0.0032569 </td><td style=\"text-align: right;\">-0.000625032</td><td style=\"text-align: right;\"> 0.000360041</td><td style=\"text-align: right;\"> 0.00101711</td><td style=\"text-align: right;\">-0.00197184</td><td style=\"text-align: right;\">-0.0042587  </td><td style=\"text-align: right;\"> 0.00389816</td><td style=\"text-align: right;\"> 2.08784e-06</td><td style=\"text-align: right;\">-0.00057711</td><td style=\"text-align: right;\"> 0.00269593 </td><td style=\"text-align: right;\">-0.00019907</td><td style=\"text-align: right;\"> 0.00323456 </td><td style=\"text-align: right;\"> 0.00465009 </td><td style=\"text-align: right;\"> 0.00163921 </td><td style=\"text-align: right;\">-0.0010498  </td><td style=\"text-align: right;\">-0.00331418</td><td style=\"text-align: right;\"> 0.000763904</td><td style=\"text-align: right;\">-0.000149959</td><td style=\"text-align: right;\"> 0.00485691 </td><td style=\"text-align: right;\"> 0.00485101 </td><td style=\"text-align: right;\">-0.000742684</td><td style=\"text-align: right;\">-0.00315935</td><td style=\"text-align: right;\">-0.00142903 </td><td style=\"text-align: right;\">-0.00249468 </td><td style=\"text-align: right;\"> 0.00353127 </td><td style=\"text-align: right;\"> 0.000792651</td><td style=\"text-align: right;\"> 0.000849817</td><td style=\"text-align: right;\"> 0.00159918 </td><td style=\"text-align: right;\">-0.0013278  </td><td style=\"text-align: right;\"> 0.00206721 </td><td style=\"text-align: right;\"> 0.000179137</td><td style=\"text-align: right;\"> 0.00158059 </td><td style=\"text-align: right;\">-0.00190382 </td><td style=\"text-align: right;\"> 0.000170676</td><td style=\"text-align: right;\">-0.00113045</td><td style=\"text-align: right;\"> 0.00341367 </td><td style=\"text-align: right;\">-0.00241372 </td><td style=\"text-align: right;\">-0.00398439</td><td style=\"text-align: right;\">-0.000252825</td><td style=\"text-align: right;\">-0.00337294 </td><td style=\"text-align: right;\"> 0.0046915  </td><td style=\"text-align: right;\"> 0.00275384 </td><td style=\"text-align: right;\">-0.00444165 </td><td style=\"text-align: right;\">-0.00434848 </td><td style=\"text-align: right;\">-0.00160969 </td><td style=\"text-align: right;\"> 0.00194927 </td><td style=\"text-align: right;\"> 0.00153083 </td><td style=\"text-align: right;\">-0.000624938</td><td style=\"text-align: right;\"> 0.000902626</td><td style=\"text-align: right;\"> 0.00385628 </td><td style=\"text-align: right;\">-0.000181548</td><td style=\"text-align: right;\">-0.00216503 </td><td style=\"text-align: right;\"> 0.00486133 </td><td style=\"text-align: right;\"> 0.00157071</td><td style=\"text-align: right;\"> 0.00485702 </td><td style=\"text-align: right;\">-0.00263045 </td><td style=\"text-align: right;\">-0.00288183 </td><td style=\"text-align: right;\"> 0.00362469 </td><td style=\"text-align: right;\">-0.00445791 </td><td style=\"text-align: right;\">-0.00411227 </td><td style=\"text-align: right;\"> 0.00342177 </td><td style=\"text-align: right;\"> 0.00192781 </td><td style=\"text-align: right;\"> 0.00387057 </td><td style=\"text-align: right;\">-0.000269417</td><td style=\"text-align: right;\"> 0.00159548 </td><td style=\"text-align: right;\">-0.00482088</td><td style=\"text-align: right;\">-0.00444038</td><td style=\"text-align: right;\"> 0.000358523</td><td style=\"text-align: right;\">-0.00474268 </td><td style=\"text-align: right;\">-0.00489143 </td><td style=\"text-align: right;\">-0.00227294 </td><td style=\"text-align: right;\">-0.00123248</td><td style=\"text-align: right;\">-0.000276324</td><td style=\"text-align: right;\">-0.000245363</td><td style=\"text-align: right;\"> 0.00166363 </td><td style=\"text-align: right;\">-0.00497138</td><td style=\"text-align: right;\"> 0.00154115 </td><td style=\"text-align: right;\">-0.00266345 </td><td style=\"text-align: right;\"> 0.00451255 </td><td style=\"text-align: right;\"> 0.00402555 </td><td style=\"text-align: right;\">-0.00187253 </td><td style=\"text-align: right;\">-0.000997721</td><td style=\"text-align: right;\">-0.00284166 </td><td style=\"text-align: right;\">-0.00221285 </td><td style=\"text-align: right;\">-0.00337741 </td><td style=\"text-align: right;\"> 0.000367843</td><td style=\"text-align: right;\">-0.000565881</td><td style=\"text-align: right;\">-0.000213032</td><td style=\"text-align: right;\"> 0.00194571 </td><td style=\"text-align: right;\"> 0.00414291 </td><td style=\"text-align: right;\"> 0.00352493 </td></tr>\n",
       "<tr><td>B0041CIR62 </td><td>A16I6WJUEBJ1C3</td><td>okay but not as healthy as it appears </td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">                       1</td><td style=\"text-align: right;\">138997</td><td>doctorsirena &quot;doctorsirena&quot;                     </td><td style=\"text-align: right;\">                     1</td><td style=\"text-align: right;\">1.34369e+09</td><td>I am always looking for healthier, whole grain versions of foods I enjoy.  Unfortunately, these Peacock brand noodles are yet another food masquerading as healthy.  The product title in big letters on the front says &quot;Brown Rice Vermicelli&quot;, making the consumer think &quot;this is made with brown rice, so it should be a healthy choice&quot;.  But the first indication that it is not is when looking at the fiber content on the nutrition facts - only 0.6g per 2oz serving.  Then onto the ingredients list to see why so low... contains brown rice, sago starch and water.  The sago starch comes from palms and must not have much (if any) fiber.&lt;br /&gt;&lt;br /&gt;The Annie Chun&#x27;s Maifun Brown Rice Noodles (sold on Amazon and in my local healthy grocer) has become one of my staples and is my frame of reference when comparing to the Peacock brand.  The Annie Chun&#x27;s product is made with 100% whole grain, with ingredients brown rice flour and water.  Per 2oz serving, it has 4g fiber and pretty much the same calories and other nutrients as the Peacock brand.&lt;br /&gt;&lt;br /&gt;If you do try this Peacock brand noodles and have not used rice noodles before, you will need to seek guidance elsewhere on preparation.  As others have pointed out, the Peacock package gives almost no directions on how to prepare the product, aside from a brief mention in the recipes (in the header text it does say that they are &quot;easy-to-cook&quot; but does not say how).  It also contains a very strange recipe for rice noodles: Aglio Olio style - this is an Italian recipe for noodles with olive oil/garlic/sprinkled with grated cheese that I think would not be very tasty.  The second recipe appears to be for a soup with veggie strips.  Neither recipe gives amounts or much direction.  In comparison, the Annie Chun&#x27;s package gives clear, specific directions on rice noodle preparation and two recipes.&lt;br /&gt;&lt;br /&gt;I use rice noodles = maifun = rice sticks = sometimes called vermicelli for making the Vietnamese salad &quot;bun tofu&quot;, to serve with stir-fried veggies or in lettuce rolls.  They can also be used in spring rolls/egg rolls.  When cooking with thin rice noodles, be careful not to oversoak/overcook/overmix or they tend to disintegrate.  Asian rice noodle vermicelli (maifun) are not the same as Italian vermicelli and are not readily interchangeable.  If making an Italian recipe, the best results would be expected from Italian pasta and not maifun.&lt;br /&gt;&lt;br /&gt;A few final notes...  Both Peacock and Annie Chun&#x27;s brown rice noodles are gluten free.  The Peacock is made in Singapore and the Annie Chun&#x27;s in Thailand.  The Peacock noodles do taste fine (kind of bland), but so do the Annie Chun&#x27;s.  At this time, they are both approximately the same price.  Peacock come in an plastic bag with some noodle crushage upon shipping; Annie Chun&#x27;s are perfect upon removal from their cellophane bag in a box.  Overall, I highly recommend the Annie Chun&#x27;s Maifun as a healthier option over the Peacock brand.  On a related note, the Annie Chun&#x27;s soba and brown rice pad thai noodles are also excellent.&lt;br /&gt;&lt;br /&gt;Rating for this product: 2.5 stars rounded down to 2 stars.</td><td style=\"text-align: right;\">               0</td><td style=\"text-align: right;\">-0.0022345  </td><td style=\"text-align: right;\">-0.00118234 </td><td style=\"text-align: right;\">-0.00473625 </td><td style=\"text-align: right;\">-0.00484359 </td><td style=\"text-align: right;\">-0.00254091 </td><td style=\"text-align: right;\">-0.00196595 </td><td style=\"text-align: right;\"> 0.0039012  </td><td style=\"text-align: right;\">-0.00366686</td><td style=\"text-align: right;\">-0.00161224 </td><td style=\"text-align: right;\"> 0.0034187 </td><td style=\"text-align: right;\"> 0.00208731 </td><td style=\"text-align: right;\">-0.00262133 </td><td style=\"text-align: right;\">-0.00338837</td><td style=\"text-align: right;\">-0.00357154</td><td style=\"text-align: right;\"> 0.000794502</td><td style=\"text-align: right;\">-0.00225998</td><td style=\"text-align: right;\"> 0.0048756  </td><td style=\"text-align: right;\"> 0.00418993</td><td style=\"text-align: right;\"> 0.00108136 </td><td style=\"text-align: right;\">-0.00142661</td><td style=\"text-align: right;\"> 0.00414992 </td><td style=\"text-align: right;\"> 0.000362012</td><td style=\"text-align: right;\"> 0.00471873 </td><td style=\"text-align: right;\"> 0.00272846 </td><td style=\"text-align: right;\">-0.00458419</td><td style=\"text-align: right;\"> 0.00281251 </td><td style=\"text-align: right;\"> 0.00178914 </td><td style=\"text-align: right;\">-0.00155722 </td><td style=\"text-align: right;\"> 0.00108952 </td><td style=\"text-align: right;\"> 0.00467054 </td><td style=\"text-align: right;\"> 0.0029314 </td><td style=\"text-align: right;\"> 0.0013397  </td><td style=\"text-align: right;\">-0.00434807 </td><td style=\"text-align: right;\">-0.0041941  </td><td style=\"text-align: right;\">-0.00392297 </td><td style=\"text-align: right;\">-0.00470489 </td><td style=\"text-align: right;\"> 0.00103919 </td><td style=\"text-align: right;\">-0.0031207  </td><td style=\"text-align: right;\">-0.00246596 </td><td style=\"text-align: right;\">-0.000463113</td><td style=\"text-align: right;\">-0.00120053 </td><td style=\"text-align: right;\"> 0.00404016 </td><td style=\"text-align: right;\">-0.00139923 </td><td style=\"text-align: right;\"> 0.00086494</td><td style=\"text-align: right;\">-0.00448568 </td><td style=\"text-align: right;\"> 0.00377154 </td><td style=\"text-align: right;\">-0.0039325 </td><td style=\"text-align: right;\">-0.00473339 </td><td style=\"text-align: right;\">-0.000363612</td><td style=\"text-align: right;\">-0.00353149 </td><td style=\"text-align: right;\"> 0.0013043  </td><td style=\"text-align: right;\"> 0.00367225 </td><td style=\"text-align: right;\">-0.000783298</td><td style=\"text-align: right;\"> 0.00148771 </td><td style=\"text-align: right;\">-0.00307635 </td><td style=\"text-align: right;\">-0.00209044 </td><td style=\"text-align: right;\">-0.00194127 </td><td style=\"text-align: right;\">-0.00044396 </td><td style=\"text-align: right;\"> 0.000763034</td><td style=\"text-align: right;\"> 0.00363327 </td><td style=\"text-align: right;\"> 0.00265388 </td><td style=\"text-align: right;\"> 0.00345427 </td><td style=\"text-align: right;\"> 0.00422608</td><td style=\"text-align: right;\">-0.00112495 </td><td style=\"text-align: right;\"> 0.00269038 </td><td style=\"text-align: right;\">-0.001819   </td><td style=\"text-align: right;\"> 0.00426291 </td><td style=\"text-align: right;\">-0.000862681</td><td style=\"text-align: right;\">-0.000236038</td><td style=\"text-align: right;\"> 0.00164279 </td><td style=\"text-align: right;\"> 0.00351    </td><td style=\"text-align: right;\">-0.000171566</td><td style=\"text-align: right;\"> 0.00420559 </td><td style=\"text-align: right;\">-0.00409525 </td><td style=\"text-align: right;\">-0.00325636</td><td style=\"text-align: right;\"> 0.00119232</td><td style=\"text-align: right;\">-0.00170607 </td><td style=\"text-align: right;\"> 0.00337731 </td><td style=\"text-align: right;\">-0.000483345</td><td style=\"text-align: right;\"> 0.00192629 </td><td style=\"text-align: right;\">-0.00202633</td><td style=\"text-align: right;\">-0.00118933 </td><td style=\"text-align: right;\"> 0.00125069 </td><td style=\"text-align: right;\"> 0.0014383  </td><td style=\"text-align: right;\">-0.00411826</td><td style=\"text-align: right;\">-0.00277424 </td><td style=\"text-align: right;\"> 0.00343989 </td><td style=\"text-align: right;\">-0.000199534</td><td style=\"text-align: right;\">-0.000771156</td><td style=\"text-align: right;\"> 0.00254363 </td><td style=\"text-align: right;\">-4.86396e-05</td><td style=\"text-align: right;\"> 0.00403402 </td><td style=\"text-align: right;\"> 0.00125157 </td><td style=\"text-align: right;\">-0.0014224  </td><td style=\"text-align: right;\">-0.00275629 </td><td style=\"text-align: right;\">-0.00439488 </td><td style=\"text-align: right;\">-0.000116479</td><td style=\"text-align: right;\"> 0.00236022 </td><td style=\"text-align: right;\">-0.00482505 </td><td style=\"text-align: right;\"> 0.0018054  </td></tr>\n",
       "<tr><td>B001R3BQFW </td><td>AM50E42AFUVNL </td><td>Taste great.                          </td><td style=\"text-align: right;\">      5</td><td style=\"text-align: right;\">                       0</td><td style=\"text-align: right;\">126555</td><td>T. Higley &quot;Tina&quot;                                </td><td style=\"text-align: right;\">                     0</td><td style=\"text-align: right;\">1.32356e+09</td><td>I have tried many different drink mix, this is the best tasting by far. It does not have the after taste of the sweetener and I really like it, it is pretty strong, so I use a big water bottle (20 oz) for one tube, it still a little stronger than I like, but it is just my taste.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     </td><td style=\"text-align: right;\">               1</td><td style=\"text-align: right;\"> 0.00123396 </td><td style=\"text-align: right;\"> 0.000301933</td><td style=\"text-align: right;\"> 0.00114138 </td><td style=\"text-align: right;\"> 0.00265743 </td><td style=\"text-align: right;\"> 0.00382718 </td><td style=\"text-align: right;\">-0.000200744</td><td style=\"text-align: right;\">-0.00409601 </td><td style=\"text-align: right;\">-0.0033307 </td><td style=\"text-align: right;\">-0.00270751 </td><td style=\"text-align: right;\"> 0.00187478</td><td style=\"text-align: right;\">-0.00099492 </td><td style=\"text-align: right;\"> 0.000969768</td><td style=\"text-align: right;\"> 0.00181785</td><td style=\"text-align: right;\">-0.00362598</td><td style=\"text-align: right;\"> 0.000566837</td><td style=\"text-align: right;\">-0.00381392</td><td style=\"text-align: right;\">-0.00300695 </td><td style=\"text-align: right;\">-0.00191247</td><td style=\"text-align: right;\"> 0.00300366 </td><td style=\"text-align: right;\">-0.00336498</td><td style=\"text-align: right;\">-0.00432527 </td><td style=\"text-align: right;\"> 0.00119418 </td><td style=\"text-align: right;\">-0.00488453 </td><td style=\"text-align: right;\"> 0.000650447</td><td style=\"text-align: right;\">-0.00144295</td><td style=\"text-align: right;\"> 0.00310596 </td><td style=\"text-align: right;\"> 0.000236916</td><td style=\"text-align: right;\">-0.00481672 </td><td style=\"text-align: right;\">-0.00254606 </td><td style=\"text-align: right;\">-0.00462366 </td><td style=\"text-align: right;\"> 0.00475575</td><td style=\"text-align: right;\">-0.000889771</td><td style=\"text-align: right;\"> 0.00375216 </td><td style=\"text-align: right;\"> 0.000796679</td><td style=\"text-align: right;\"> 0.00468825 </td><td style=\"text-align: right;\">-0.00285035 </td><td style=\"text-align: right;\">-0.00210191 </td><td style=\"text-align: right;\">-0.000838894</td><td style=\"text-align: right;\">-0.00174631 </td><td style=\"text-align: right;\"> 0.00209886 </td><td style=\"text-align: right;\"> 0.00267867 </td><td style=\"text-align: right;\"> 0.00151349 </td><td style=\"text-align: right;\"> 0.000270887</td><td style=\"text-align: right;\">-0.00183741</td><td style=\"text-align: right;\"> 0.00250297 </td><td style=\"text-align: right;\">-0.00206031 </td><td style=\"text-align: right;\">-0.00436664</td><td style=\"text-align: right;\"> 0.000507985</td><td style=\"text-align: right;\"> 0.0015475  </td><td style=\"text-align: right;\"> 0.00389932 </td><td style=\"text-align: right;\"> 0.00459838 </td><td style=\"text-align: right;\"> 0.00136654 </td><td style=\"text-align: right;\">-0.00448985 </td><td style=\"text-align: right;\">-0.000330303</td><td style=\"text-align: right;\"> 0.00373779 </td><td style=\"text-align: right;\"> 0.00285466 </td><td style=\"text-align: right;\"> 0.00365732 </td><td style=\"text-align: right;\"> 0.00129211 </td><td style=\"text-align: right;\">-0.000667081</td><td style=\"text-align: right;\">-0.00282556 </td><td style=\"text-align: right;\">-0.000703698</td><td style=\"text-align: right;\"> 0.00244934 </td><td style=\"text-align: right;\">-0.00309064</td><td style=\"text-align: right;\">-0.00281051 </td><td style=\"text-align: right;\">-0.00397981 </td><td style=\"text-align: right;\">-0.00174585 </td><td style=\"text-align: right;\">-0.00489213 </td><td style=\"text-align: right;\"> 0.00237766 </td><td style=\"text-align: right;\">-0.00340813 </td><td style=\"text-align: right;\">-0.00306574 </td><td style=\"text-align: right;\"> 0.00301165 </td><td style=\"text-align: right;\">-0.00235627 </td><td style=\"text-align: right;\">-0.00121219 </td><td style=\"text-align: right;\">-0.00305666 </td><td style=\"text-align: right;\"> 0.00260114</td><td style=\"text-align: right;\">-0.00350915</td><td style=\"text-align: right;\">-0.0022534  </td><td style=\"text-align: right;\">-0.000735179</td><td style=\"text-align: right;\">-6.73042e-05</td><td style=\"text-align: right;\">-0.00317106 </td><td style=\"text-align: right;\">-0.00302512</td><td style=\"text-align: right;\">-0.000345416</td><td style=\"text-align: right;\">-0.0021387  </td><td style=\"text-align: right;\"> 0.00176393 </td><td style=\"text-align: right;\"> 0.00316998</td><td style=\"text-align: right;\"> 0.00484468 </td><td style=\"text-align: right;\">-0.00252975 </td><td style=\"text-align: right;\"> 6.737e-05  </td><td style=\"text-align: right;\"> 0.00185976 </td><td style=\"text-align: right;\"> 0.00315663 </td><td style=\"text-align: right;\">-0.00283867 </td><td style=\"text-align: right;\">-0.00463886 </td><td style=\"text-align: right;\">-0.0013722  </td><td style=\"text-align: right;\"> 0.00199899 </td><td style=\"text-align: right;\">-0.00138835 </td><td style=\"text-align: right;\"> 0.00382214 </td><td style=\"text-align: right;\">-0.00120284 </td><td style=\"text-align: right;\"> 0.00273947 </td><td style=\"text-align: right;\"> 0.0030877  </td><td style=\"text-align: right;\"> 0.00293027 </td></tr>\n",
       "<tr><td>B005HGAV8I </td><td>A2I5KDNOESGJ1H</td><td>variety galore                        </td><td style=\"text-align: right;\">      5</td><td style=\"text-align: right;\">                       1</td><td style=\"text-align: right;\">438837</td><td>TJ                                              </td><td style=\"text-align: right;\">                     1</td><td style=\"text-align: right;\">1.33402e+09</td><td>This is my favorite item to order for my Keurig. There are so many flavors, my finicky palate never gets bored!  The only downside is there are probably 5-6 decaf varieties.  I don&#x27;t drink decaf (I REQUIRE copious amounts of caffeine), so they sit on the shelf...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     </td><td style=\"text-align: right;\">               1</td><td style=\"text-align: right;\">-0.00375343 </td><td style=\"text-align: right;\">-0.00393268 </td><td style=\"text-align: right;\"> 0.00376161 </td><td style=\"text-align: right;\"> 0.00256412 </td><td style=\"text-align: right;\"> 0.00214072 </td><td style=\"text-align: right;\"> 0.000653193</td><td style=\"text-align: right;\"> 0.00183313 </td><td style=\"text-align: right;\"> 0.00352902</td><td style=\"text-align: right;\"> 0.00140252 </td><td style=\"text-align: right;\"> 0.00174463</td><td style=\"text-align: right;\"> 0.000954776</td><td style=\"text-align: right;\">-0.00099104 </td><td style=\"text-align: right;\"> 0.00459114</td><td style=\"text-align: right;\">-0.00490181</td><td style=\"text-align: right;\">-0.00328535 </td><td style=\"text-align: right;\">-0.00365145</td><td style=\"text-align: right;\"> 0.00307499 </td><td style=\"text-align: right;\"> 0.00294675</td><td style=\"text-align: right;\"> 0.0012551  </td><td style=\"text-align: right;\"> 0.00194888</td><td style=\"text-align: right;\">-0.000315908</td><td style=\"text-align: right;\"> 0.00407931 </td><td style=\"text-align: right;\"> 0.000905928</td><td style=\"text-align: right;\">-0.00292016 </td><td style=\"text-align: right;\"> 0.00425359</td><td style=\"text-align: right;\">-0.00412502 </td><td style=\"text-align: right;\">-0.00181654 </td><td style=\"text-align: right;\"> 0.00450063 </td><td style=\"text-align: right;\"> 0.000308167</td><td style=\"text-align: right;\">-0.00321498 </td><td style=\"text-align: right;\"> 0.00145849</td><td style=\"text-align: right;\">-0.00124448 </td><td style=\"text-align: right;\">-0.00118156 </td><td style=\"text-align: right;\"> 0.00171784 </td><td style=\"text-align: right;\">-0.000325824</td><td style=\"text-align: right;\">-0.00308182 </td><td style=\"text-align: right;\"> 0.00100014 </td><td style=\"text-align: right;\"> 0.00479069 </td><td style=\"text-align: right;\">-0.00354579 </td><td style=\"text-align: right;\">-0.00318747 </td><td style=\"text-align: right;\"> 0.00267011 </td><td style=\"text-align: right;\"> 0.00314672 </td><td style=\"text-align: right;\"> 0.0022169  </td><td style=\"text-align: right;\">-0.00346791</td><td style=\"text-align: right;\">-0.000689808</td><td style=\"text-align: right;\">-0.00297246 </td><td style=\"text-align: right;\">-0.00271654</td><td style=\"text-align: right;\"> 0.00481185 </td><td style=\"text-align: right;\">-0.00216024 </td><td style=\"text-align: right;\">-0.00312251 </td><td style=\"text-align: right;\"> 0.00109544 </td><td style=\"text-align: right;\"> 0.00406831 </td><td style=\"text-align: right;\"> 0.00339785 </td><td style=\"text-align: right;\">-0.0033081  </td><td style=\"text-align: right;\">-0.00238185 </td><td style=\"text-align: right;\"> 0.000332508</td><td style=\"text-align: right;\">-0.000439839</td><td style=\"text-align: right;\">-0.00266257 </td><td style=\"text-align: right;\">-0.0020657  </td><td style=\"text-align: right;\"> 0.00409712 </td><td style=\"text-align: right;\"> 0.000192648</td><td style=\"text-align: right;\">-0.00290522 </td><td style=\"text-align: right;\">-0.00452122</td><td style=\"text-align: right;\">-0.00314381 </td><td style=\"text-align: right;\"> 0.00244607 </td><td style=\"text-align: right;\">-0.00498    </td><td style=\"text-align: right;\">-0.00449144 </td><td style=\"text-align: right;\">-0.00422764 </td><td style=\"text-align: right;\">-0.000839038</td><td style=\"text-align: right;\"> 0.00272842 </td><td style=\"text-align: right;\">-0.00454304 </td><td style=\"text-align: right;\">-0.00227237 </td><td style=\"text-align: right;\"> 0.00461924 </td><td style=\"text-align: right;\">-0.00407978 </td><td style=\"text-align: right;\"> 0.00257298</td><td style=\"text-align: right;\"> 0.00130447</td><td style=\"text-align: right;\">-0.000276626</td><td style=\"text-align: right;\"> 0.000729811</td><td style=\"text-align: right;\">-0.00442137 </td><td style=\"text-align: right;\">-0.00342739 </td><td style=\"text-align: right;\">-0.00265551</td><td style=\"text-align: right;\">-0.000302081</td><td style=\"text-align: right;\">-0.000438805</td><td style=\"text-align: right;\"> 0.00114224 </td><td style=\"text-align: right;\"> 0.00220955</td><td style=\"text-align: right;\"> 0.00019091 </td><td style=\"text-align: right;\">-0.00117184 </td><td style=\"text-align: right;\">-0.000975595</td><td style=\"text-align: right;\">-0.00426036 </td><td style=\"text-align: right;\">-0.00334755 </td><td style=\"text-align: right;\"> 0.00169898 </td><td style=\"text-align: right;\">-0.0024145  </td><td style=\"text-align: right;\">-0.00413543 </td><td style=\"text-align: right;\">-0.00231128 </td><td style=\"text-align: right;\"> 0.0049212  </td><td style=\"text-align: right;\">-0.00476102 </td><td style=\"text-align: right;\">-0.00158452 </td><td style=\"text-align: right;\">-0.00319514 </td><td style=\"text-align: right;\"> 0.000988775</td><td style=\"text-align: right;\">-0.00448164 </td></tr>\n",
       "<tr><td>B000GFYRHQ </td><td>A3A7YUR6FS6ZCI</td><td>Bigelow Earl Grey Green Tea           </td><td style=\"text-align: right;\">      5</td><td style=\"text-align: right;\">                       0</td><td style=\"text-align: right;\">245379</td><td>Tea Lover                                       </td><td style=\"text-align: right;\">                     0</td><td style=\"text-align: right;\">1.17841e+09</td><td>Tastes like Earl Grey, but it&#x27;s green tea so it&#x27;s healthier.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                </td><td style=\"text-align: right;\">               1</td><td style=\"text-align: right;\"> 0.000883576</td><td style=\"text-align: right;\"> 0.00416768 </td><td style=\"text-align: right;\"> 0.00241078 </td><td style=\"text-align: right;\"> 0.0024785  </td><td style=\"text-align: right;\"> 0.00251729 </td><td style=\"text-align: right;\"> 0.00404526 </td><td style=\"text-align: right;\"> 0.00127415 </td><td style=\"text-align: right;\"> 0.00373964</td><td style=\"text-align: right;\">-0.000536183</td><td style=\"text-align: right;\">-0.00409837</td><td style=\"text-align: right;\"> 0.000343285</td><td style=\"text-align: right;\">-0.00276207 </td><td style=\"text-align: right;\">-0.00360077</td><td style=\"text-align: right;\">-0.00134928</td><td style=\"text-align: right;\">-0.00272092 </td><td style=\"text-align: right;\"> 0.00401039</td><td style=\"text-align: right;\">-0.000528815</td><td style=\"text-align: right;\"> 0.00404991</td><td style=\"text-align: right;\">-0.00149153 </td><td style=\"text-align: right;\">-0.00165725</td><td style=\"text-align: right;\"> 0.00374201 </td><td style=\"text-align: right;\">-0.00250871 </td><td style=\"text-align: right;\"> 0.00180705 </td><td style=\"text-align: right;\">-0.00155262 </td><td style=\"text-align: right;\"> 0.0012568 </td><td style=\"text-align: right;\">-0.00384055 </td><td style=\"text-align: right;\">-0.00372583 </td><td style=\"text-align: right;\">-0.000703169</td><td style=\"text-align: right;\"> 0.00161199 </td><td style=\"text-align: right;\">-0.00415082 </td><td style=\"text-align: right;\"> 0.00483041</td><td style=\"text-align: right;\">-0.000387938</td><td style=\"text-align: right;\">-0.000123403</td><td style=\"text-align: right;\"> 0.00248269 </td><td style=\"text-align: right;\">-0.00194829 </td><td style=\"text-align: right;\">-0.00102209 </td><td style=\"text-align: right;\"> 0.000590692</td><td style=\"text-align: right;\"> 0.00303491 </td><td style=\"text-align: right;\">-0.000781513</td><td style=\"text-align: right;\"> 0.00167915 </td><td style=\"text-align: right;\"> 0.00418578 </td><td style=\"text-align: right;\"> 0.00440761 </td><td style=\"text-align: right;\">-0.00133484 </td><td style=\"text-align: right;\"> 0.00382828</td><td style=\"text-align: right;\"> 0.00341748 </td><td style=\"text-align: right;\"> 0.00362067 </td><td style=\"text-align: right;\">-0.00464635</td><td style=\"text-align: right;\">-0.00407653 </td><td style=\"text-align: right;\">-0.00244232 </td><td style=\"text-align: right;\">-0.00124951 </td><td style=\"text-align: right;\">-0.00220171 </td><td style=\"text-align: right;\"> 0.00497627 </td><td style=\"text-align: right;\">-0.00496104 </td><td style=\"text-align: right;\">-0.000367554</td><td style=\"text-align: right;\"> 0.00179864 </td><td style=\"text-align: right;\"> 0.00465319 </td><td style=\"text-align: right;\"> 0.00415352 </td><td style=\"text-align: right;\"> 0.00277194 </td><td style=\"text-align: right;\"> 0.000575014</td><td style=\"text-align: right;\"> 0.00231091 </td><td style=\"text-align: right;\">-0.00138146 </td><td style=\"text-align: right;\"> 0.00170772 </td><td style=\"text-align: right;\"> 0.00086127</td><td style=\"text-align: right;\">-0.00125835 </td><td style=\"text-align: right;\"> 0.000788935</td><td style=\"text-align: right;\">-0.00200379 </td><td style=\"text-align: right;\"> 0.00329121 </td><td style=\"text-align: right;\">-0.000578574</td><td style=\"text-align: right;\"> 3.7214e-05 </td><td style=\"text-align: right;\"> 0.00490456 </td><td style=\"text-align: right;\"> 0.0026317  </td><td style=\"text-align: right;\">-0.00439163 </td><td style=\"text-align: right;\"> 0.00408751 </td><td style=\"text-align: right;\">-0.000127621</td><td style=\"text-align: right;\"> 0.00127612</td><td style=\"text-align: right;\">-0.00405302</td><td style=\"text-align: right;\">-0.00300455 </td><td style=\"text-align: right;\">-0.00181316 </td><td style=\"text-align: right;\"> 0.000731965</td><td style=\"text-align: right;\">-0.00368531 </td><td style=\"text-align: right;\"> 0.00100137</td><td style=\"text-align: right;\">-0.00293142 </td><td style=\"text-align: right;\"> 0.00325013 </td><td style=\"text-align: right;\">-0.00343161 </td><td style=\"text-align: right;\"> 0.00300494</td><td style=\"text-align: right;\"> 0.000280863</td><td style=\"text-align: right;\">-0.00339996 </td><td style=\"text-align: right;\">-0.000524465</td><td style=\"text-align: right;\"> 0.00339028 </td><td style=\"text-align: right;\"> 0.00367251 </td><td style=\"text-align: right;\">-0.00300171 </td><td style=\"text-align: right;\"> 0.00181966 </td><td style=\"text-align: right;\"> 0.00206239 </td><td style=\"text-align: right;\">-0.00271772 </td><td style=\"text-align: right;\"> 0.000709735</td><td style=\"text-align: right;\"> 0.000230888</td><td style=\"text-align: right;\"> 0.00381006 </td><td style=\"text-align: right;\">-0.000897656</td><td style=\"text-align: right;\">-0.000202455</td><td style=\"text-align: right;\">-0.00426461 </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate a vector for each review\n",
    "review_vecs = h2o.H2OFrame(word2vec_model.transform([pdf.fillna(\"\")['Text']]))\n",
    "# Add the review vectors to the original dataframe\n",
    "# Add aggregated word embeddings \n",
    "ext_reviews = reviews.cbind(review_vecs)\n",
    "ext_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: GBM with Review vectors\n",
    "<blockquote>\n",
    "    Now we can train a GBM like before, but include the review vectors. This should hopefully increase improvement! We'll log everything to mlflow so we can compare the results.\n",
    "    </i></br><footer>Splice Machine</footer></blockquote><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Code Block train_time... gbm Model Build progress: |███████████████████████████████████████████████| 100%\n",
      "Done.\n",
      "Code Block train_time:\n",
      "Ran in 10.978 secs\n",
      "Ran in 0.183 mins\n",
      "Saving artifact of size: 1593.21 KB to Splice Machine DB\n",
      "Saving artifact of size: 761.135 KB to Splice Machine DB\n",
      "Model Details\n",
      "=============\n",
      "H2OGradientBoostingEstimator :  Gradient Boosting Machine\n",
      "Model Key:  gbm_embeddings.hex\n",
      "\n",
      "\n",
      "Model Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>number_of_trees</th>\n",
       "      <th>number_of_internal_trees</th>\n",
       "      <th>model_size_in_bytes</th>\n",
       "      <th>min_depth</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>mean_depth</th>\n",
       "      <th>min_leaves</th>\n",
       "      <th>max_leaves</th>\n",
       "      <th>mean_leaves</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>22697.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>29.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     number_of_trees  number_of_internal_trees  model_size_in_bytes  \\\n",
       "0               50.0                      50.0              22697.0   \n",
       "\n",
       "   min_depth  max_depth  mean_depth  min_leaves  max_leaves  mean_leaves  \n",
       "0        5.0        5.0         5.0        20.0        32.0         29.4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.13669621832053175\n",
      "RMSE: 0.36972451679667084\n",
      "LogLoss: 0.4370177188419529\n",
      "Mean Per-Class Error: 0.29930198463142377\n",
      "AUC: 0.7679606603316217\n",
      "AUCPR: 0.9089462147440353\n",
      "Gini: 0.5359213206632434\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5280522001695236: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>Error</th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4052.0</td>\n",
       "      <td>11331.0</td>\n",
       "      <td>0.7366</td>\n",
       "      <td>(11331.0/15383.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1268.0</td>\n",
       "      <td>53408.0</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>(1268.0/54676.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total</td>\n",
       "      <td>5320.0</td>\n",
       "      <td>64739.0</td>\n",
       "      <td>0.1798</td>\n",
       "      <td>(12599.0/70059.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0        1   Error                Rate\n",
       "0      0  4052.0  11331.0  0.7366   (11331.0/15383.0)\n",
       "1      1  1268.0  53408.0  0.0232    (1268.0/54676.0)\n",
       "2  Total  5320.0  64739.0  0.1798   (12599.0/70059.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>threshold</th>\n",
       "      <th>value</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>max f1</td>\n",
       "      <td>0.528052</td>\n",
       "      <td>0.894494</td>\n",
       "      <td>271.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max f2</td>\n",
       "      <td>0.288617</td>\n",
       "      <td>0.949583</td>\n",
       "      <td>346.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>max f0point5</td>\n",
       "      <td>0.762155</td>\n",
       "      <td>0.866466</td>\n",
       "      <td>163.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>max accuracy</td>\n",
       "      <td>0.603146</td>\n",
       "      <td>0.821679</td>\n",
       "      <td>241.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max precision</td>\n",
       "      <td>0.944390</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>max recall</td>\n",
       "      <td>0.113336</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>394.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>max specificity</td>\n",
       "      <td>0.944390</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>max absolute_mcc</td>\n",
       "      <td>0.624071</td>\n",
       "      <td>0.399899</td>\n",
       "      <td>231.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>max min_per_class_accuracy</td>\n",
       "      <td>0.809620</td>\n",
       "      <td>0.690230</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max mean_per_class_accuracy</td>\n",
       "      <td>0.789365</td>\n",
       "      <td>0.700698</td>\n",
       "      <td>141.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>max tns</td>\n",
       "      <td>0.944390</td>\n",
       "      <td>15383.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>max fns</td>\n",
       "      <td>0.944390</td>\n",
       "      <td>54673.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>max fps</td>\n",
       "      <td>0.072948</td>\n",
       "      <td>15383.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>max tps</td>\n",
       "      <td>0.113336</td>\n",
       "      <td>54676.000000</td>\n",
       "      <td>394.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>max tnr</td>\n",
       "      <td>0.944390</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>max fnr</td>\n",
       "      <td>0.944390</td>\n",
       "      <td>0.999945</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>max fpr</td>\n",
       "      <td>0.072948</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>max tpr</td>\n",
       "      <td>0.113336</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>394.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         metric  threshold         value    idx\n",
       "0                        max f1   0.528052      0.894494  271.0\n",
       "1                        max f2   0.288617      0.949583  346.0\n",
       "2                  max f0point5   0.762155      0.866466  163.0\n",
       "3                  max accuracy   0.603146      0.821679  241.0\n",
       "4                 max precision   0.944390      1.000000    0.0\n",
       "5                    max recall   0.113336      1.000000  394.0\n",
       "6               max specificity   0.944390      1.000000    0.0\n",
       "7              max absolute_mcc   0.624071      0.399899  231.0\n",
       "8    max min_per_class_accuracy   0.809620      0.690230  120.0\n",
       "9   max mean_per_class_accuracy   0.789365      0.700698  141.0\n",
       "10                      max tns   0.944390  15383.000000    0.0\n",
       "11                      max fns   0.944390  54673.000000    0.0\n",
       "12                      max fps   0.072948  15383.000000  399.0\n",
       "13                      max tps   0.113336  54676.000000  394.0\n",
       "14                      max tnr   0.944390      1.000000    0.0\n",
       "15                      max fnr   0.944390      0.999945    0.0\n",
       "16                      max fpr   0.072948      1.000000  399.0\n",
       "17                      max tpr   0.113336      1.000000  394.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate: 78.04 %, avg score: 78.03 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>cumulative_data_fraction</th>\n",
       "      <th>lower_threshold</th>\n",
       "      <th>lift</th>\n",
       "      <th>cumulative_lift</th>\n",
       "      <th>response_rate</th>\n",
       "      <th>score</th>\n",
       "      <th>cumulative_response_rate</th>\n",
       "      <th>cumulative_score</th>\n",
       "      <th>capture_rate</th>\n",
       "      <th>cumulative_capture_rate</th>\n",
       "      <th>gain</th>\n",
       "      <th>cumulative_gain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0.010006</td>\n",
       "      <td>0.919004</td>\n",
       "      <td>1.266725</td>\n",
       "      <td>1.266725</td>\n",
       "      <td>0.988588</td>\n",
       "      <td>0.924269</td>\n",
       "      <td>0.988588</td>\n",
       "      <td>0.924269</td>\n",
       "      <td>0.012675</td>\n",
       "      <td>0.012675</td>\n",
       "      <td>26.672522</td>\n",
       "      <td>26.672522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>0.020012</td>\n",
       "      <td>0.913625</td>\n",
       "      <td>1.263069</td>\n",
       "      <td>1.264897</td>\n",
       "      <td>0.985735</td>\n",
       "      <td>0.916089</td>\n",
       "      <td>0.987161</td>\n",
       "      <td>0.920179</td>\n",
       "      <td>0.012638</td>\n",
       "      <td>0.025313</td>\n",
       "      <td>26.306944</td>\n",
       "      <td>26.489733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>0.030003</td>\n",
       "      <td>0.909859</td>\n",
       "      <td>1.250230</td>\n",
       "      <td>1.260013</td>\n",
       "      <td>0.975714</td>\n",
       "      <td>0.911638</td>\n",
       "      <td>0.983349</td>\n",
       "      <td>0.917335</td>\n",
       "      <td>0.012492</td>\n",
       "      <td>0.037805</td>\n",
       "      <td>25.022985</td>\n",
       "      <td>26.001282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>0.040009</td>\n",
       "      <td>0.906811</td>\n",
       "      <td>1.239307</td>\n",
       "      <td>1.254834</td>\n",
       "      <td>0.967190</td>\n",
       "      <td>0.908263</td>\n",
       "      <td>0.979308</td>\n",
       "      <td>0.915066</td>\n",
       "      <td>0.012400</td>\n",
       "      <td>0.050205</td>\n",
       "      <td>23.930692</td>\n",
       "      <td>25.483450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.904326</td>\n",
       "      <td>1.226433</td>\n",
       "      <td>1.249159</td>\n",
       "      <td>0.957143</td>\n",
       "      <td>0.905560</td>\n",
       "      <td>0.974879</td>\n",
       "      <td>0.913167</td>\n",
       "      <td>0.012254</td>\n",
       "      <td>0.062459</td>\n",
       "      <td>22.643338</td>\n",
       "      <td>24.915914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>6</td>\n",
       "      <td>0.100001</td>\n",
       "      <td>0.895037</td>\n",
       "      <td>1.221725</td>\n",
       "      <td>1.235442</td>\n",
       "      <td>0.953468</td>\n",
       "      <td>0.899514</td>\n",
       "      <td>0.964174</td>\n",
       "      <td>0.906340</td>\n",
       "      <td>0.061087</td>\n",
       "      <td>0.123546</td>\n",
       "      <td>22.172519</td>\n",
       "      <td>23.544217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>7</td>\n",
       "      <td>0.150002</td>\n",
       "      <td>0.885746</td>\n",
       "      <td>1.174905</td>\n",
       "      <td>1.215263</td>\n",
       "      <td>0.916928</td>\n",
       "      <td>0.890542</td>\n",
       "      <td>0.948425</td>\n",
       "      <td>0.901074</td>\n",
       "      <td>0.058746</td>\n",
       "      <td>0.182292</td>\n",
       "      <td>17.490458</td>\n",
       "      <td>21.526297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td>8</td>\n",
       "      <td>0.200003</td>\n",
       "      <td>0.873932</td>\n",
       "      <td>1.163565</td>\n",
       "      <td>1.202339</td>\n",
       "      <td>0.908079</td>\n",
       "      <td>0.879782</td>\n",
       "      <td>0.938339</td>\n",
       "      <td>0.895751</td>\n",
       "      <td>0.058179</td>\n",
       "      <td>0.240471</td>\n",
       "      <td>16.356522</td>\n",
       "      <td>20.233853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td>9</td>\n",
       "      <td>0.300004</td>\n",
       "      <td>0.854273</td>\n",
       "      <td>1.129364</td>\n",
       "      <td>1.178014</td>\n",
       "      <td>0.881387</td>\n",
       "      <td>0.864369</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.885291</td>\n",
       "      <td>0.112938</td>\n",
       "      <td>0.353409</td>\n",
       "      <td>12.936423</td>\n",
       "      <td>17.801377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "      <td>0.400006</td>\n",
       "      <td>0.836782</td>\n",
       "      <td>1.130644</td>\n",
       "      <td>1.166171</td>\n",
       "      <td>0.882387</td>\n",
       "      <td>0.844537</td>\n",
       "      <td>0.910113</td>\n",
       "      <td>0.875102</td>\n",
       "      <td>0.113066</td>\n",
       "      <td>0.466475</td>\n",
       "      <td>13.064448</td>\n",
       "      <td>16.617144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td></td>\n",
       "      <td>11</td>\n",
       "      <td>0.500007</td>\n",
       "      <td>0.823669</td>\n",
       "      <td>1.101564</td>\n",
       "      <td>1.153250</td>\n",
       "      <td>0.859692</td>\n",
       "      <td>0.830279</td>\n",
       "      <td>0.900029</td>\n",
       "      <td>0.866138</td>\n",
       "      <td>0.110158</td>\n",
       "      <td>0.576633</td>\n",
       "      <td>10.156449</td>\n",
       "      <td>15.325005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.599994</td>\n",
       "      <td>0.810067</td>\n",
       "      <td>1.072272</td>\n",
       "      <td>1.139755</td>\n",
       "      <td>0.836831</td>\n",
       "      <td>0.816768</td>\n",
       "      <td>0.889497</td>\n",
       "      <td>0.857910</td>\n",
       "      <td>0.107213</td>\n",
       "      <td>0.683847</td>\n",
       "      <td>7.227177</td>\n",
       "      <td>13.975528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0.699996</td>\n",
       "      <td>0.794190</td>\n",
       "      <td>1.037735</td>\n",
       "      <td>1.125181</td>\n",
       "      <td>0.809877</td>\n",
       "      <td>0.802814</td>\n",
       "      <td>0.878122</td>\n",
       "      <td>0.850039</td>\n",
       "      <td>0.103775</td>\n",
       "      <td>0.787622</td>\n",
       "      <td>3.773484</td>\n",
       "      <td>12.518063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>0.799997</td>\n",
       "      <td>0.755321</td>\n",
       "      <td>0.959274</td>\n",
       "      <td>1.104442</td>\n",
       "      <td>0.748644</td>\n",
       "      <td>0.779232</td>\n",
       "      <td>0.861937</td>\n",
       "      <td>0.841188</td>\n",
       "      <td>0.095929</td>\n",
       "      <td>0.883550</td>\n",
       "      <td>-4.072625</td>\n",
       "      <td>10.444190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td></td>\n",
       "      <td>15</td>\n",
       "      <td>0.899999</td>\n",
       "      <td>0.589092</td>\n",
       "      <td>0.788452</td>\n",
       "      <td>1.069331</td>\n",
       "      <td>0.615330</td>\n",
       "      <td>0.675578</td>\n",
       "      <td>0.834536</td>\n",
       "      <td>0.822787</td>\n",
       "      <td>0.078846</td>\n",
       "      <td>0.962397</td>\n",
       "      <td>-21.154831</td>\n",
       "      <td>6.933132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td></td>\n",
       "      <td>16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.069407</td>\n",
       "      <td>0.376028</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.293463</td>\n",
       "      <td>0.397910</td>\n",
       "      <td>0.780428</td>\n",
       "      <td>0.780299</td>\n",
       "      <td>0.037603</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-62.397201</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      group  cumulative_data_fraction  lower_threshold      lift  \\\n",
       "0         1                  0.010006         0.919004  1.266725   \n",
       "1         2                  0.020012         0.913625  1.263069   \n",
       "2         3                  0.030003         0.909859  1.250230   \n",
       "3         4                  0.040009         0.906811  1.239307   \n",
       "4         5                  0.050001         0.904326  1.226433   \n",
       "5         6                  0.100001         0.895037  1.221725   \n",
       "6         7                  0.150002         0.885746  1.174905   \n",
       "7         8                  0.200003         0.873932  1.163565   \n",
       "8         9                  0.300004         0.854273  1.129364   \n",
       "9        10                  0.400006         0.836782  1.130644   \n",
       "10       11                  0.500007         0.823669  1.101564   \n",
       "11       12                  0.599994         0.810067  1.072272   \n",
       "12       13                  0.699996         0.794190  1.037735   \n",
       "13       14                  0.799997         0.755321  0.959274   \n",
       "14       15                  0.899999         0.589092  0.788452   \n",
       "15       16                  1.000000         0.069407  0.376028   \n",
       "\n",
       "    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n",
       "0          1.266725       0.988588  0.924269                  0.988588   \n",
       "1          1.264897       0.985735  0.916089                  0.987161   \n",
       "2          1.260013       0.975714  0.911638                  0.983349   \n",
       "3          1.254834       0.967190  0.908263                  0.979308   \n",
       "4          1.249159       0.957143  0.905560                  0.974879   \n",
       "5          1.235442       0.953468  0.899514                  0.964174   \n",
       "6          1.215263       0.916928  0.890542                  0.948425   \n",
       "7          1.202339       0.908079  0.879782                  0.938339   \n",
       "8          1.178014       0.881387  0.864369                  0.919355   \n",
       "9          1.166171       0.882387  0.844537                  0.910113   \n",
       "10         1.153250       0.859692  0.830279                  0.900029   \n",
       "11         1.139755       0.836831  0.816768                  0.889497   \n",
       "12         1.125181       0.809877  0.802814                  0.878122   \n",
       "13         1.104442       0.748644  0.779232                  0.861937   \n",
       "14         1.069331       0.615330  0.675578                  0.834536   \n",
       "15         1.000000       0.293463  0.397910                  0.780428   \n",
       "\n",
       "    cumulative_score  capture_rate  cumulative_capture_rate       gain  \\\n",
       "0           0.924269      0.012675                 0.012675  26.672522   \n",
       "1           0.920179      0.012638                 0.025313  26.306944   \n",
       "2           0.917335      0.012492                 0.037805  25.022985   \n",
       "3           0.915066      0.012400                 0.050205  23.930692   \n",
       "4           0.913167      0.012254                 0.062459  22.643338   \n",
       "5           0.906340      0.061087                 0.123546  22.172519   \n",
       "6           0.901074      0.058746                 0.182292  17.490458   \n",
       "7           0.895751      0.058179                 0.240471  16.356522   \n",
       "8           0.885291      0.112938                 0.353409  12.936423   \n",
       "9           0.875102      0.113066                 0.466475  13.064448   \n",
       "10          0.866138      0.110158                 0.576633  10.156449   \n",
       "11          0.857910      0.107213                 0.683847   7.227177   \n",
       "12          0.850039      0.103775                 0.787622   3.773484   \n",
       "13          0.841188      0.095929                 0.883550  -4.072625   \n",
       "14          0.822787      0.078846                 0.962397 -21.154831   \n",
       "15          0.780299      0.037603                 1.000000 -62.397201   \n",
       "\n",
       "    cumulative_gain  \n",
       "0         26.672522  \n",
       "1         26.489733  \n",
       "2         26.001282  \n",
       "3         25.483450  \n",
       "4         24.915914  \n",
       "5         23.544217  \n",
       "6         21.526297  \n",
       "7         20.233853  \n",
       "8         17.801377  \n",
       "9         16.617144  \n",
       "10        15.325005  \n",
       "11        13.975528  \n",
       "12        12.518063  \n",
       "13        10.444190  \n",
       "14         6.933132  \n",
       "15         0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on validation data. **\n",
      "\n",
      "MSE: 0.14054661136213017\n",
      "RMSE: 0.3748954672467116\n",
      "LogLoss: 0.4483687236302639\n",
      "Mean Per-Class Error: 0.331998847835558\n",
      "AUC: 0.728196521460703\n",
      "AUCPR: 0.8904505504804234\n",
      "Gini: 0.45639304292140603\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.49490480134763554: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>Error</th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>708.0</td>\n",
       "      <td>2521.0</td>\n",
       "      <td>0.7807</td>\n",
       "      <td>(2521.0/3229.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>239.0</td>\n",
       "      <td>11561.0</td>\n",
       "      <td>0.0203</td>\n",
       "      <td>(239.0/11800.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total</td>\n",
       "      <td>947.0</td>\n",
       "      <td>14082.0</td>\n",
       "      <td>0.1836</td>\n",
       "      <td>(2760.0/15029.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0        1   Error               Rate\n",
       "0      0  708.0   2521.0  0.7807    (2521.0/3229.0)\n",
       "1      1  239.0  11561.0  0.0203    (239.0/11800.0)\n",
       "2  Total  947.0  14082.0  0.1836   (2760.0/15029.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>threshold</th>\n",
       "      <th>value</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>max f1</td>\n",
       "      <td>0.494905</td>\n",
       "      <td>0.893362</td>\n",
       "      <td>289.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max f2</td>\n",
       "      <td>0.312893</td>\n",
       "      <td>0.950142</td>\n",
       "      <td>344.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>max f0point5</td>\n",
       "      <td>0.677169</td>\n",
       "      <td>0.861371</td>\n",
       "      <td>212.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>max accuracy</td>\n",
       "      <td>0.500695</td>\n",
       "      <td>0.816422</td>\n",
       "      <td>287.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max precision</td>\n",
       "      <td>0.937212</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>max recall</td>\n",
       "      <td>0.125426</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>394.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>max specificity</td>\n",
       "      <td>0.937212</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>max absolute_mcc</td>\n",
       "      <td>0.646052</td>\n",
       "      <td>0.368538</td>\n",
       "      <td>226.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>max min_per_class_accuracy</td>\n",
       "      <td>0.811804</td>\n",
       "      <td>0.659237</td>\n",
       "      <td>123.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max mean_per_class_accuracy</td>\n",
       "      <td>0.777946</td>\n",
       "      <td>0.668001</td>\n",
       "      <td>160.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>max tns</td>\n",
       "      <td>0.937212</td>\n",
       "      <td>3229.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>max fns</td>\n",
       "      <td>0.937212</td>\n",
       "      <td>11796.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>max fps</td>\n",
       "      <td>0.095107</td>\n",
       "      <td>3229.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>max tps</td>\n",
       "      <td>0.125426</td>\n",
       "      <td>11800.000000</td>\n",
       "      <td>394.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>max tnr</td>\n",
       "      <td>0.937212</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>max fnr</td>\n",
       "      <td>0.937212</td>\n",
       "      <td>0.999661</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>max fpr</td>\n",
       "      <td>0.095107</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>max tpr</td>\n",
       "      <td>0.125426</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>394.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         metric  threshold         value    idx\n",
       "0                        max f1   0.494905      0.893362  289.0\n",
       "1                        max f2   0.312893      0.950142  344.0\n",
       "2                  max f0point5   0.677169      0.861371  212.0\n",
       "3                  max accuracy   0.500695      0.816422  287.0\n",
       "4                 max precision   0.937212      1.000000    0.0\n",
       "5                    max recall   0.125426      1.000000  394.0\n",
       "6               max specificity   0.937212      1.000000    0.0\n",
       "7              max absolute_mcc   0.646052      0.368538  226.0\n",
       "8    max min_per_class_accuracy   0.811804      0.659237  123.0\n",
       "9   max mean_per_class_accuracy   0.777946      0.668001  160.0\n",
       "10                      max tns   0.937212   3229.000000    0.0\n",
       "11                      max fns   0.937212  11796.000000    0.0\n",
       "12                      max fps   0.095107   3229.000000  399.0\n",
       "13                      max tps   0.125426  11800.000000  394.0\n",
       "14                      max tnr   0.937212      1.000000    0.0\n",
       "15                      max fnr   0.937212      0.999661    0.0\n",
       "16                      max fpr   0.095107      1.000000  399.0\n",
       "17                      max tpr   0.125426      1.000000  394.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate: 78.51 %, avg score: 78.14 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>cumulative_data_fraction</th>\n",
       "      <th>lower_threshold</th>\n",
       "      <th>lift</th>\n",
       "      <th>cumulative_lift</th>\n",
       "      <th>response_rate</th>\n",
       "      <th>score</th>\n",
       "      <th>cumulative_response_rate</th>\n",
       "      <th>cumulative_score</th>\n",
       "      <th>capture_rate</th>\n",
       "      <th>cumulative_capture_rate</th>\n",
       "      <th>gain</th>\n",
       "      <th>cumulative_gain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0.010047</td>\n",
       "      <td>0.917400</td>\n",
       "      <td>1.223036</td>\n",
       "      <td>1.223036</td>\n",
       "      <td>0.960265</td>\n",
       "      <td>0.922788</td>\n",
       "      <td>0.960265</td>\n",
       "      <td>0.922788</td>\n",
       "      <td>0.012288</td>\n",
       "      <td>0.012288</td>\n",
       "      <td>22.303569</td>\n",
       "      <td>22.303569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>0.020028</td>\n",
       "      <td>0.912478</td>\n",
       "      <td>1.256662</td>\n",
       "      <td>1.239793</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>0.914709</td>\n",
       "      <td>0.973422</td>\n",
       "      <td>0.918762</td>\n",
       "      <td>0.012542</td>\n",
       "      <td>0.024831</td>\n",
       "      <td>25.666215</td>\n",
       "      <td>23.979306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>0.030009</td>\n",
       "      <td>0.908885</td>\n",
       "      <td>1.188734</td>\n",
       "      <td>1.222811</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.910582</td>\n",
       "      <td>0.960089</td>\n",
       "      <td>0.916042</td>\n",
       "      <td>0.011864</td>\n",
       "      <td>0.036695</td>\n",
       "      <td>18.873446</td>\n",
       "      <td>22.281127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>0.040056</td>\n",
       "      <td>0.906014</td>\n",
       "      <td>1.180862</td>\n",
       "      <td>1.212289</td>\n",
       "      <td>0.927152</td>\n",
       "      <td>0.907413</td>\n",
       "      <td>0.951827</td>\n",
       "      <td>0.913877</td>\n",
       "      <td>0.011864</td>\n",
       "      <td>0.048559</td>\n",
       "      <td>18.086205</td>\n",
       "      <td>21.228912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "      <td>0.050037</td>\n",
       "      <td>0.903703</td>\n",
       "      <td>1.163262</td>\n",
       "      <td>1.202510</td>\n",
       "      <td>0.913333</td>\n",
       "      <td>0.904880</td>\n",
       "      <td>0.944149</td>\n",
       "      <td>0.912082</td>\n",
       "      <td>0.011610</td>\n",
       "      <td>0.060169</td>\n",
       "      <td>16.326158</td>\n",
       "      <td>20.250969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>6</td>\n",
       "      <td>0.100007</td>\n",
       "      <td>0.894705</td>\n",
       "      <td>1.183760</td>\n",
       "      <td>1.193141</td>\n",
       "      <td>0.929427</td>\n",
       "      <td>0.899210</td>\n",
       "      <td>0.936793</td>\n",
       "      <td>0.905651</td>\n",
       "      <td>0.059153</td>\n",
       "      <td>0.119322</td>\n",
       "      <td>18.375973</td>\n",
       "      <td>19.314095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>7</td>\n",
       "      <td>0.150043</td>\n",
       "      <td>0.885103</td>\n",
       "      <td>1.144925</td>\n",
       "      <td>1.177062</td>\n",
       "      <td>0.898936</td>\n",
       "      <td>0.890021</td>\n",
       "      <td>0.924169</td>\n",
       "      <td>0.900438</td>\n",
       "      <td>0.057288</td>\n",
       "      <td>0.176610</td>\n",
       "      <td>14.492472</td>\n",
       "      <td>17.706175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td>8</td>\n",
       "      <td>0.200013</td>\n",
       "      <td>0.873738</td>\n",
       "      <td>1.126098</td>\n",
       "      <td>1.164329</td>\n",
       "      <td>0.884154</td>\n",
       "      <td>0.879396</td>\n",
       "      <td>0.914172</td>\n",
       "      <td>0.895181</td>\n",
       "      <td>0.056271</td>\n",
       "      <td>0.232881</td>\n",
       "      <td>12.609808</td>\n",
       "      <td>16.432931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td>9</td>\n",
       "      <td>0.300020</td>\n",
       "      <td>0.853326</td>\n",
       "      <td>1.121959</td>\n",
       "      <td>1.150206</td>\n",
       "      <td>0.880905</td>\n",
       "      <td>0.864111</td>\n",
       "      <td>0.903083</td>\n",
       "      <td>0.884824</td>\n",
       "      <td>0.112203</td>\n",
       "      <td>0.345085</td>\n",
       "      <td>12.195925</td>\n",
       "      <td>15.020595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "      <td>0.400027</td>\n",
       "      <td>0.836279</td>\n",
       "      <td>1.088911</td>\n",
       "      <td>1.134882</td>\n",
       "      <td>0.854957</td>\n",
       "      <td>0.844007</td>\n",
       "      <td>0.891051</td>\n",
       "      <td>0.874620</td>\n",
       "      <td>0.108898</td>\n",
       "      <td>0.453983</td>\n",
       "      <td>8.891060</td>\n",
       "      <td>13.488211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td></td>\n",
       "      <td>11</td>\n",
       "      <td>0.500033</td>\n",
       "      <td>0.823088</td>\n",
       "      <td>1.088063</td>\n",
       "      <td>1.125518</td>\n",
       "      <td>0.854291</td>\n",
       "      <td>0.829817</td>\n",
       "      <td>0.883699</td>\n",
       "      <td>0.865659</td>\n",
       "      <td>0.108814</td>\n",
       "      <td>0.562797</td>\n",
       "      <td>8.806320</td>\n",
       "      <td>12.551833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.599973</td>\n",
       "      <td>0.810007</td>\n",
       "      <td>1.060805</td>\n",
       "      <td>1.114739</td>\n",
       "      <td>0.832889</td>\n",
       "      <td>0.816595</td>\n",
       "      <td>0.875236</td>\n",
       "      <td>0.857487</td>\n",
       "      <td>0.106017</td>\n",
       "      <td>0.668814</td>\n",
       "      <td>6.080475</td>\n",
       "      <td>11.473871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0.699980</td>\n",
       "      <td>0.793989</td>\n",
       "      <td>1.027050</td>\n",
       "      <td>1.102211</td>\n",
       "      <td>0.806387</td>\n",
       "      <td>0.802522</td>\n",
       "      <td>0.865399</td>\n",
       "      <td>0.849634</td>\n",
       "      <td>0.102712</td>\n",
       "      <td>0.771525</td>\n",
       "      <td>2.705031</td>\n",
       "      <td>10.221061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>0.799987</td>\n",
       "      <td>0.757158</td>\n",
       "      <td>0.991459</td>\n",
       "      <td>1.088366</td>\n",
       "      <td>0.778443</td>\n",
       "      <td>0.779708</td>\n",
       "      <td>0.854529</td>\n",
       "      <td>0.840892</td>\n",
       "      <td>0.099153</td>\n",
       "      <td>0.870678</td>\n",
       "      <td>-0.854055</td>\n",
       "      <td>8.836556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td></td>\n",
       "      <td>15</td>\n",
       "      <td>0.899993</td>\n",
       "      <td>0.593228</td>\n",
       "      <td>0.842317</td>\n",
       "      <td>1.061025</td>\n",
       "      <td>0.661344</td>\n",
       "      <td>0.678393</td>\n",
       "      <td>0.833062</td>\n",
       "      <td>0.822836</td>\n",
       "      <td>0.084237</td>\n",
       "      <td>0.954915</td>\n",
       "      <td>-15.768316</td>\n",
       "      <td>6.102479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td></td>\n",
       "      <td>16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.094127</td>\n",
       "      <td>0.450817</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.353959</td>\n",
       "      <td>0.408022</td>\n",
       "      <td>0.785149</td>\n",
       "      <td>0.781351</td>\n",
       "      <td>0.045085</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-54.918254</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      group  cumulative_data_fraction  lower_threshold      lift  \\\n",
       "0         1                  0.010047         0.917400  1.223036   \n",
       "1         2                  0.020028         0.912478  1.256662   \n",
       "2         3                  0.030009         0.908885  1.188734   \n",
       "3         4                  0.040056         0.906014  1.180862   \n",
       "4         5                  0.050037         0.903703  1.163262   \n",
       "5         6                  0.100007         0.894705  1.183760   \n",
       "6         7                  0.150043         0.885103  1.144925   \n",
       "7         8                  0.200013         0.873738  1.126098   \n",
       "8         9                  0.300020         0.853326  1.121959   \n",
       "9        10                  0.400027         0.836279  1.088911   \n",
       "10       11                  0.500033         0.823088  1.088063   \n",
       "11       12                  0.599973         0.810007  1.060805   \n",
       "12       13                  0.699980         0.793989  1.027050   \n",
       "13       14                  0.799987         0.757158  0.991459   \n",
       "14       15                  0.899993         0.593228  0.842317   \n",
       "15       16                  1.000000         0.094127  0.450817   \n",
       "\n",
       "    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n",
       "0          1.223036       0.960265  0.922788                  0.960265   \n",
       "1          1.239793       0.986667  0.914709                  0.973422   \n",
       "2          1.222811       0.933333  0.910582                  0.960089   \n",
       "3          1.212289       0.927152  0.907413                  0.951827   \n",
       "4          1.202510       0.913333  0.904880                  0.944149   \n",
       "5          1.193141       0.929427  0.899210                  0.936793   \n",
       "6          1.177062       0.898936  0.890021                  0.924169   \n",
       "7          1.164329       0.884154  0.879396                  0.914172   \n",
       "8          1.150206       0.880905  0.864111                  0.903083   \n",
       "9          1.134882       0.854957  0.844007                  0.891051   \n",
       "10         1.125518       0.854291  0.829817                  0.883699   \n",
       "11         1.114739       0.832889  0.816595                  0.875236   \n",
       "12         1.102211       0.806387  0.802522                  0.865399   \n",
       "13         1.088366       0.778443  0.779708                  0.854529   \n",
       "14         1.061025       0.661344  0.678393                  0.833062   \n",
       "15         1.000000       0.353959  0.408022                  0.785149   \n",
       "\n",
       "    cumulative_score  capture_rate  cumulative_capture_rate       gain  \\\n",
       "0           0.922788      0.012288                 0.012288  22.303569   \n",
       "1           0.918762      0.012542                 0.024831  25.666215   \n",
       "2           0.916042      0.011864                 0.036695  18.873446   \n",
       "3           0.913877      0.011864                 0.048559  18.086205   \n",
       "4           0.912082      0.011610                 0.060169  16.326158   \n",
       "5           0.905651      0.059153                 0.119322  18.375973   \n",
       "6           0.900438      0.057288                 0.176610  14.492472   \n",
       "7           0.895181      0.056271                 0.232881  12.609808   \n",
       "8           0.884824      0.112203                 0.345085  12.195925   \n",
       "9           0.874620      0.108898                 0.453983   8.891060   \n",
       "10          0.865659      0.108814                 0.562797   8.806320   \n",
       "11          0.857487      0.106017                 0.668814   6.080475   \n",
       "12          0.849634      0.102712                 0.771525   2.705031   \n",
       "13          0.840892      0.099153                 0.870678  -0.854055   \n",
       "14          0.822836      0.084237                 0.954915 -15.768316   \n",
       "15          0.781351      0.045085                 1.000000 -54.918254   \n",
       "\n",
       "    cumulative_gain  \n",
       "0         22.303569  \n",
       "1         23.979306  \n",
       "2         22.281127  \n",
       "3         21.228912  \n",
       "4         20.250969  \n",
       "5         19.314095  \n",
       "6         17.706175  \n",
       "7         16.432931  \n",
       "8         15.020595  \n",
       "9         13.488211  \n",
       "10        12.551833  \n",
       "11        11.473871  \n",
       "12        10.221061  \n",
       "13         8.836556  \n",
       "14         6.102479  \n",
       "15         0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>duration</th>\n",
       "      <th>number_of_trees</th>\n",
       "      <th>training_rmse</th>\n",
       "      <th>training_logloss</th>\n",
       "      <th>training_auc</th>\n",
       "      <th>training_pr_auc</th>\n",
       "      <th>training_lift</th>\n",
       "      <th>training_classification_error</th>\n",
       "      <th>validation_rmse</th>\n",
       "      <th>validation_logloss</th>\n",
       "      <th>validation_auc</th>\n",
       "      <th>validation_pr_auc</th>\n",
       "      <th>validation_lift</th>\n",
       "      <th>validation_classification_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>2020-06-03 01:47:34</td>\n",
       "      <td>0.821 sec</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.413957</td>\n",
       "      <td>0.526366</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.219572</td>\n",
       "      <td>0.410746</td>\n",
       "      <td>0.520379</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.214851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>2020-06-03 01:47:36</td>\n",
       "      <td>2.828 sec</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.386418</td>\n",
       "      <td>0.470391</td>\n",
       "      <td>0.723534</td>\n",
       "      <td>0.887080</td>\n",
       "      <td>1.233606</td>\n",
       "      <td>0.190211</td>\n",
       "      <td>0.384600</td>\n",
       "      <td>0.467335</td>\n",
       "      <td>0.717767</td>\n",
       "      <td>0.885046</td>\n",
       "      <td>1.198281</td>\n",
       "      <td>0.191563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>2020-06-03 01:47:38</td>\n",
       "      <td>4.686 sec</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.378116</td>\n",
       "      <td>0.454396</td>\n",
       "      <td>0.736033</td>\n",
       "      <td>0.892522</td>\n",
       "      <td>1.241505</td>\n",
       "      <td>0.185101</td>\n",
       "      <td>0.377888</td>\n",
       "      <td>0.454646</td>\n",
       "      <td>0.720757</td>\n",
       "      <td>0.885553</td>\n",
       "      <td>1.211134</td>\n",
       "      <td>0.185308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>2020-06-03 01:47:40</td>\n",
       "      <td>6.508 sec</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.374486</td>\n",
       "      <td>0.447258</td>\n",
       "      <td>0.743641</td>\n",
       "      <td>0.896566</td>\n",
       "      <td>1.259414</td>\n",
       "      <td>0.183403</td>\n",
       "      <td>0.375966</td>\n",
       "      <td>0.450893</td>\n",
       "      <td>0.723132</td>\n",
       "      <td>0.886708</td>\n",
       "      <td>1.197732</td>\n",
       "      <td>0.184177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>2020-06-03 01:47:42</td>\n",
       "      <td>8.290 sec</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.371936</td>\n",
       "      <td>0.441814</td>\n",
       "      <td>0.755149</td>\n",
       "      <td>0.902679</td>\n",
       "      <td>1.259414</td>\n",
       "      <td>0.180705</td>\n",
       "      <td>0.375288</td>\n",
       "      <td>0.449365</td>\n",
       "      <td>0.724709</td>\n",
       "      <td>0.888470</td>\n",
       "      <td>1.206166</td>\n",
       "      <td>0.183911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>2020-06-03 01:47:44</td>\n",
       "      <td>9.969 sec</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.369725</td>\n",
       "      <td>0.437018</td>\n",
       "      <td>0.767961</td>\n",
       "      <td>0.908946</td>\n",
       "      <td>1.266725</td>\n",
       "      <td>0.179834</td>\n",
       "      <td>0.374895</td>\n",
       "      <td>0.448369</td>\n",
       "      <td>0.728197</td>\n",
       "      <td>0.890451</td>\n",
       "      <td>1.223036</td>\n",
       "      <td>0.183645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               timestamp    duration  number_of_trees  training_rmse  \\\n",
       "0    2020-06-03 01:47:34   0.821 sec              0.0       0.413957   \n",
       "1    2020-06-03 01:47:36   2.828 sec             10.0       0.386418   \n",
       "2    2020-06-03 01:47:38   4.686 sec             20.0       0.378116   \n",
       "3    2020-06-03 01:47:40   6.508 sec             30.0       0.374486   \n",
       "4    2020-06-03 01:47:42   8.290 sec             40.0       0.371936   \n",
       "5    2020-06-03 01:47:44   9.969 sec             50.0       0.369725   \n",
       "\n",
       "   training_logloss  training_auc  training_pr_auc  training_lift  \\\n",
       "0          0.526366      0.500000         0.000000       1.000000   \n",
       "1          0.470391      0.723534         0.887080       1.233606   \n",
       "2          0.454396      0.736033         0.892522       1.241505   \n",
       "3          0.447258      0.743641         0.896566       1.259414   \n",
       "4          0.441814      0.755149         0.902679       1.259414   \n",
       "5          0.437018      0.767961         0.908946       1.266725   \n",
       "\n",
       "   training_classification_error  validation_rmse  validation_logloss  \\\n",
       "0                       0.219572         0.410746            0.520379   \n",
       "1                       0.190211         0.384600            0.467335   \n",
       "2                       0.185101         0.377888            0.454646   \n",
       "3                       0.183403         0.375966            0.450893   \n",
       "4                       0.180705         0.375288            0.449365   \n",
       "5                       0.179834         0.374895            0.448369   \n",
       "\n",
       "   validation_auc  validation_pr_auc  validation_lift  \\\n",
       "0        0.500000           0.000000         1.000000   \n",
       "1        0.717767           0.885046         1.198281   \n",
       "2        0.720757           0.885553         1.211134   \n",
       "3        0.723132           0.886708         1.197732   \n",
       "4        0.724709           0.888470         1.206166   \n",
       "5        0.728197           0.890451         1.223036   \n",
       "\n",
       "   validation_classification_error  \n",
       "0                         0.214851  \n",
       "1                         0.191563  \n",
       "2                         0.185308  \n",
       "3                         0.184177  \n",
       "4                         0.183911  \n",
       "5                         0.183645  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>relative_importance</th>\n",
       "      <th>scaled_importance</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HelpfulnessNumerator</td>\n",
       "      <td>4623.907715</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.369515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HelpfulnessDenominator</td>\n",
       "      <td>4366.922363</td>\n",
       "      <td>0.944422</td>\n",
       "      <td>0.348978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Time</td>\n",
       "      <td>1330.391357</td>\n",
       "      <td>0.287720</td>\n",
       "      <td>0.106317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ProductId</td>\n",
       "      <td>428.513885</td>\n",
       "      <td>0.092674</td>\n",
       "      <td>0.034244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UserId</td>\n",
       "      <td>120.660072</td>\n",
       "      <td>0.026095</td>\n",
       "      <td>0.009642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C59</td>\n",
       "      <td>52.431252</td>\n",
       "      <td>0.011339</td>\n",
       "      <td>0.004190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>C79</td>\n",
       "      <td>35.146072</td>\n",
       "      <td>0.007601</td>\n",
       "      <td>0.002809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>C10</td>\n",
       "      <td>34.029274</td>\n",
       "      <td>0.007359</td>\n",
       "      <td>0.002719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>C38</td>\n",
       "      <td>32.917484</td>\n",
       "      <td>0.007119</td>\n",
       "      <td>0.002631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>C5</td>\n",
       "      <td>32.728588</td>\n",
       "      <td>0.007078</td>\n",
       "      <td>0.002615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>C68</td>\n",
       "      <td>31.350174</td>\n",
       "      <td>0.006780</td>\n",
       "      <td>0.002505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>C9</td>\n",
       "      <td>30.536861</td>\n",
       "      <td>0.006604</td>\n",
       "      <td>0.002440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>C7</td>\n",
       "      <td>29.923222</td>\n",
       "      <td>0.006471</td>\n",
       "      <td>0.002391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>C24</td>\n",
       "      <td>28.834768</td>\n",
       "      <td>0.006236</td>\n",
       "      <td>0.002304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>C62</td>\n",
       "      <td>27.339672</td>\n",
       "      <td>0.005913</td>\n",
       "      <td>0.002185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>C32</td>\n",
       "      <td>26.954771</td>\n",
       "      <td>0.005829</td>\n",
       "      <td>0.002154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>C81</td>\n",
       "      <td>26.888647</td>\n",
       "      <td>0.005815</td>\n",
       "      <td>0.002149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>C40</td>\n",
       "      <td>26.075401</td>\n",
       "      <td>0.005639</td>\n",
       "      <td>0.002084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>C80</td>\n",
       "      <td>25.572639</td>\n",
       "      <td>0.005531</td>\n",
       "      <td>0.002044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>C91</td>\n",
       "      <td>25.551682</td>\n",
       "      <td>0.005526</td>\n",
       "      <td>0.002042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  variable  relative_importance  scaled_importance  percentage\n",
       "0     HelpfulnessNumerator          4623.907715           1.000000    0.369515\n",
       "1   HelpfulnessDenominator          4366.922363           0.944422    0.348978\n",
       "2                     Time          1330.391357           0.287720    0.106317\n",
       "3                ProductId           428.513885           0.092674    0.034244\n",
       "4                   UserId           120.660072           0.026095    0.009642\n",
       "5                      C59            52.431252           0.011339    0.004190\n",
       "6                      C79            35.146072           0.007601    0.002809\n",
       "7                      C10            34.029274           0.007359    0.002719\n",
       "8                      C38            32.917484           0.007119    0.002631\n",
       "9                       C5            32.728588           0.007078    0.002615\n",
       "10                     C68            31.350174           0.006780    0.002505\n",
       "11                      C9            30.536861           0.006604    0.002440\n",
       "12                      C7            29.923222           0.006471    0.002391\n",
       "13                     C24            28.834768           0.006236    0.002304\n",
       "14                     C62            27.339672           0.005913    0.002185\n",
       "15                     C32            26.954771           0.005829    0.002154\n",
       "16                     C81            26.888647           0.005815    0.002149\n",
       "17                     C40            26.075401           0.005639    0.002084\n",
       "18                     C80            25.572639           0.005531    0.002044\n",
       "19                     C91            25.551682           0.005526    0.002042"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "See the whole table with table.as_data_frame()\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from h2o.estimators import H2OGradientBoostingEstimator\n",
    "mlflow.end_run()\n",
    "mlflow.start_run(run_name='GBM with word vectors')\n",
    "RATIOS = [0.7,0.15]\n",
    "# Train Test Split\n",
    "ext_train,ext_test,ext_valid = ext_reviews.split_frame(ratios=RATIOS)\n",
    "# Log our ratios\n",
    "mlflow.lp('ratios',RATIOS)\n",
    "# Log what word vectors we're using\n",
    "mlflow.lp('word vectors', 'reviews')\n",
    "\n",
    "non_token_predictors = ['ProductId', 'UserId', 'HelpfulnessNumerator', 'HelpfulnessDenominator', 'Time']\n",
    "predictors = non_token_predictors + review_vecs.names\n",
    "response = 'PositiveReview'\n",
    "\n",
    "mlflow.lp('label', response)\n",
    "# There are a lot of predictors here (C1-C100 + features) so let's shorten that\n",
    "mlflow.lp('predictors', non_token_predictors + [f'C1-C{len(review_vecs.columns)}'])\n",
    "\n",
    "gbm_embeddings = H2OGradientBoostingEstimator(stopping_metric = \"AUC\", stopping_tolerance = 0.001,\n",
    "                                              stopping_rounds = 5, score_tree_interval = 10,\n",
    "                                              model_id = \"gbm_embeddings.hex\"\n",
    "                                             )\n",
    "with mlflow.timer('train_time'):\n",
    "    gbm_embeddings.train(x = predictors, y = response, \n",
    "                       training_frame = ext_train, validation_frame = ext_test\n",
    "                      )\n",
    "\n",
    "# Log the model params to mlflow\n",
    "mlflow.log_params(gbm_embeddings.get_params())\n",
    "# Log the model to MLFlow\n",
    "mlflow.log_model(gbm_embeddings, 'baseline_model')\n",
    "# Log the training notebook to MLFlow\n",
    "mlflow.log_artifact('MLManager H2O Demo.ipynb', 'training_notebook')\n",
    "gbm_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Just like before, let's log all of our outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>number_of_trees</th>\n",
       "      <th>number_of_internal_trees</th>\n",
       "      <th>model_size_in_bytes</th>\n",
       "      <th>min_depth</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>mean_depth</th>\n",
       "      <th>min_leaves</th>\n",
       "      <th>max_leaves</th>\n",
       "      <th>mean_leaves</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>22697.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>29.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     number_of_trees  number_of_internal_trees  model_size_in_bytes  \\\n",
       "0               50.0                      50.0              22697.0   \n",
       "\n",
       "   min_depth  max_depth  mean_depth  min_leaves  max_leaves  mean_leaves  \n",
       "0        5.0        5.0         5.0        20.0        32.0         29.4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC on Validation Data: 0.728\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.49490480134763554: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>Error</th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>708.0</td>\n",
       "      <td>2521.0</td>\n",
       "      <td>0.7807</td>\n",
       "      <td>(2521.0/3229.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>239.0</td>\n",
       "      <td>11561.0</td>\n",
       "      <td>0.0203</td>\n",
       "      <td>(239.0/11800.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total</td>\n",
       "      <td>947.0</td>\n",
       "      <td>14082.0</td>\n",
       "      <td>0.1836</td>\n",
       "      <td>(2760.0/15029.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0        1   Error               Rate\n",
       "0      0  708.0   2521.0  0.7807    (2521.0/3229.0)\n",
       "1      1  239.0  11561.0  0.0203    (239.0/11800.0)\n",
       "2  Total  947.0  14082.0  0.1836   (2760.0/15029.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PartialDependencePlot progress: |█████████████████████████████████████████| 100%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline  \n",
    "from IPython.core.display import HTML\n",
    "\n",
    "# Print and Log Model params\n",
    "params = dict(zip(gbm_embeddings.summary().col_header[1:],\n",
    "                    gbm_embeddings.summary().cell_values[0][1:]))\n",
    "print(gbm_embeddings.summary())\n",
    "mlflow.log_params(params)\n",
    "\n",
    "\n",
    "#Plot and Log Scoring history\n",
    "gbm_embeddings.plot()\n",
    "print(\"AUC on Validation Data: \" + str(round(gbm_embeddings.auc(valid = True), 3)))\n",
    "# Log training and validation metrics over time\n",
    "for step, row in gbm_embeddings.scoring_history().iterrows():\n",
    "    row_dict = row.to_dict()\n",
    "    for r in row_dict:\n",
    "        if 'train' in r or 'valid' in r:\n",
    "            mlflow.log_metric(r, row_dict[r],step=step)\n",
    "\n",
    "\n",
    "# Print and Log Confusion Matrix\n",
    "print(gbm_embeddings.confusion_matrix(valid = True))\n",
    "mlflow.lm('fpr', gbm_embeddings.fpr(valid=True)[0][0])\n",
    "mlflow.lm('tpr', gbm_embeddings.tpr(valid=True)[0][0])\n",
    "mlflow.lm('fnr', gbm_embeddings.fnr(valid=True)[0][0])\n",
    "mlflow.lm('tnr', gbm_embeddings.fnr(valid=True)[0][0])\n",
    "mlflow.lm('F0point5', gbm_embeddings.F0point5(valid=True)[0][1])\n",
    "mlflow.lm('F1', gbm_embeddings.F1(valid=True)[0][1])\n",
    "mlflow.lm('F2', gbm_embeddings.F2(valid=True)[0][1])\n",
    "mlflow.lm('auc', gbm_embeddings.auc(valid = True))\n",
    "mlflow.lp('threshold', gbm_embeddings.F1(valid=True)[0][0]) # First element is the threshold\n",
    "\n",
    "\n",
    "# Plot and Log Variable Importance\n",
    "gbm_embeddings.varimp_plot()\n",
    "for var in gbm_embeddings.varimp():\n",
    "    mlflow.lm(f'varimp_{var[0]}',var[-1])\n",
    "    \n",
    "    \n",
    "# Partial Dependence Plot\n",
    "pdp_helpfulness = gbm_embeddings.partial_plot(ext_train, cols = [\"HelpfulnessNumerator\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<font size=\"+1\">Compare your 2 runs <a href=/mlflow/#/metric/training_auc?runs=[\"ac7ab3a95183\",\"ac7ab3a95183\"]&experiment=1&plot_metric_keys=[\"training_logloss\",\"validation_logloss\",\"training_rmse\",\"validation_rmse\"]>here</a></font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_run = cur_run\n",
    "cur_run = mlflow.current_run_id()\n",
    "cur_exp = mlflow.current_exp_id()\n",
    "link = f'/mlflow/#/metric/training_auc?runs=[\"{cur_run}\",\"{old_run}\"]&experiment={cur_exp}&plot_metric_keys=[\"training_logloss\",\\\"validation_logloss\\\",\\\"training_rmse\\\",\\\"validation_rmse\\\"]'\n",
    "HTML(f'<font size=\"+1\">Compare your 2 runs <a href={link}>here</a></font>') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>duration</th>\n",
       "      <th>number_of_trees</th>\n",
       "      <th>training_rmse</th>\n",
       "      <th>training_logloss</th>\n",
       "      <th>training_auc</th>\n",
       "      <th>training_pr_auc</th>\n",
       "      <th>training_lift</th>\n",
       "      <th>training_classification_error</th>\n",
       "      <th>validation_rmse</th>\n",
       "      <th>validation_logloss</th>\n",
       "      <th>validation_auc</th>\n",
       "      <th>validation_pr_auc</th>\n",
       "      <th>validation_lift</th>\n",
       "      <th>validation_classification_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>2020-06-03 01:47:34</td>\n",
       "      <td>0.821 sec</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.413957</td>\n",
       "      <td>0.526366</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.219572</td>\n",
       "      <td>0.410746</td>\n",
       "      <td>0.520379</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.214851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>2020-06-03 01:47:36</td>\n",
       "      <td>2.828 sec</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.386418</td>\n",
       "      <td>0.470391</td>\n",
       "      <td>0.723534</td>\n",
       "      <td>0.887080</td>\n",
       "      <td>1.233606</td>\n",
       "      <td>0.190211</td>\n",
       "      <td>0.384600</td>\n",
       "      <td>0.467335</td>\n",
       "      <td>0.717767</td>\n",
       "      <td>0.885046</td>\n",
       "      <td>1.198281</td>\n",
       "      <td>0.191563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>2020-06-03 01:47:38</td>\n",
       "      <td>4.686 sec</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.378116</td>\n",
       "      <td>0.454396</td>\n",
       "      <td>0.736033</td>\n",
       "      <td>0.892522</td>\n",
       "      <td>1.241505</td>\n",
       "      <td>0.185101</td>\n",
       "      <td>0.377888</td>\n",
       "      <td>0.454646</td>\n",
       "      <td>0.720757</td>\n",
       "      <td>0.885553</td>\n",
       "      <td>1.211134</td>\n",
       "      <td>0.185308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>2020-06-03 01:47:40</td>\n",
       "      <td>6.508 sec</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.374486</td>\n",
       "      <td>0.447258</td>\n",
       "      <td>0.743641</td>\n",
       "      <td>0.896566</td>\n",
       "      <td>1.259414</td>\n",
       "      <td>0.183403</td>\n",
       "      <td>0.375966</td>\n",
       "      <td>0.450893</td>\n",
       "      <td>0.723132</td>\n",
       "      <td>0.886708</td>\n",
       "      <td>1.197732</td>\n",
       "      <td>0.184177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>2020-06-03 01:47:42</td>\n",
       "      <td>8.290 sec</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.371936</td>\n",
       "      <td>0.441814</td>\n",
       "      <td>0.755149</td>\n",
       "      <td>0.902679</td>\n",
       "      <td>1.259414</td>\n",
       "      <td>0.180705</td>\n",
       "      <td>0.375288</td>\n",
       "      <td>0.449365</td>\n",
       "      <td>0.724709</td>\n",
       "      <td>0.888470</td>\n",
       "      <td>1.206166</td>\n",
       "      <td>0.183911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>2020-06-03 01:47:44</td>\n",
       "      <td>9.969 sec</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.369725</td>\n",
       "      <td>0.437018</td>\n",
       "      <td>0.767961</td>\n",
       "      <td>0.908946</td>\n",
       "      <td>1.266725</td>\n",
       "      <td>0.179834</td>\n",
       "      <td>0.374895</td>\n",
       "      <td>0.448369</td>\n",
       "      <td>0.728197</td>\n",
       "      <td>0.890451</td>\n",
       "      <td>1.223036</td>\n",
       "      <td>0.183645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               timestamp    duration  number_of_trees  training_rmse  \\\n",
       "0    2020-06-03 01:47:34   0.821 sec              0.0       0.413957   \n",
       "1    2020-06-03 01:47:36   2.828 sec             10.0       0.386418   \n",
       "2    2020-06-03 01:47:38   4.686 sec             20.0       0.378116   \n",
       "3    2020-06-03 01:47:40   6.508 sec             30.0       0.374486   \n",
       "4    2020-06-03 01:47:42   8.290 sec             40.0       0.371936   \n",
       "5    2020-06-03 01:47:44   9.969 sec             50.0       0.369725   \n",
       "\n",
       "   training_logloss  training_auc  training_pr_auc  training_lift  \\\n",
       "0          0.526366      0.500000         0.000000       1.000000   \n",
       "1          0.470391      0.723534         0.887080       1.233606   \n",
       "2          0.454396      0.736033         0.892522       1.241505   \n",
       "3          0.447258      0.743641         0.896566       1.259414   \n",
       "4          0.441814      0.755149         0.902679       1.259414   \n",
       "5          0.437018      0.767961         0.908946       1.266725   \n",
       "\n",
       "   training_classification_error  validation_rmse  validation_logloss  \\\n",
       "0                       0.219572         0.410746            0.520379   \n",
       "1                       0.190211         0.384600            0.467335   \n",
       "2                       0.185101         0.377888            0.454646   \n",
       "3                       0.183403         0.375966            0.450893   \n",
       "4                       0.180705         0.375288            0.449365   \n",
       "5                       0.179834         0.374895            0.448369   \n",
       "\n",
       "   validation_auc  validation_pr_auc  validation_lift  \\\n",
       "0        0.500000           0.000000         1.000000   \n",
       "1        0.717767           0.885046         1.198281   \n",
       "2        0.720757           0.885553         1.211134   \n",
       "3        0.723132           0.886708         1.197732   \n",
       "4        0.724709           0.888470         1.206166   \n",
       "5        0.728197           0.890451         1.223036   \n",
       "\n",
       "   validation_classification_error  \n",
       "0                         0.214851  \n",
       "1                         0.191563  \n",
       "2                         0.185308  \n",
       "3                         0.184177  \n",
       "4                         0.183911  \n",
       "5                         0.183645  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm_embeddings.scoring_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline AUC: 0.725\n",
      "With Embeddings AUC: 0.728\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "See a metrics comparison <a href=/mlflow/#/metric/training_auc?runs=[\"ac7ab3a95183\",\"ac7ab3a95183\"]&experiment=1&plot_metric_keys=[\"training_auc\",\"validation_auc\",\"training_pr_auc\",\"validation_pr_auc\"]>here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Baseline AUC: \" + str(round(gbm_baseline.auc(valid = True), 3)))\n",
    "print(\"With Embeddings AUC: \" + str(round(gbm_embeddings.auc(valid = True), 3)))\n",
    "link = f'/mlflow/#/metric/training_auc?runs=[\"{cur_run}\",\"{old_run}\"]&experiment={cur_exp}&plot_metric_keys=[\"training_auc\",\\\"validation_auc\\\",\\\"training_pr_auc\\\",\\\"validation_pr_auc\\\"]'\n",
    "HTML(f'See a metrics comparison <a href={link}>here</a>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# That's some great imrpovement! So what's next?\n",
    "<blockquote>We included the customer reviews and developed a better model. We've logged everything to MLFlow for detailed comparisons. Now what?<br>\n",
    "    Let's deploy our models to production so we can utilize what we've built. First, we'll deploy our word vectorizer model, and then deploy our GBM model. Finally, we'll create a feed from the first model to the second, so we can see the final predictions!\n",
    "        </i></br><footer>Splice Machine</footer></blockquote><br>\n",
    "<img src=https://splice-demo.s3.amazonaws.com/H2O+Demo+Model+Diagram.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Deploy Word2Vec Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function _deploy_db in module splicemachine.mlflow_support.mlflow_support:\n",
      "\n",
      "_deploy_db(fittedModel, df, db_schema_name, db_table_name, primary_key, run_id: str = None, classes=None, sklearn_args={}, verbose=False, pred_threshold=None, replace=False) -> None\n",
      "    Function to deploy a trained (currently Spark, Sklearn or H2O) model to the Database.\n",
      "    This creates 2 tables: One with the features of the model, and one with the prediction and metadata.\n",
      "    They are linked with a column called MOMENT_ID\n",
      "    \n",
      "    :param fittedModel: (ML pipeline or model) The fitted pipeline to deploy\n",
      "    :param df: (Spark DF) The dataframe used to train the model\n",
      "                NOTE: this dataframe should NOT be transformed by the model. The columns in this df are the ones\n",
      "                that will be used to create the table.\n",
      "    :param db_schema_name: (str) the schema name to deploy to. If None, the currently set schema will be used.\n",
      "    :param db_table_name: (str) the table name to deploy to. If none, the run_id will be used for the table name(s)\n",
      "    :param primary_key: (List[Tuple[str, str]]) List of column + SQL datatype to use for the primary/composite key\n",
      "    :param run_id: (str) The active run_id\n",
      "    :param classes: (List[str]) The classes (prediction labels) for the model being deployed.\n",
      "                    NOTE: If not supplied, the table will have default column names for each class\n",
      "    :param sklearn_args: (dict{str: str}) Prediction options for sklearn models\n",
      "                        Available key value options:\n",
      "                        'predict_call': 'predict', 'predict_proba', or 'transform'\n",
      "                                                                       - Determines the function call for the model\n",
      "                                                                       If blank, predict will be used\n",
      "                                                                       (or transform if model doesn't have predict)\n",
      "                        'predict_args': 'return_std' or 'return_cov' - For Bayesian and Gaussian models\n",
      "                                                                         Only one can be specified\n",
      "                        If the model does not have the option specified, it will be ignored.\n",
      "    :param verbose: (bool) Whether or not to print out the queries being created. Helpful for debugging\n",
      "    :param pred_threshold: (double) A prediction threshold for *Keras* binary classification models\n",
      "                            If the model type isn't Keras, this parameter will be ignored\n",
      "                            NOTE: If the model type is Keras, the output layer has 1 node, and pred_threshold is None,\n",
      "                                  you will NOT receive a class prediction, only the output of the final layer (like model.predict()).\n",
      "                                  If you want a class prediction\n",
      "                                  for your binary classification problem, you MUST pass in a threshold.\n",
      "    :param replace: (bool) whether or not to replace a currently existing model. This param does not yet work\n",
      "    \n",
      "    \n",
      "    This function creates the following:\n",
      "    * Table (default called DATA_{run_id}) where run_id is the run_id of the mlflow run associated to that model.\n",
      "        This will have a column for each feature in the feature vector as well as a MOMENT_ID as primary key\n",
      "    * Table (default called DATA_{run_id}_PREDS) That will have the columns:\n",
      "        USER which is the current user who made the request\n",
      "        EVAL_TIME which is the CURRENT_TIMESTAMP\n",
      "        MOMENT_ID same as the DATA table to link predictions to rows in the table\n",
      "        PREDICTION. The prediction of the model. If the :classes: param is not filled in, this will be default values for classification models\n",
      "        A column for each class of the predictor with the value being the probability/confidence of the model if applicable\n",
      "    * A trigger that runs on (after) insertion to the data table that runs an INSERT into the prediction table,\n",
      "        calling the PREDICT function, passing in the row of data as well as the schema of the dataset, and the run_id of the model to run\n",
      "    * A trigger that runs on (after) insertion to the prediction table that calls an UPDATE to the row inserted,\n",
      "        parsing the prediction probabilities and filling in proper column values\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(mlflow.deploy_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model of size: 8014.339 KB to Splice Machine DB\n",
      "Deploying model b8738905c16c to table BEN.word_vec_model\n",
      "Creating data table ... \n",
      " CREATE TABLE BEN.word_vec_model (\n",
      "\tReview VARCHAR(5000),\tMOMENT_KEY INT,\n",
      "\tPRIMARY KEY(MOMENT_KEY)\n",
      ")\n",
      "\n",
      "Done.\n",
      "Creating prediction table ... \n",
      "CREATE TABLE BEN.word_vec_model_PREDS (\n",
      "        \tCUR_USER VARCHAR(50) DEFAULT CURRENT_USER,\n",
      "        \tEVAL_TIME TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
      "        \tRUN_ID VARCHAR(50) DEFAULT 'b8738905c16c',\n",
      "        \tMOMENT_KEY INT,\n",
      "\t\"C1_C0\" DOUBLE,\n",
      "\t\"C1_C1\" DOUBLE,\n",
      "\t\"C1_C2\" DOUBLE,\n",
      "\t\"C1_C3\" DOUBLE,\n",
      "\t\"C1_C4\" DOUBLE,\n",
      "\t\"C1_C5\" DOUBLE,\n",
      "\t\"C1_C6\" DOUBLE,\n",
      "\t\"C1_C7\" DOUBLE,\n",
      "\t\"C1_C8\" DOUBLE,\n",
      "\t\"C1_C9\" DOUBLE,\n",
      "\t\"C1_C10\" DOUBLE,\n",
      "\t\"C1_C11\" DOUBLE,\n",
      "\t\"C1_C12\" DOUBLE,\n",
      "\t\"C1_C13\" DOUBLE,\n",
      "\t\"C1_C14\" DOUBLE,\n",
      "\t\"C1_C15\" DOUBLE,\n",
      "\t\"C1_C16\" DOUBLE,\n",
      "\t\"C1_C17\" DOUBLE,\n",
      "\t\"C1_C18\" DOUBLE,\n",
      "\t\"C1_C19\" DOUBLE,\n",
      "\t\"C1_C20\" DOUBLE,\n",
      "\t\"C1_C21\" DOUBLE,\n",
      "\t\"C1_C22\" DOUBLE,\n",
      "\t\"C1_C23\" DOUBLE,\n",
      "\t\"C1_C24\" DOUBLE,\n",
      "\t\"C1_C25\" DOUBLE,\n",
      "\t\"C1_C26\" DOUBLE,\n",
      "\t\"C1_C27\" DOUBLE,\n",
      "\t\"C1_C28\" DOUBLE,\n",
      "\t\"C1_C29\" DOUBLE,\n",
      "\t\"C1_C30\" DOUBLE,\n",
      "\t\"C1_C31\" DOUBLE,\n",
      "\t\"C1_C32\" DOUBLE,\n",
      "\t\"C1_C33\" DOUBLE,\n",
      "\t\"C1_C34\" DOUBLE,\n",
      "\t\"C1_C35\" DOUBLE,\n",
      "\t\"C1_C36\" DOUBLE,\n",
      "\t\"C1_C37\" DOUBLE,\n",
      "\t\"C1_C38\" DOUBLE,\n",
      "\t\"C1_C39\" DOUBLE,\n",
      "\t\"C1_C40\" DOUBLE,\n",
      "\t\"C1_C41\" DOUBLE,\n",
      "\t\"C1_C42\" DOUBLE,\n",
      "\t\"C1_C43\" DOUBLE,\n",
      "\t\"C1_C44\" DOUBLE,\n",
      "\t\"C1_C45\" DOUBLE,\n",
      "\t\"C1_C46\" DOUBLE,\n",
      "\t\"C1_C47\" DOUBLE,\n",
      "\t\"C1_C48\" DOUBLE,\n",
      "\t\"C1_C49\" DOUBLE,\n",
      "\t\"C1_C50\" DOUBLE,\n",
      "\t\"C1_C51\" DOUBLE,\n",
      "\t\"C1_C52\" DOUBLE,\n",
      "\t\"C1_C53\" DOUBLE,\n",
      "\t\"C1_C54\" DOUBLE,\n",
      "\t\"C1_C55\" DOUBLE,\n",
      "\t\"C1_C56\" DOUBLE,\n",
      "\t\"C1_C57\" DOUBLE,\n",
      "\t\"C1_C58\" DOUBLE,\n",
      "\t\"C1_C59\" DOUBLE,\n",
      "\t\"C1_C60\" DOUBLE,\n",
      "\t\"C1_C61\" DOUBLE,\n",
      "\t\"C1_C62\" DOUBLE,\n",
      "\t\"C1_C63\" DOUBLE,\n",
      "\t\"C1_C64\" DOUBLE,\n",
      "\t\"C1_C65\" DOUBLE,\n",
      "\t\"C1_C66\" DOUBLE,\n",
      "\t\"C1_C67\" DOUBLE,\n",
      "\t\"C1_C68\" DOUBLE,\n",
      "\t\"C1_C69\" DOUBLE,\n",
      "\t\"C1_C70\" DOUBLE,\n",
      "\t\"C1_C71\" DOUBLE,\n",
      "\t\"C1_C72\" DOUBLE,\n",
      "\t\"C1_C73\" DOUBLE,\n",
      "\t\"C1_C74\" DOUBLE,\n",
      "\t\"C1_C75\" DOUBLE,\n",
      "\t\"C1_C76\" DOUBLE,\n",
      "\t\"C1_C77\" DOUBLE,\n",
      "\t\"C1_C78\" DOUBLE,\n",
      "\t\"C1_C79\" DOUBLE,\n",
      "\t\"C1_C80\" DOUBLE,\n",
      "\t\"C1_C81\" DOUBLE,\n",
      "\t\"C1_C82\" DOUBLE,\n",
      "\t\"C1_C83\" DOUBLE,\n",
      "\t\"C1_C84\" DOUBLE,\n",
      "\t\"C1_C85\" DOUBLE,\n",
      "\t\"C1_C86\" DOUBLE,\n",
      "\t\"C1_C87\" DOUBLE,\n",
      "\t\"C1_C88\" DOUBLE,\n",
      "\t\"C1_C89\" DOUBLE,\n",
      "\t\"C1_C90\" DOUBLE,\n",
      "\t\"C1_C91\" DOUBLE,\n",
      "\t\"C1_C92\" DOUBLE,\n",
      "\t\"C1_C93\" DOUBLE,\n",
      "\t\"C1_C94\" DOUBLE,\n",
      "\t\"C1_C95\" DOUBLE,\n",
      "\t\"C1_C96\" DOUBLE,\n",
      "\t\"C1_C97\" DOUBLE,\n",
      "\t\"C1_C98\" DOUBLE,\n",
      "\t\"C1_C99\" DOUBLE,\n",
      "\tPRIMARY KEY(MOMENT_KEY)\n",
      ")\n",
      "\n",
      "Done.\n",
      "Creating model prediction trigger ... \n",
      "CREATE TRIGGER runModel_BEN_word_vec_model_b8738905c16c\n",
      " \tAFTER INSERT\n",
      " \tON BEN.word_vec_model\n",
      " \tREFERENCING NEW AS NEWROW\n",
      " \tFOR EACH ROW\n",
      " \t\tINSERT INTO BEN.word_vec_model_PREDS(MOMENT_KEY,\"C1_C0\",\"C1_C1\",\"C1_C2\",\"C1_C3\",\"C1_C4\",\"C1_C5\",\"C1_C6\",\"C1_C7\",\"C1_C8\",\"C1_C9\",\"C1_C10\",\"C1_C11\",\"C1_C12\",\"C1_C13\",\"C1_C14\",\"C1_C15\",\"C1_C16\",\"C1_C17\",\"C1_C18\",\"C1_C19\",\"C1_C20\",\"C1_C21\",\"C1_C22\",\"C1_C23\",\"C1_C24\",\"C1_C25\",\"C1_C26\",\"C1_C27\",\"C1_C28\",\"C1_C29\",\"C1_C30\",\"C1_C31\",\"C1_C32\",\"C1_C33\",\"C1_C34\",\"C1_C35\",\"C1_C36\",\"C1_C37\",\"C1_C38\",\"C1_C39\",\"C1_C40\",\"C1_C41\",\"C1_C42\",\"C1_C43\",\"C1_C44\",\"C1_C45\",\"C1_C46\",\"C1_C47\",\"C1_C48\",\"C1_C49\",\"C1_C50\",\"C1_C51\",\"C1_C52\",\"C1_C53\",\"C1_C54\",\"C1_C55\",\"C1_C56\",\"C1_C57\",\"C1_C58\",\"C1_C59\",\"C1_C60\",\"C1_C61\",\"C1_C62\",\"C1_C63\",\"C1_C64\",\"C1_C65\",\"C1_C66\",\"C1_C67\",\"C1_C68\",\"C1_C69\",\"C1_C70\",\"C1_C71\",\"C1_C72\",\"C1_C73\",\"C1_C74\",\"C1_C75\",\"C1_C76\",\"C1_C77\",\"C1_C78\",\"C1_C79\",\"C1_C80\",\"C1_C81\",\"C1_C82\",\"C1_C83\",\"C1_C84\",\"C1_C85\",\"C1_C86\",\"C1_C87\",\"C1_C88\",\"C1_C89\",\"C1_C90\",\"C1_C91\",\"C1_C92\",\"C1_C93\",\"C1_C94\",\"C1_C95\",\"C1_C96\",\"C1_C97\",\"C1_C98\",\"C1_C99\") SELECT \tNEWROW.MOMENT_KEY, b.\"C1_C0\",b.\"C1_C1\",b.\"C1_C2\",b.\"C1_C3\",b.\"C1_C4\",b.\"C1_C5\",b.\"C1_C6\",b.\"C1_C7\",b.\"C1_C8\",b.\"C1_C9\",b.\"C1_C10\",b.\"C1_C11\",b.\"C1_C12\",b.\"C1_C13\",b.\"C1_C14\",b.\"C1_C15\",b.\"C1_C16\",b.\"C1_C17\",b.\"C1_C18\",b.\"C1_C19\",b.\"C1_C20\",b.\"C1_C21\",b.\"C1_C22\",b.\"C1_C23\",b.\"C1_C24\",b.\"C1_C25\",b.\"C1_C26\",b.\"C1_C27\",b.\"C1_C28\",b.\"C1_C29\",b.\"C1_C30\",b.\"C1_C31\",b.\"C1_C32\",b.\"C1_C33\",b.\"C1_C34\",b.\"C1_C35\",b.\"C1_C36\",b.\"C1_C37\",b.\"C1_C38\",b.\"C1_C39\",b.\"C1_C40\",b.\"C1_C41\",b.\"C1_C42\",b.\"C1_C43\",b.\"C1_C44\",b.\"C1_C45\",b.\"C1_C46\",b.\"C1_C47\",b.\"C1_C48\",b.\"C1_C49\",b.\"C1_C50\",b.\"C1_C51\",b.\"C1_C52\",b.\"C1_C53\",b.\"C1_C54\",b.\"C1_C55\",b.\"C1_C56\",b.\"C1_C57\",b.\"C1_C58\",b.\"C1_C59\",b.\"C1_C60\",b.\"C1_C61\",b.\"C1_C62\",b.\"C1_C63\",b.\"C1_C64\",b.\"C1_C65\",b.\"C1_C66\",b.\"C1_C67\",b.\"C1_C68\",b.\"C1_C69\",b.\"C1_C70\",b.\"C1_C71\",b.\"C1_C72\",b.\"C1_C73\",b.\"C1_C74\",b.\"C1_C75\",b.\"C1_C76\",b.\"C1_C77\",b.\"C1_C78\",b.\"C1_C79\",b.\"C1_C80\",b.\"C1_C81\",b.\"C1_C82\",b.\"C1_C83\",b.\"C1_C84\",b.\"C1_C85\",b.\"C1_C86\",b.\"C1_C87\",b.\"C1_C88\",b.\"C1_C89\",b.\"C1_C90\",b.\"C1_C91\",b.\"C1_C92\",b.\"C1_C93\",b.\"C1_C94\",b.\"C1_C95\",b.\"C1_C96\",b.\"C1_C97\",b.\"C1_C98\",b.\"C1_C99\" FROM new com.splicemachine.mlrunner.MLRunner('key_value', 'b8738905c16c', TRIM(CAST(NEWROW.Review as CHAR(41))), 'Review VARCHAR(5000)') as b (\"C1_C0\" DOUBLE,\"C1_C1\" DOUBLE,\"C1_C2\" DOUBLE,\"C1_C3\" DOUBLE,\"C1_C4\" DOUBLE,\"C1_C5\" DOUBLE,\"C1_C6\" DOUBLE,\"C1_C7\" DOUBLE,\"C1_C8\" DOUBLE,\"C1_C9\" DOUBLE,\"C1_C10\" DOUBLE,\"C1_C11\" DOUBLE,\"C1_C12\" DOUBLE,\"C1_C13\" DOUBLE,\"C1_C14\" DOUBLE,\"C1_C15\" DOUBLE,\"C1_C16\" DOUBLE,\"C1_C17\" DOUBLE,\"C1_C18\" DOUBLE,\"C1_C19\" DOUBLE,\"C1_C20\" DOUBLE,\"C1_C21\" DOUBLE,\"C1_C22\" DOUBLE,\"C1_C23\" DOUBLE,\"C1_C24\" DOUBLE,\"C1_C25\" DOUBLE,\"C1_C26\" DOUBLE,\"C1_C27\" DOUBLE,\"C1_C28\" DOUBLE,\"C1_C29\" DOUBLE,\"C1_C30\" DOUBLE,\"C1_C31\" DOUBLE,\"C1_C32\" DOUBLE,\"C1_C33\" DOUBLE,\"C1_C34\" DOUBLE,\"C1_C35\" DOUBLE,\"C1_C36\" DOUBLE,\"C1_C37\" DOUBLE,\"C1_C38\" DOUBLE,\"C1_C39\" DOUBLE,\"C1_C40\" DOUBLE,\"C1_C41\" DOUBLE,\"C1_C42\" DOUBLE,\"C1_C43\" DOUBLE,\"C1_C44\" DOUBLE,\"C1_C45\" DOUBLE,\"C1_C46\" DOUBLE,\"C1_C47\" DOUBLE,\"C1_C48\" DOUBLE,\"C1_C49\" DOUBLE,\"C1_C50\" DOUBLE,\"C1_C51\" DOUBLE,\"C1_C52\" DOUBLE,\"C1_C53\" DOUBLE,\"C1_C54\" DOUBLE,\"C1_C55\" DOUBLE,\"C1_C56\" DOUBLE,\"C1_C57\" DOUBLE,\"C1_C58\" DOUBLE,\"C1_C59\" DOUBLE,\"C1_C60\" DOUBLE,\"C1_C61\" DOUBLE,\"C1_C62\" DOUBLE,\"C1_C63\" DOUBLE,\"C1_C64\" DOUBLE,\"C1_C65\" DOUBLE,\"C1_C66\" DOUBLE,\"C1_C67\" DOUBLE,\"C1_C68\" DOUBLE,\"C1_C69\" DOUBLE,\"C1_C70\" DOUBLE,\"C1_C71\" DOUBLE,\"C1_C72\" DOUBLE,\"C1_C73\" DOUBLE,\"C1_C74\" DOUBLE,\"C1_C75\" DOUBLE,\"C1_C76\" DOUBLE,\"C1_C77\" DOUBLE,\"C1_C78\" DOUBLE,\"C1_C79\" DOUBLE,\"C1_C80\" DOUBLE,\"C1_C81\" DOUBLE,\"C1_C82\" DOUBLE,\"C1_C83\" DOUBLE,\"C1_C84\" DOUBLE,\"C1_C85\" DOUBLE,\"C1_C86\" DOUBLE,\"C1_C87\" DOUBLE,\"C1_C88\" DOUBLE,\"C1_C89\" DOUBLE,\"C1_C90\" DOUBLE,\"C1_C91\" DOUBLE,\"C1_C92\" DOUBLE,\"C1_C93\" DOUBLE,\"C1_C94\" DOUBLE,\"C1_C95\" DOUBLE,\"C1_C96\" DOUBLE,\"C1_C97\" DOUBLE,\"C1_C98\" DOUBLE,\"C1_C99\" DOUBLE)\n",
      "\n",
      "Done.\n",
      "Model Deployed.\n"
     ]
    }
   ],
   "source": [
    "# Get the run_id from the name. Note that multiple runs can have the same name, so this returns a list\n",
    "run_id = mlflow.get_run_ids_by_name('review_tokenizer')[0]\n",
    "# Get the model from that run\n",
    "w2v_model = mlflow.load_model(run_id=run_id, name='review_vectorizer_model')\n",
    "deploy_df = hc.asSparkFrame(reviews[['Text']]).withColumnRenamed('Text', 'Review')\n",
    "schema = 'REPLACE_ME_DBSCHEMA'\n",
    "schema='BEN'\n",
    "mlflow.deploy_db(w2v_model, deploy_df, schema, 'word_vec_model', [('MOMENT_KEY', 'INT')], run_id=run_id, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sweet! Let's try it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>Review                                                      </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>Tastes like Earl Grey, but it&#x27;s green tea so it&#x27;s healthier.</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">        C1</th><th style=\"text-align: right;\">        C2</th><th style=\"text-align: right;\">        C3</th><th style=\"text-align: right;\">       C4</th><th style=\"text-align: right;\">         C5</th><th style=\"text-align: right;\">         C6</th><th style=\"text-align: right;\">        C7</th><th style=\"text-align: right;\">        C8</th><th style=\"text-align: right;\">        C9</th><th style=\"text-align: right;\">       C10</th><th style=\"text-align: right;\">       C11</th><th style=\"text-align: right;\">       C12</th><th style=\"text-align: right;\">        C13</th><th style=\"text-align: right;\">        C14</th><th style=\"text-align: right;\">       C15</th><th style=\"text-align: right;\">     C16</th><th style=\"text-align: right;\">       C17</th><th style=\"text-align: right;\">        C18</th><th style=\"text-align: right;\">      C19</th><th style=\"text-align: right;\">        C20</th><th style=\"text-align: right;\">       C21</th><th style=\"text-align: right;\">       C22</th><th style=\"text-align: right;\">      C23</th><th style=\"text-align: right;\">         C24</th><th style=\"text-align: right;\">      C25</th><th style=\"text-align: right;\">       C26</th><th style=\"text-align: right;\">        C27</th><th style=\"text-align: right;\">       C28</th><th style=\"text-align: right;\">        C29</th><th style=\"text-align: right;\">        C30</th><th style=\"text-align: right;\">       C31</th><th style=\"text-align: right;\">         C32</th><th style=\"text-align: right;\">       C33</th><th style=\"text-align: right;\">        C34</th><th style=\"text-align: right;\">       C35</th><th style=\"text-align: right;\">      C36</th><th style=\"text-align: right;\">      C37</th><th style=\"text-align: right;\">       C38</th><th style=\"text-align: right;\">       C39</th><th style=\"text-align: right;\">        C40</th><th style=\"text-align: right;\">       C41</th><th style=\"text-align: right;\">       C42</th><th style=\"text-align: right;\">       C43</th><th style=\"text-align: right;\">        C44</th><th style=\"text-align: right;\">        C45</th><th style=\"text-align: right;\">         C46</th><th style=\"text-align: right;\">       C47</th><th style=\"text-align: right;\">      C48</th><th style=\"text-align: right;\">        C49</th><th style=\"text-align: right;\">       C50</th><th style=\"text-align: right;\">       C51</th><th style=\"text-align: right;\">        C52</th><th style=\"text-align: right;\">        C53</th><th style=\"text-align: right;\">        C54</th><th style=\"text-align: right;\">        C55</th><th style=\"text-align: right;\">       C56</th><th style=\"text-align: right;\">         C57</th><th style=\"text-align: right;\">      C58</th><th style=\"text-align: right;\">       C59</th><th style=\"text-align: right;\">        C60</th><th style=\"text-align: right;\">       C61</th><th style=\"text-align: right;\">       C62</th><th style=\"text-align: right;\">       C63</th><th style=\"text-align: right;\">        C64</th><th style=\"text-align: right;\">        C65</th><th style=\"text-align: right;\">        C66</th><th style=\"text-align: right;\">       C67</th><th style=\"text-align: right;\">      C68</th><th style=\"text-align: right;\">       C69</th><th style=\"text-align: right;\">       C70</th><th style=\"text-align: right;\">        C71</th><th style=\"text-align: right;\">        C72</th><th style=\"text-align: right;\">       C73</th><th style=\"text-align: right;\">       C74</th><th style=\"text-align: right;\">       C75</th><th style=\"text-align: right;\">       C76</th><th style=\"text-align: right;\">        C77</th><th style=\"text-align: right;\">       C78</th><th style=\"text-align: right;\">       C79</th><th style=\"text-align: right;\">       C80</th><th style=\"text-align: right;\">        C81</th><th style=\"text-align: right;\">       C82</th><th style=\"text-align: right;\">         C83</th><th style=\"text-align: right;\">        C84</th><th style=\"text-align: right;\">       C85</th><th style=\"text-align: right;\">        C86</th><th style=\"text-align: right;\">       C87</th><th style=\"text-align: right;\">       C88</th><th style=\"text-align: right;\">       C89</th><th style=\"text-align: right;\">        C90</th><th style=\"text-align: right;\">        C91</th><th style=\"text-align: right;\">       C92</th><th style=\"text-align: right;\">        C93</th><th style=\"text-align: right;\">       C94</th><th style=\"text-align: right;\">        C95</th><th style=\"text-align: right;\">        C96</th><th style=\"text-align: right;\">       C97</th><th style=\"text-align: right;\">        C98</th><th style=\"text-align: right;\">        C99</th><th style=\"text-align: right;\">       C100</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\"> 0.0118207</td><td style=\"text-align: right;\">-0.101889 </td><td style=\"text-align: right;\"> 0.0147137</td><td style=\"text-align: right;\">0.278492 </td><td style=\"text-align: right;\"> 0.0469628 </td><td style=\"text-align: right;\">-0.172297  </td><td style=\"text-align: right;\">-0.0129039</td><td style=\"text-align: right;\"> 0.0830429</td><td style=\"text-align: right;\">-0.0914811</td><td style=\"text-align: right;\"> 0.0574676</td><td style=\"text-align: right;\">-0.0639514</td><td style=\"text-align: right;\"> 0.120431 </td><td style=\"text-align: right;\">-0.0962916 </td><td style=\"text-align: right;\">-0.0178387 </td><td style=\"text-align: right;\"> 0.0759381</td><td style=\"text-align: right;\">0.179793</td><td style=\"text-align: right;\">-0.0157825</td><td style=\"text-align: right;\">-0.12134   </td><td style=\"text-align: right;\">0.0527563</td><td style=\"text-align: right;\"> 0.0573318 </td><td style=\"text-align: right;\"> 0.0509253</td><td style=\"text-align: right;\"> 0.120528 </td><td style=\"text-align: right;\">0.15535  </td><td style=\"text-align: right;\">-0.0792156  </td><td style=\"text-align: right;\">0.0379387</td><td style=\"text-align: right;\">-0.0660397</td><td style=\"text-align: right;\">-0.00495673</td><td style=\"text-align: right;\">-0.079089 </td><td style=\"text-align: right;\">-0.0337948 </td><td style=\"text-align: right;\"> 0.0854287 </td><td style=\"text-align: right;\">-0.270305 </td><td style=\"text-align: right;\"> 0.14011    </td><td style=\"text-align: right;\"> 0.0664857</td><td style=\"text-align: right;\">-0.0903058 </td><td style=\"text-align: right;\">-0.0534608</td><td style=\"text-align: right;\">0.139986 </td><td style=\"text-align: right;\">0.114537 </td><td style=\"text-align: right;\">-0.0631098</td><td style=\"text-align: right;\">-0.145617 </td><td style=\"text-align: right;\"> 0.00200458</td><td style=\"text-align: right;\"> 0.195605 </td><td style=\"text-align: right;\">-0.12095  </td><td style=\"text-align: right;\"> 0.0142132</td><td style=\"text-align: right;\"> 0.00382048</td><td style=\"text-align: right;\"> 0.00467813</td><td style=\"text-align: right;\">-0.0647183  </td><td style=\"text-align: right;\"> 0.12261  </td><td style=\"text-align: right;\">0.10863  </td><td style=\"text-align: right;\">-0.179427  </td><td style=\"text-align: right;\"> 0.100265 </td><td style=\"text-align: right;\">-0.0961187</td><td style=\"text-align: right;\"> 0.108058  </td><td style=\"text-align: right;\"> 0.0614284 </td><td style=\"text-align: right;\">-0.113856  </td><td style=\"text-align: right;\">-0.0481913 </td><td style=\"text-align: right;\">-0.0260456</td><td style=\"text-align: right;\"> 0.0346338  </td><td style=\"text-align: right;\">0.127268 </td><td style=\"text-align: right;\"> 0.112572 </td><td style=\"text-align: right;\">-0.0689213 </td><td style=\"text-align: right;\"> 0.032635 </td><td style=\"text-align: right;\"> 0.1602   </td><td style=\"text-align: right;\">-0.0245575</td><td style=\"text-align: right;\">-0.0889716 </td><td style=\"text-align: right;\"> 0.0344523 </td><td style=\"text-align: right;\"> 0.0388336 </td><td style=\"text-align: right;\">-0.0977627</td><td style=\"text-align: right;\">0.0664074</td><td style=\"text-align: right;\">-0.0214509</td><td style=\"text-align: right;\">-0.0922424</td><td style=\"text-align: right;\">-0.0759032 </td><td style=\"text-align: right;\"> 0.168529  </td><td style=\"text-align: right;\"> 0.0484152</td><td style=\"text-align: right;\">0.0341554 </td><td style=\"text-align: right;\">-0.0530976</td><td style=\"text-align: right;\"> 0.0814525</td><td style=\"text-align: right;\"> 0.114328  </td><td style=\"text-align: right;\"> 0.118376 </td><td style=\"text-align: right;\"> 0.0836662</td><td style=\"text-align: right;\">-0.155847 </td><td style=\"text-align: right;\"> 0.0524612 </td><td style=\"text-align: right;\">-0.0582578</td><td style=\"text-align: right;\"> 0.0343186  </td><td style=\"text-align: right;\">-0.0191061 </td><td style=\"text-align: right;\"> 0.0982101</td><td style=\"text-align: right;\">-0.0475758 </td><td style=\"text-align: right;\">0.00883958</td><td style=\"text-align: right;\"> 0.159842 </td><td style=\"text-align: right;\">-0.0601515</td><td style=\"text-align: right;\"> 0.0405056 </td><td style=\"text-align: right;\">-0.00583725</td><td style=\"text-align: right;\">-0.113468 </td><td style=\"text-align: right;\"> 0.0123878 </td><td style=\"text-align: right;\"> 0.0548682</td><td style=\"text-align: right;\"> 0.0231149 </td><td style=\"text-align: right;\">-0.153038  </td><td style=\"text-align: right;\">-0.0830139</td><td style=\"text-align: right;\"> 0.0517786 </td><td style=\"text-align: right;\">-0.167759  </td><td style=\"text-align: right;\"> 0.0590884 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">-0.0647607</td><td style=\"text-align: right;\">-0.0727755</td><td style=\"text-align: right;\">-0.115707 </td><td style=\"text-align: right;\">0.0486232</td><td style=\"text-align: right;\"> 0.00228006</td><td style=\"text-align: right;\">-0.0894267 </td><td style=\"text-align: right;\">-0.0550715</td><td style=\"text-align: right;\"> 0.0182499</td><td style=\"text-align: right;\"> 0.104742 </td><td style=\"text-align: right;\"> 0.0961806</td><td style=\"text-align: right;\">-0.0779413</td><td style=\"text-align: right;\">-0.0978953</td><td style=\"text-align: right;\"> 0.115459  </td><td style=\"text-align: right;\">-0.153234  </td><td style=\"text-align: right;\"> 0.0496184</td><td style=\"text-align: right;\">0.168469</td><td style=\"text-align: right;\">-0.0180559</td><td style=\"text-align: right;\"> 0.122231  </td><td style=\"text-align: right;\">0.0145231</td><td style=\"text-align: right;\"> 0.0172325 </td><td style=\"text-align: right;\">-0.0637962</td><td style=\"text-align: right;\">-0.126619 </td><td style=\"text-align: right;\">0.15836  </td><td style=\"text-align: right;\">-0.0885775  </td><td style=\"text-align: right;\">0.0203511</td><td style=\"text-align: right;\">-0.0701156</td><td style=\"text-align: right;\">-0.040133  </td><td style=\"text-align: right;\">-0.304234 </td><td style=\"text-align: right;\">-0.0746839 </td><td style=\"text-align: right;\">-0.0674719 </td><td style=\"text-align: right;\">-0.103309 </td><td style=\"text-align: right;\"> 0.0273377  </td><td style=\"text-align: right;\"> 0.108569 </td><td style=\"text-align: right;\"> 0.0180806 </td><td style=\"text-align: right;\">-0.0350313</td><td style=\"text-align: right;\">0.21245  </td><td style=\"text-align: right;\">0.0424701</td><td style=\"text-align: right;\">-0.126426 </td><td style=\"text-align: right;\">-0.0514539</td><td style=\"text-align: right;\">-0.112131  </td><td style=\"text-align: right;\"> 0.0785268</td><td style=\"text-align: right;\">-0.0475902</td><td style=\"text-align: right;\">-0.166364 </td><td style=\"text-align: right;\"> 0.253536  </td><td style=\"text-align: right;\">-0.0662786 </td><td style=\"text-align: right;\"> 0.133733   </td><td style=\"text-align: right;\"> 0.139492 </td><td style=\"text-align: right;\">0.144991 </td><td style=\"text-align: right;\"> 0.00557501</td><td style=\"text-align: right;\">-0.079479 </td><td style=\"text-align: right;\">-0.0282375</td><td style=\"text-align: right;\">-0.0368711 </td><td style=\"text-align: right;\"> 0.0286063 </td><td style=\"text-align: right;\">-0.0782206 </td><td style=\"text-align: right;\"> 0.00642933</td><td style=\"text-align: right;\"> 0.11829  </td><td style=\"text-align: right;\"> 0.00523307 </td><td style=\"text-align: right;\">0.0984682</td><td style=\"text-align: right;\">-0.0332558</td><td style=\"text-align: right;\"> 0.0394351 </td><td style=\"text-align: right;\"> 0.0516561</td><td style=\"text-align: right;\"> 0.191958 </td><td style=\"text-align: right;\">-0.0593793</td><td style=\"text-align: right;\">-0.0620899 </td><td style=\"text-align: right;\"> 0.00285376</td><td style=\"text-align: right;\"> 0.0289805 </td><td style=\"text-align: right;\">-0.0604133</td><td style=\"text-align: right;\">0.0530364</td><td style=\"text-align: right;\">-0.0330077</td><td style=\"text-align: right;\"> 0.0675788</td><td style=\"text-align: right;\">-0.0419845 </td><td style=\"text-align: right;\"> 0.157696  </td><td style=\"text-align: right;\"> 0.0653407</td><td style=\"text-align: right;\">0.161192  </td><td style=\"text-align: right;\"> 0.0112189</td><td style=\"text-align: right;\"> 0.111598 </td><td style=\"text-align: right;\"> 0.0453798 </td><td style=\"text-align: right;\"> 0.194989 </td><td style=\"text-align: right;\"> 0.138888 </td><td style=\"text-align: right;\"> 0.0231592</td><td style=\"text-align: right;\"> 0.00690089</td><td style=\"text-align: right;\">-0.166217 </td><td style=\"text-align: right;\">-0.0599659  </td><td style=\"text-align: right;\">-0.102449  </td><td style=\"text-align: right;\"> 0.0882302</td><td style=\"text-align: right;\">-0.00776763</td><td style=\"text-align: right;\">0.113629  </td><td style=\"text-align: right;\"> 0.0108894</td><td style=\"text-align: right;\">-0.222703 </td><td style=\"text-align: right;\">-0.15212   </td><td style=\"text-align: right;\">-0.0933445 </td><td style=\"text-align: right;\">-0.0339013</td><td style=\"text-align: right;\"> 0.0440877 </td><td style=\"text-align: right;\">-0.116198 </td><td style=\"text-align: right;\"> 0.00132958</td><td style=\"text-align: right;\">-0.00732167</td><td style=\"text-align: right;\">-0.157039 </td><td style=\"text-align: right;\">-0.039421  </td><td style=\"text-align: right;\">-0.0166677 </td><td style=\"text-align: right;\">-0.0640155 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">-0.0385096</td><td style=\"text-align: right;\">-0.164311 </td><td style=\"text-align: right;\"> 0.0749115</td><td style=\"text-align: right;\">0.105914 </td><td style=\"text-align: right;\"> 0.0364867 </td><td style=\"text-align: right;\">-0.14865   </td><td style=\"text-align: right;\"> 0.0147054</td><td style=\"text-align: right;\"> 0.0432582</td><td style=\"text-align: right;\"> 0.0389016</td><td style=\"text-align: right;\"> 0.0396217</td><td style=\"text-align: right;\">-0.0317641</td><td style=\"text-align: right;\"> 0.095205 </td><td style=\"text-align: right;\">-0.0875548 </td><td style=\"text-align: right;\">-0.00580839</td><td style=\"text-align: right;\"> 0.0605815</td><td style=\"text-align: right;\">0.184019</td><td style=\"text-align: right;\">-0.0828741</td><td style=\"text-align: right;\">-0.075011  </td><td style=\"text-align: right;\">0.0940388</td><td style=\"text-align: right;\"> 0.0624332 </td><td style=\"text-align: right;\">-0.0170392</td><td style=\"text-align: right;\">-0.0428544</td><td style=\"text-align: right;\">0.127299 </td><td style=\"text-align: right;\"> 0.0350129  </td><td style=\"text-align: right;\">0.0544682</td><td style=\"text-align: right;\">-0.0712631</td><td style=\"text-align: right;\"> 0.0524339 </td><td style=\"text-align: right;\">-0.114599 </td><td style=\"text-align: right;\"> 0.0339514 </td><td style=\"text-align: right;\">-0.0160842 </td><td style=\"text-align: right;\">-0.206147 </td><td style=\"text-align: right;\">-0.0418927  </td><td style=\"text-align: right;\">-0.0193752</td><td style=\"text-align: right;\"> 0.0589492 </td><td style=\"text-align: right;\">-0.0550368</td><td style=\"text-align: right;\">0.160735 </td><td style=\"text-align: right;\">0.0416373</td><td style=\"text-align: right;\">-0.106153 </td><td style=\"text-align: right;\">-0.0952572</td><td style=\"text-align: right;\">-0.0907418 </td><td style=\"text-align: right;\"> 0.140228 </td><td style=\"text-align: right;\">-0.141172 </td><td style=\"text-align: right;\">-0.0906205</td><td style=\"text-align: right;\"> 0.172362  </td><td style=\"text-align: right;\">-0.0140963 </td><td style=\"text-align: right;\">-0.0684992  </td><td style=\"text-align: right;\"> 0.0649892</td><td style=\"text-align: right;\">0.218862 </td><td style=\"text-align: right;\">-0.112363  </td><td style=\"text-align: right;\"> 0.0910496</td><td style=\"text-align: right;\">-0.0594554</td><td style=\"text-align: right;\"> 0.0785124 </td><td style=\"text-align: right;\"> 0.0352732 </td><td style=\"text-align: right;\"> 0.00169446</td><td style=\"text-align: right;\"> 0.0356621 </td><td style=\"text-align: right;\"> 0.126364 </td><td style=\"text-align: right;\">-0.0982795  </td><td style=\"text-align: right;\">0.136849 </td><td style=\"text-align: right;\"> 0.0250553</td><td style=\"text-align: right;\">-0.132051  </td><td style=\"text-align: right;\"> 0.0240202</td><td style=\"text-align: right;\"> 0.0611908</td><td style=\"text-align: right;\">-0.0153794</td><td style=\"text-align: right;\">-0.0686614 </td><td style=\"text-align: right;\">-0.0755786 </td><td style=\"text-align: right;\"> 0.070956  </td><td style=\"text-align: right;\">-0.0514114</td><td style=\"text-align: right;\">0.101125 </td><td style=\"text-align: right;\">-0.0541772</td><td style=\"text-align: right;\"> 0.0603693</td><td style=\"text-align: right;\">-0.151588  </td><td style=\"text-align: right;\"> 0.118073  </td><td style=\"text-align: right;\"> 0.0864352</td><td style=\"text-align: right;\">0.0697684 </td><td style=\"text-align: right;\"> 0.0771088</td><td style=\"text-align: right;\"> 0.127461 </td><td style=\"text-align: right;\">-0.00255191</td><td style=\"text-align: right;\"> 0.171573 </td><td style=\"text-align: right;\"> 0.0162494</td><td style=\"text-align: right;\">-0.0422113</td><td style=\"text-align: right;\">-0.0200063 </td><td style=\"text-align: right;\">-0.016754 </td><td style=\"text-align: right;\">-0.0927813  </td><td style=\"text-align: right;\">-0.0477321 </td><td style=\"text-align: right;\">-0.0520219</td><td style=\"text-align: right;\">-0.123997  </td><td style=\"text-align: right;\">0.147805  </td><td style=\"text-align: right;\"> 0.0895179</td><td style=\"text-align: right;\">-0.0564334</td><td style=\"text-align: right;\"> 0.0667794 </td><td style=\"text-align: right;\">-0.0441478 </td><td style=\"text-align: right;\">-0.263763 </td><td style=\"text-align: right;\"> 0.0178793 </td><td style=\"text-align: right;\">-0.0385753</td><td style=\"text-align: right;\"> 0.0908309 </td><td style=\"text-align: right;\">-0.213796  </td><td style=\"text-align: right;\">-0.0448226</td><td style=\"text-align: right;\"> 0.0337263 </td><td style=\"text-align: right;\"> 0.0551377 </td><td style=\"text-align: right;\">-0.00646082</td></tr>\n",
       "<tr><td style=\"text-align: right;\">-0.0335025</td><td style=\"text-align: right;\">-0.104515 </td><td style=\"text-align: right;\"> 0.0670558</td><td style=\"text-align: right;\">0.125524 </td><td style=\"text-align: right;\"> 0.121117  </td><td style=\"text-align: right;\">-0.132281  </td><td style=\"text-align: right;\">-0.0278141</td><td style=\"text-align: right;\"> 0.0481801</td><td style=\"text-align: right;\"> 0.0214209</td><td style=\"text-align: right;\"> 0.0399683</td><td style=\"text-align: right;\">-0.0675355</td><td style=\"text-align: right;\"> 0.0613814</td><td style=\"text-align: right;\">-0.0557912 </td><td style=\"text-align: right;\">-0.0336307 </td><td style=\"text-align: right;\"> 0.0842112</td><td style=\"text-align: right;\">0.186743</td><td style=\"text-align: right;\">-0.087822 </td><td style=\"text-align: right;\"> 0.00219227</td><td style=\"text-align: right;\">0.108149 </td><td style=\"text-align: right;\">-0.00918456</td><td style=\"text-align: right;\">-0.0524869</td><td style=\"text-align: right;\">-0.0394393</td><td style=\"text-align: right;\">0.0391789</td><td style=\"text-align: right;\"> 0.0445749  </td><td style=\"text-align: right;\">0.0390993</td><td style=\"text-align: right;\">-0.0879633</td><td style=\"text-align: right;\"> 0.00584351</td><td style=\"text-align: right;\">-0.144511 </td><td style=\"text-align: right;\"> 0.0167408 </td><td style=\"text-align: right;\">-0.13431   </td><td style=\"text-align: right;\">-0.0807045</td><td style=\"text-align: right;\"> 0.0671659  </td><td style=\"text-align: right;\"> 0.0427141</td><td style=\"text-align: right;\"> 0.041196  </td><td style=\"text-align: right;\">-0.0704532</td><td style=\"text-align: right;\">0.181694 </td><td style=\"text-align: right;\">0.0836733</td><td style=\"text-align: right;\">-0.0584921</td><td style=\"text-align: right;\">-0.0831199</td><td style=\"text-align: right;\"> 0.0848009 </td><td style=\"text-align: right;\"> 0.169781 </td><td style=\"text-align: right;\">-0.0153495</td><td style=\"text-align: right;\">-0.190452 </td><td style=\"text-align: right;\"> 0.0853043 </td><td style=\"text-align: right;\"> 0.0573439 </td><td style=\"text-align: right;\">-0.0407362  </td><td style=\"text-align: right;\"> 0.107085 </td><td style=\"text-align: right;\">0.0810725</td><td style=\"text-align: right;\">-0.200234  </td><td style=\"text-align: right;\"> 0.179503 </td><td style=\"text-align: right;\">-0.0225273</td><td style=\"text-align: right;\"> 0.0183807 </td><td style=\"text-align: right;\"> 0.0216287 </td><td style=\"text-align: right;\"> 0.0350069 </td><td style=\"text-align: right;\"> 0.0458474 </td><td style=\"text-align: right;\"> 0.136206 </td><td style=\"text-align: right;\"> 0.0118192  </td><td style=\"text-align: right;\">0.0873194</td><td style=\"text-align: right;\"> 0.0177314</td><td style=\"text-align: right;\">-0.0423478 </td><td style=\"text-align: right;\">-0.0389214</td><td style=\"text-align: right;\"> 0.0677268</td><td style=\"text-align: right;\">-0.0431368</td><td style=\"text-align: right;\">-0.00251263</td><td style=\"text-align: right;\"> 0.0645829 </td><td style=\"text-align: right;\">-0.0395505 </td><td style=\"text-align: right;\"> 0.0327319</td><td style=\"text-align: right;\">0.072015 </td><td style=\"text-align: right;\"> 0.0300226</td><td style=\"text-align: right;\"> 0.0785264</td><td style=\"text-align: right;\">-0.0905882 </td><td style=\"text-align: right;\"> 0.0845776 </td><td style=\"text-align: right;\"> 0.127451 </td><td style=\"text-align: right;\">0.0224333 </td><td style=\"text-align: right;\"> 0.050228 </td><td style=\"text-align: right;\"> 0.108584 </td><td style=\"text-align: right;\">-0.0275074 </td><td style=\"text-align: right;\"> 0.215823 </td><td style=\"text-align: right;\"> 0.107455 </td><td style=\"text-align: right;\">-0.0603542</td><td style=\"text-align: right;\"> 0.0351557 </td><td style=\"text-align: right;\">-0.0219788</td><td style=\"text-align: right;\">-0.126746   </td><td style=\"text-align: right;\">-0.0453881 </td><td style=\"text-align: right;\"> 0.0899957</td><td style=\"text-align: right;\">-0.0165066 </td><td style=\"text-align: right;\">0.0925419 </td><td style=\"text-align: right;\">-0.0128623</td><td style=\"text-align: right;\">-0.102198 </td><td style=\"text-align: right;\">-0.00859935</td><td style=\"text-align: right;\">-0.058625  </td><td style=\"text-align: right;\">-0.289004 </td><td style=\"text-align: right;\">-0.0106296 </td><td style=\"text-align: right;\">-0.0464101</td><td style=\"text-align: right;\"> 0.105933  </td><td style=\"text-align: right;\">-0.110108  </td><td style=\"text-align: right;\">-0.0585328</td><td style=\"text-align: right;\">-0.0127461 </td><td style=\"text-align: right;\"> 0.00460146</td><td style=\"text-align: right;\"> 0.00230653</td></tr>\n",
       "<tr><td style=\"text-align: right;\">-0.0201451</td><td style=\"text-align: right;\">-0.132165 </td><td style=\"text-align: right;\"> 0.0379038</td><td style=\"text-align: right;\">0.161137 </td><td style=\"text-align: right;\"> 0.124739  </td><td style=\"text-align: right;\">-0.178314  </td><td style=\"text-align: right;\">-0.0275578</td><td style=\"text-align: right;\"> 0.0744305</td><td style=\"text-align: right;\"> 0.0447734</td><td style=\"text-align: right;\">-0.0425596</td><td style=\"text-align: right;\"> 0.0165299</td><td style=\"text-align: right;\"> 0.145382 </td><td style=\"text-align: right;\">-0.0457867 </td><td style=\"text-align: right;\">-0.0420987 </td><td style=\"text-align: right;\"> 0.137567 </td><td style=\"text-align: right;\">0.119278</td><td style=\"text-align: right;\">-0.11449  </td><td style=\"text-align: right;\">-0.0836703 </td><td style=\"text-align: right;\">0.164161 </td><td style=\"text-align: right;\"> 0.0346721 </td><td style=\"text-align: right;\"> 0.0557758</td><td style=\"text-align: right;\">-0.0353933</td><td style=\"text-align: right;\">0.17646  </td><td style=\"text-align: right;\">-0.0539324  </td><td style=\"text-align: right;\">0.0196024</td><td style=\"text-align: right;\">-0.0559806</td><td style=\"text-align: right;\"> 0.0231409 </td><td style=\"text-align: right;\">-0.108781 </td><td style=\"text-align: right;\">-0.0593631 </td><td style=\"text-align: right;\">-0.0490342 </td><td style=\"text-align: right;\">-0.212415 </td><td style=\"text-align: right;\"> 0.0274417  </td><td style=\"text-align: right;\">-0.046688 </td><td style=\"text-align: right;\">-0.0630046 </td><td style=\"text-align: right;\">-0.0759929</td><td style=\"text-align: right;\">0.15379  </td><td style=\"text-align: right;\">0.0883736</td><td style=\"text-align: right;\">-0.0141757</td><td style=\"text-align: right;\">-0.0614761</td><td style=\"text-align: right;\"> 0.0105543 </td><td style=\"text-align: right;\"> 0.138841 </td><td style=\"text-align: right;\">-0.0907222</td><td style=\"text-align: right;\">-0.149053 </td><td style=\"text-align: right;\"> 0.0686344 </td><td style=\"text-align: right;\">-0.00758567</td><td style=\"text-align: right;\"> 0.000467301</td><td style=\"text-align: right;\"> 0.101195 </td><td style=\"text-align: right;\">0.171427 </td><td style=\"text-align: right;\">-0.17147   </td><td style=\"text-align: right;\"> 0.0747841</td><td style=\"text-align: right;\">-0.0688282</td><td style=\"text-align: right;\"> 0.123618  </td><td style=\"text-align: right;\"> 0.0871568 </td><td style=\"text-align: right;\">-0.0806954 </td><td style=\"text-align: right;\"> 0.0701221 </td><td style=\"text-align: right;\">-0.0372177</td><td style=\"text-align: right;\"> 0.0681081  </td><td style=\"text-align: right;\">0.1486   </td><td style=\"text-align: right;\"> 0.099561 </td><td style=\"text-align: right;\"> 0.0636671 </td><td style=\"text-align: right;\"> 0.0701539</td><td style=\"text-align: right;\"> 0.147183 </td><td style=\"text-align: right;\">-0.0509202</td><td style=\"text-align: right;\">-0.0172091 </td><td style=\"text-align: right;\"> 0.0473874 </td><td style=\"text-align: right;\"> 0.0857132 </td><td style=\"text-align: right;\">-0.047345 </td><td style=\"text-align: right;\">0.137962 </td><td style=\"text-align: right;\">-0.0638686</td><td style=\"text-align: right;\">-0.0367208</td><td style=\"text-align: right;\">-0.145565  </td><td style=\"text-align: right;\"> 0.163988  </td><td style=\"text-align: right;\"> 0.0627691</td><td style=\"text-align: right;\">0.0367048 </td><td style=\"text-align: right;\">-0.0394994</td><td style=\"text-align: right;\"> 0.0967054</td><td style=\"text-align: right;\"> 0.030205  </td><td style=\"text-align: right;\"> 0.157469 </td><td style=\"text-align: right;\"> 0.0740559</td><td style=\"text-align: right;\">-0.0329426</td><td style=\"text-align: right;\"> 0.0543468 </td><td style=\"text-align: right;\"> 0.0171674</td><td style=\"text-align: right;\">-0.0890092  </td><td style=\"text-align: right;\">-0.0360687 </td><td style=\"text-align: right;\"> 0.0424948</td><td style=\"text-align: right;\">-0.0229394 </td><td style=\"text-align: right;\">0.17668   </td><td style=\"text-align: right;\"> 0.067795 </td><td style=\"text-align: right;\">-0.0300711</td><td style=\"text-align: right;\">-0.0254723 </td><td style=\"text-align: right;\">-0.0622449 </td><td style=\"text-align: right;\">-0.242192 </td><td style=\"text-align: right;\">-0.017879  </td><td style=\"text-align: right;\">-0.10616  </td><td style=\"text-align: right;\"> 0.0546131 </td><td style=\"text-align: right;\">-0.161157  </td><td style=\"text-align: right;\">-0.115351 </td><td style=\"text-align: right;\"> 0.123939  </td><td style=\"text-align: right;\">-0.0864101 </td><td style=\"text-align: right;\"> 0.0883715 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">-0.214375 </td><td style=\"text-align: right;\">-0.0369557</td><td style=\"text-align: right;\">-0.101649 </td><td style=\"text-align: right;\">0.219768 </td><td style=\"text-align: right;\"> 0.0442532 </td><td style=\"text-align: right;\">-0.0170526 </td><td style=\"text-align: right;\">-0.11648  </td><td style=\"text-align: right;\"> 0.126972 </td><td style=\"text-align: right;\"> 0.197733 </td><td style=\"text-align: right;\"> 0.101063 </td><td style=\"text-align: right;\"> 0.135763 </td><td style=\"text-align: right;\">-0.0163704</td><td style=\"text-align: right;\"> 0.156413  </td><td style=\"text-align: right;\">-0.111991  </td><td style=\"text-align: right;\">-0.0803099</td><td style=\"text-align: right;\">0.205641</td><td style=\"text-align: right;\">-0.0581775</td><td style=\"text-align: right;\"> 0.131295  </td><td style=\"text-align: right;\">0.15432  </td><td style=\"text-align: right;\"> 0.163607  </td><td style=\"text-align: right;\">-0.046011 </td><td style=\"text-align: right;\">-0.172902 </td><td style=\"text-align: right;\">0.158536 </td><td style=\"text-align: right;\"> 0.0242689  </td><td style=\"text-align: right;\">0.114504 </td><td style=\"text-align: right;\">-0.160656 </td><td style=\"text-align: right;\">-0.143985  </td><td style=\"text-align: right;\">-0.122883 </td><td style=\"text-align: right;\">-0.0575605 </td><td style=\"text-align: right;\">-0.23525   </td><td style=\"text-align: right;\">-0.0999923</td><td style=\"text-align: right;\"> 0.0764702  </td><td style=\"text-align: right;\"> 0.0782552</td><td style=\"text-align: right;\">-0.0861496 </td><td style=\"text-align: right;\"> 0.0464735</td><td style=\"text-align: right;\">0.121648 </td><td style=\"text-align: right;\">0.131931 </td><td style=\"text-align: right;\">-0.136769 </td><td style=\"text-align: right;\">-0.180226 </td><td style=\"text-align: right;\">-0.00352418</td><td style=\"text-align: right;\"> 0.0587089</td><td style=\"text-align: right;\">-0.0295637</td><td style=\"text-align: right;\">-0.185958 </td><td style=\"text-align: right;\"> 0.117099  </td><td style=\"text-align: right;\"> 0.0319455 </td><td style=\"text-align: right;\">-0.0144965  </td><td style=\"text-align: right;\"> 0.0958378</td><td style=\"text-align: right;\">0.167461 </td><td style=\"text-align: right;\"> 0.0451791 </td><td style=\"text-align: right;\">-0.104298 </td><td style=\"text-align: right;\">-0.105662 </td><td style=\"text-align: right;\">-0.0157025 </td><td style=\"text-align: right;\"> 0.133378  </td><td style=\"text-align: right;\">-0.00208287</td><td style=\"text-align: right;\"> 0.0573898 </td><td style=\"text-align: right;\"> 0.148256 </td><td style=\"text-align: right;\"> 0.0580269  </td><td style=\"text-align: right;\">0.126037 </td><td style=\"text-align: right;\">-0.0436015</td><td style=\"text-align: right;\">-0.0891411 </td><td style=\"text-align: right;\">-0.149922 </td><td style=\"text-align: right;\">-0.0155653</td><td style=\"text-align: right;\">-0.0691431</td><td style=\"text-align: right;\"> 0.0369772 </td><td style=\"text-align: right;\"> 0.0261047 </td><td style=\"text-align: right;\"> 0.030653  </td><td style=\"text-align: right;\">-0.0814072</td><td style=\"text-align: right;\">0.0576432</td><td style=\"text-align: right;\"> 0.0169297</td><td style=\"text-align: right;\"> 0.0700941</td><td style=\"text-align: right;\">-0.102137  </td><td style=\"text-align: right;\">-0.00144821</td><td style=\"text-align: right;\"> 0.142381 </td><td style=\"text-align: right;\">0.0538387 </td><td style=\"text-align: right;\"> 0.122036 </td><td style=\"text-align: right;\"> 0.183889 </td><td style=\"text-align: right;\"> 0.103282  </td><td style=\"text-align: right;\"> 0.20281  </td><td style=\"text-align: right;\">-0.0831994</td><td style=\"text-align: right;\"> 0.0495038</td><td style=\"text-align: right;\">-0.0367568 </td><td style=\"text-align: right;\"> 0.0443851</td><td style=\"text-align: right;\"> 0.00556307 </td><td style=\"text-align: right;\">-0.0492791 </td><td style=\"text-align: right;\">-0.125605 </td><td style=\"text-align: right;\"> 0.021378  </td><td style=\"text-align: right;\">0.047709  </td><td style=\"text-align: right;\"> 0.188007 </td><td style=\"text-align: right;\"> 0.0488827</td><td style=\"text-align: right;\">-0.0578316 </td><td style=\"text-align: right;\"> 0.0528324 </td><td style=\"text-align: right;\">-0.109295 </td><td style=\"text-align: right;\"> 0.0497787 </td><td style=\"text-align: right;\">-0.0638945</td><td style=\"text-align: right;\">-0.0914897 </td><td style=\"text-align: right;\">-0.120594  </td><td style=\"text-align: right;\">-0.157838 </td><td style=\"text-align: right;\">-0.114866  </td><td style=\"text-align: right;\">-0.0680224 </td><td style=\"text-align: right;\">-0.0389557 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">-0.0216595</td><td style=\"text-align: right;\">-0.0860846</td><td style=\"text-align: right;\">-0.0521659</td><td style=\"text-align: right;\">0.127222 </td><td style=\"text-align: right;\"> 0.0805164 </td><td style=\"text-align: right;\">-0.0687312 </td><td style=\"text-align: right;\">-0.0416746</td><td style=\"text-align: right;\"> 0.0276679</td><td style=\"text-align: right;\"> 0.0555427</td><td style=\"text-align: right;\"> 0.0161992</td><td style=\"text-align: right;\">-0.1786   </td><td style=\"text-align: right;\"> 0.0442721</td><td style=\"text-align: right;\">-0.00771938</td><td style=\"text-align: right;\">-0.131468  </td><td style=\"text-align: right;\">-0.0724022</td><td style=\"text-align: right;\">0.116649</td><td style=\"text-align: right;\"> 0.0231421</td><td style=\"text-align: right;\"> 0.0466121 </td><td style=\"text-align: right;\">0.0813585</td><td style=\"text-align: right;\"> 0.0264658 </td><td style=\"text-align: right;\">-0.0433392</td><td style=\"text-align: right;\">-0.0666173</td><td style=\"text-align: right;\">0.142332 </td><td style=\"text-align: right;\"> 0.0232238  </td><td style=\"text-align: right;\">0.0645313</td><td style=\"text-align: right;\">-0.166218 </td><td style=\"text-align: right;\">-0.036077  </td><td style=\"text-align: right;\">-0.151196 </td><td style=\"text-align: right;\">-0.00563044</td><td style=\"text-align: right;\"> 0.00734563</td><td style=\"text-align: right;\">-0.110929 </td><td style=\"text-align: right;\">-0.000840302</td><td style=\"text-align: right;\"> 0.0864319</td><td style=\"text-align: right;\">-0.0096056 </td><td style=\"text-align: right;\"> 0.0318864</td><td style=\"text-align: right;\">0.0852141</td><td style=\"text-align: right;\">0.161717 </td><td style=\"text-align: right;\">-0.119659 </td><td style=\"text-align: right;\">-0.0806639</td><td style=\"text-align: right;\">-0.00661783</td><td style=\"text-align: right;\"> 0.181565 </td><td style=\"text-align: right;\">-0.224121 </td><td style=\"text-align: right;\"> 0.018073 </td><td style=\"text-align: right;\"> 0.219789  </td><td style=\"text-align: right;\"> 0.0170883 </td><td style=\"text-align: right;\"> 0.0974341  </td><td style=\"text-align: right;\">-0.0228969</td><td style=\"text-align: right;\">0.0718762</td><td style=\"text-align: right;\">-0.158417  </td><td style=\"text-align: right;\"> 0.051986 </td><td style=\"text-align: right;\"> 0.010496 </td><td style=\"text-align: right;\"> 0.031218  </td><td style=\"text-align: right;\">-0.075082  </td><td style=\"text-align: right;\">-0.0960302 </td><td style=\"text-align: right;\">-0.0845548 </td><td style=\"text-align: right;\"> 0.0788758</td><td style=\"text-align: right;\"> 0.000478667</td><td style=\"text-align: right;\">0.175059 </td><td style=\"text-align: right;\"> 0.0958483</td><td style=\"text-align: right;\"> 0.0243113 </td><td style=\"text-align: right;\">-0.127263 </td><td style=\"text-align: right;\">-0.0199746</td><td style=\"text-align: right;\">-0.0444245</td><td style=\"text-align: right;\"> 0.0452839 </td><td style=\"text-align: right;\"> 0.0381728 </td><td style=\"text-align: right;\">-0.00664754</td><td style=\"text-align: right;\">-0.141949 </td><td style=\"text-align: right;\">0.0411201</td><td style=\"text-align: right;\">-0.0683749</td><td style=\"text-align: right;\">-0.0159984</td><td style=\"text-align: right;\">-0.130445  </td><td style=\"text-align: right;\"> 0.0980892 </td><td style=\"text-align: right;\"> 0.11186  </td><td style=\"text-align: right;\">0.0769736 </td><td style=\"text-align: right;\">-0.0755395</td><td style=\"text-align: right;\">-0.0548621</td><td style=\"text-align: right;\"> 0.130341  </td><td style=\"text-align: right;\"> 0.226099 </td><td style=\"text-align: right;\"> 0.155404 </td><td style=\"text-align: right;\">-0.0411062</td><td style=\"text-align: right;\"> 0.221949  </td><td style=\"text-align: right;\"> 0.0798396</td><td style=\"text-align: right;\">-0.000585934</td><td style=\"text-align: right;\">-0.0451517 </td><td style=\"text-align: right;\"> 0.107744 </td><td style=\"text-align: right;\">-0.0904976 </td><td style=\"text-align: right;\">0.103362  </td><td style=\"text-align: right;\"> 0.096351 </td><td style=\"text-align: right;\">-0.107486 </td><td style=\"text-align: right;\">-0.0772551 </td><td style=\"text-align: right;\">-0.0136998 </td><td style=\"text-align: right;\">-0.0307121</td><td style=\"text-align: right;\"> 0.0458204 </td><td style=\"text-align: right;\">-0.0781022</td><td style=\"text-align: right;\"> 0.0654209 </td><td style=\"text-align: right;\">-0.0509875 </td><td style=\"text-align: right;\">-0.116846 </td><td style=\"text-align: right;\">-0.0907132 </td><td style=\"text-align: right;\">-0.100661  </td><td style=\"text-align: right;\">-0.00077185</td></tr>\n",
       "<tr><td style=\"text-align: right;\">-0.0152875</td><td style=\"text-align: right;\">-0.0715452</td><td style=\"text-align: right;\">-0.0596505</td><td style=\"text-align: right;\">0.0210277</td><td style=\"text-align: right;\">-0.0280086 </td><td style=\"text-align: right;\">-0.00420187</td><td style=\"text-align: right;\">-0.146765 </td><td style=\"text-align: right;\">-0.012545 </td><td style=\"text-align: right;\"> 0.150861 </td><td style=\"text-align: right;\"> 0.0924331</td><td style=\"text-align: right;\"> 0.0398208</td><td style=\"text-align: right;\">-0.0178212</td><td style=\"text-align: right;\"> 0.0357146 </td><td style=\"text-align: right;\">-0.0820587 </td><td style=\"text-align: right;\">-0.0333361</td><td style=\"text-align: right;\">0.128814</td><td style=\"text-align: right;\"> 0.0120944</td><td style=\"text-align: right;\"> 0.0290463 </td><td style=\"text-align: right;\">0.125865 </td><td style=\"text-align: right;\"> 0.0967999 </td><td style=\"text-align: right;\">-0.0355486</td><td style=\"text-align: right;\">-0.0708388</td><td style=\"text-align: right;\">0.123957 </td><td style=\"text-align: right;\">-0.00348934 </td><td style=\"text-align: right;\">0.0897278</td><td style=\"text-align: right;\">-0.108525 </td><td style=\"text-align: right;\">-0.0914897 </td><td style=\"text-align: right;\">-0.279995 </td><td style=\"text-align: right;\">-0.02007   </td><td style=\"text-align: right;\">-0.0919259 </td><td style=\"text-align: right;\">-0.159563 </td><td style=\"text-align: right;\"> 0.0868672  </td><td style=\"text-align: right;\"> 0.0588285</td><td style=\"text-align: right;\"> 0.0171826 </td><td style=\"text-align: right;\"> 0.0185981</td><td style=\"text-align: right;\">0.186392 </td><td style=\"text-align: right;\">0.0420061</td><td style=\"text-align: right;\">-0.23516  </td><td style=\"text-align: right;\">-0.187293 </td><td style=\"text-align: right;\"> 0.0465837 </td><td style=\"text-align: right;\"> 0.10126  </td><td style=\"text-align: right;\">-0.111872 </td><td style=\"text-align: right;\">-0.144822 </td><td style=\"text-align: right;\"> 0.101581  </td><td style=\"text-align: right;\">-0.117462  </td><td style=\"text-align: right;\"> 0.0796994  </td><td style=\"text-align: right;\"> 0.115214 </td><td style=\"text-align: right;\">0.229584 </td><td style=\"text-align: right;\">-0.0713672 </td><td style=\"text-align: right;\">-0.0390147</td><td style=\"text-align: right;\"> 0.0512523</td><td style=\"text-align: right;\"> 0.00191428</td><td style=\"text-align: right;\"> 0.0536491 </td><td style=\"text-align: right;\">-0.0486795 </td><td style=\"text-align: right;\"> 0.0666075 </td><td style=\"text-align: right;\"> 0.102646 </td><td style=\"text-align: right;\"> 0.00214635 </td><td style=\"text-align: right;\">0.138902 </td><td style=\"text-align: right;\"> 0.0214773</td><td style=\"text-align: right;\"> 0.00136467</td><td style=\"text-align: right;\">-0.061166 </td><td style=\"text-align: right;\"> 0.0963146</td><td style=\"text-align: right;\">-0.0312219</td><td style=\"text-align: right;\">-0.0377728 </td><td style=\"text-align: right;\"> 0.0110977 </td><td style=\"text-align: right;\"> 0.0267467 </td><td style=\"text-align: right;\">-0.0658187</td><td style=\"text-align: right;\">0.0593206</td><td style=\"text-align: right;\">-0.0343376</td><td style=\"text-align: right;\"> 0.135023 </td><td style=\"text-align: right;\">-0.0621164 </td><td style=\"text-align: right;\"> 0.106411  </td><td style=\"text-align: right;\"> 0.0584986</td><td style=\"text-align: right;\">0.046391  </td><td style=\"text-align: right;\"> 0.0460339</td><td style=\"text-align: right;\"> 0.0906557</td><td style=\"text-align: right;\"> 0.00114776</td><td style=\"text-align: right;\"> 0.158475 </td><td style=\"text-align: right;\"> 0.0708439</td><td style=\"text-align: right;\">-0.0360095</td><td style=\"text-align: right;\">-0.0325766 </td><td style=\"text-align: right;\">-0.0717995</td><td style=\"text-align: right;\">-0.0448237  </td><td style=\"text-align: right;\">-0.0939923 </td><td style=\"text-align: right;\">-0.0255299</td><td style=\"text-align: right;\">-0.0232647 </td><td style=\"text-align: right;\">0.0337385 </td><td style=\"text-align: right;\"> 0.104819 </td><td style=\"text-align: right;\">-0.0848314</td><td style=\"text-align: right;\">-0.132427  </td><td style=\"text-align: right;\"> 0.0592799 </td><td style=\"text-align: right;\">-0.0278515</td><td style=\"text-align: right;\">-0.00470951</td><td style=\"text-align: right;\">-0.0997909</td><td style=\"text-align: right;\"> 0.0221211 </td><td style=\"text-align: right;\">-0.114544  </td><td style=\"text-align: right;\">-0.187636 </td><td style=\"text-align: right;\">-0.094655  </td><td style=\"text-align: right;\"> 0.00655682</td><td style=\"text-align: right;\">-0.0753624 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">-0.0444855</td><td style=\"text-align: right;\">-0.136749 </td><td style=\"text-align: right;\">-0.064766 </td><td style=\"text-align: right;\">0.0865771</td><td style=\"text-align: right;\"> 0.0429173 </td><td style=\"text-align: right;\">-0.0376827 </td><td style=\"text-align: right;\">-0.0927733</td><td style=\"text-align: right;\"> 0.141897 </td><td style=\"text-align: right;\"> 0.157546 </td><td style=\"text-align: right;\"> 0.0613846</td><td style=\"text-align: right;\"> 0.063049 </td><td style=\"text-align: right;\"> 0.0612632</td><td style=\"text-align: right;\">-0.0817861 </td><td style=\"text-align: right;\"> 0.035267  </td><td style=\"text-align: right;\"> 0.0314649</td><td style=\"text-align: right;\">0.180172</td><td style=\"text-align: right;\">-0.035238 </td><td style=\"text-align: right;\"> 0.145447  </td><td style=\"text-align: right;\">0.112999 </td><td style=\"text-align: right;\"> 0.0847628 </td><td style=\"text-align: right;\">-0.0511798</td><td style=\"text-align: right;\">-0.169082 </td><td style=\"text-align: right;\">0.0878044</td><td style=\"text-align: right;\"> 0.0226005  </td><td style=\"text-align: right;\">0.130172 </td><td style=\"text-align: right;\">-0.110729 </td><td style=\"text-align: right;\">-0.122074  </td><td style=\"text-align: right;\">-0.0896175</td><td style=\"text-align: right;\"> 0.00558331</td><td style=\"text-align: right;\">-0.0909231 </td><td style=\"text-align: right;\">-0.151759 </td><td style=\"text-align: right;\"> 0.0922034  </td><td style=\"text-align: right;\"> 0.027838 </td><td style=\"text-align: right;\">-0.0651061 </td><td style=\"text-align: right;\">-0.0216926</td><td style=\"text-align: right;\">0.109536 </td><td style=\"text-align: right;\">0.100399 </td><td style=\"text-align: right;\">-0.211377 </td><td style=\"text-align: right;\">-0.122195 </td><td style=\"text-align: right;\"> 0.0359905 </td><td style=\"text-align: right;\"> 0.113204 </td><td style=\"text-align: right;\"> 0.024932 </td><td style=\"text-align: right;\">-0.156284 </td><td style=\"text-align: right;\"> 0.085134  </td><td style=\"text-align: right;\"> 0.0364976 </td><td style=\"text-align: right;\"> 0.0174787  </td><td style=\"text-align: right;\"> 0.0664203</td><td style=\"text-align: right;\">0.150909 </td><td style=\"text-align: right;\">-0.0884863 </td><td style=\"text-align: right;\"> 0.0497732</td><td style=\"text-align: right;\">-0.0815174</td><td style=\"text-align: right;\"> 0.0573616 </td><td style=\"text-align: right;\">-0.0223498 </td><td style=\"text-align: right;\"> 0.00331112</td><td style=\"text-align: right;\"> 0.118039  </td><td style=\"text-align: right;\"> 0.0732774</td><td style=\"text-align: right;\"> 0.0301757  </td><td style=\"text-align: right;\">0.244341 </td><td style=\"text-align: right;\"> 0.066726 </td><td style=\"text-align: right;\">-0.0630507 </td><td style=\"text-align: right;\">-0.0542544</td><td style=\"text-align: right;\"> 0.0753806</td><td style=\"text-align: right;\">-0.0143171</td><td style=\"text-align: right;\">-0.0220478 </td><td style=\"text-align: right;\"> 0.00918858</td><td style=\"text-align: right;\"> 0.00505272</td><td style=\"text-align: right;\">-0.0906953</td><td style=\"text-align: right;\">0.120604 </td><td style=\"text-align: right;\"> 0.024875 </td><td style=\"text-align: right;\"> 0.0801327</td><td style=\"text-align: right;\"> 0.00900708</td><td style=\"text-align: right;\"> 0.106778  </td><td style=\"text-align: right;\"> 0.0905721</td><td style=\"text-align: right;\">0.0544582 </td><td style=\"text-align: right;\"> 0.074747 </td><td style=\"text-align: right;\"> 0.0795821</td><td style=\"text-align: right;\"> 0.00600424</td><td style=\"text-align: right;\"> 0.113041 </td><td style=\"text-align: right;\"> 0.0149877</td><td style=\"text-align: right;\">-0.13618  </td><td style=\"text-align: right;\"> 0.00315993</td><td style=\"text-align: right;\">-0.0886219</td><td style=\"text-align: right;\">-0.0907169  </td><td style=\"text-align: right;\"> 0.029071  </td><td style=\"text-align: right;\">-0.0397595</td><td style=\"text-align: right;\">-0.0318108 </td><td style=\"text-align: right;\">0.139571  </td><td style=\"text-align: right;\"> 0.137431 </td><td style=\"text-align: right;\">-0.0147875</td><td style=\"text-align: right;\"> 0.0184729 </td><td style=\"text-align: right;\"> 0.0470235 </td><td style=\"text-align: right;\">-0.0800962</td><td style=\"text-align: right;\"> 0.104865  </td><td style=\"text-align: right;\">-0.0679469</td><td style=\"text-align: right;\"> 0.062309  </td><td style=\"text-align: right;\">-0.204208  </td><td style=\"text-align: right;\">-0.0638533</td><td style=\"text-align: right;\">-0.00313411</td><td style=\"text-align: right;\"> 0.0227715 </td><td style=\"text-align: right;\">-0.0697703 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">-0.151232 </td><td style=\"text-align: right;\">-0.128398 </td><td style=\"text-align: right;\">-0.0458661</td><td style=\"text-align: right;\">0.209259 </td><td style=\"text-align: right;\"> 0.121817  </td><td style=\"text-align: right;\"> 0.0958705 </td><td style=\"text-align: right;\">-0.552895 </td><td style=\"text-align: right;\"> 0.167645 </td><td style=\"text-align: right;\"> 0.0418051</td><td style=\"text-align: right;\"> 0.121377 </td><td style=\"text-align: right;\"> 0.0955454</td><td style=\"text-align: right;\">-0.211727 </td><td style=\"text-align: right;\">-0.0103224 </td><td style=\"text-align: right;\"> 0.0164757 </td><td style=\"text-align: right;\">-0.0475631</td><td style=\"text-align: right;\">0.262533</td><td style=\"text-align: right;\">-0.156327 </td><td style=\"text-align: right;\"> 0.377485  </td><td style=\"text-align: right;\">0.246717 </td><td style=\"text-align: right;\">-0.0135573 </td><td style=\"text-align: right;\">-0.177406 </td><td style=\"text-align: right;\">-0.183147 </td><td style=\"text-align: right;\">0.180468 </td><td style=\"text-align: right;\">-0.000253381</td><td style=\"text-align: right;\">0.265976 </td><td style=\"text-align: right;\">-0.160893 </td><td style=\"text-align: right;\">-0.200018  </td><td style=\"text-align: right;\">-0.261309 </td><td style=\"text-align: right;\"> 0.0500338 </td><td style=\"text-align: right;\">-0.0399509 </td><td style=\"text-align: right;\">-0.0765872</td><td style=\"text-align: right;\">-0.0506921  </td><td style=\"text-align: right;\"> 0.169115 </td><td style=\"text-align: right;\"> 0.00725004</td><td style=\"text-align: right;\">-0.297368 </td><td style=\"text-align: right;\">0.301351 </td><td style=\"text-align: right;\">0.299986 </td><td style=\"text-align: right;\">-0.455418 </td><td style=\"text-align: right;\">-0.179032 </td><td style=\"text-align: right;\">-0.0106398 </td><td style=\"text-align: right;\">-0.0170218</td><td style=\"text-align: right;\"> 0.0471121</td><td style=\"text-align: right;\">-0.212905 </td><td style=\"text-align: right;\">-0.0643439 </td><td style=\"text-align: right;\">-0.220091  </td><td style=\"text-align: right;\">-0.0173816  </td><td style=\"text-align: right;\"> 0.156557 </td><td style=\"text-align: right;\">0.343897 </td><td style=\"text-align: right;\"> 0.114946  </td><td style=\"text-align: right;\">-0.138344 </td><td style=\"text-align: right;\">-0.237115 </td><td style=\"text-align: right;\">-0.0706474 </td><td style=\"text-align: right;\">-0.00870185</td><td style=\"text-align: right;\"> 0.00491258</td><td style=\"text-align: right;\">-0.00255729</td><td style=\"text-align: right;\">-0.0589396</td><td style=\"text-align: right;\"> 0.207085   </td><td style=\"text-align: right;\">0.0937893</td><td style=\"text-align: right;\"> 0.104862 </td><td style=\"text-align: right;\">-0.105031  </td><td style=\"text-align: right;\">-0.0036231</td><td style=\"text-align: right;\">-0.0776935</td><td style=\"text-align: right;\"> 0.259848 </td><td style=\"text-align: right;\"> 0.217472  </td><td style=\"text-align: right;\">-0.194927  </td><td style=\"text-align: right;\"> 0.0453228 </td><td style=\"text-align: right;\">-0.13975  </td><td style=\"text-align: right;\">0.115349 </td><td style=\"text-align: right;\"> 0.133061 </td><td style=\"text-align: right;\">-0.05156  </td><td style=\"text-align: right;\"> 0.247622  </td><td style=\"text-align: right;\">-0.159117  </td><td style=\"text-align: right;\">-0.0349687</td><td style=\"text-align: right;\">0.00249731</td><td style=\"text-align: right;\">-0.134824 </td><td style=\"text-align: right;\"> 0.100211 </td><td style=\"text-align: right;\"> 0.0741915 </td><td style=\"text-align: right;\">-0.0620691</td><td style=\"text-align: right;\"> 0.182817 </td><td style=\"text-align: right;\"> 0.101812 </td><td style=\"text-align: right;\"> 0.136909  </td><td style=\"text-align: right;\">-0.0102396</td><td style=\"text-align: right;\">-0.23326    </td><td style=\"text-align: right;\"> 0.00444215</td><td style=\"text-align: right;\"> 0.153172 </td><td style=\"text-align: right;\"> 0.0549877 </td><td style=\"text-align: right;\">0.114905  </td><td style=\"text-align: right;\"> 0.0954119</td><td style=\"text-align: right;\">-0.103502 </td><td style=\"text-align: right;\">-0.0435195 </td><td style=\"text-align: right;\">-0.245606  </td><td style=\"text-align: right;\">-0.107886 </td><td style=\"text-align: right;\">-0.0321344 </td><td style=\"text-align: right;\"> 0.022238 </td><td style=\"text-align: right;\">-0.0756358 </td><td style=\"text-align: right;\"> 0.0391836 </td><td style=\"text-align: right;\">-0.155411 </td><td style=\"text-align: right;\"> 0.079341  </td><td style=\"text-align: right;\"> 0.330519  </td><td style=\"text-align: right;\">-0.215143  </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = reviews['Text'][9,:]\n",
    "row.set_names(['Review'])\n",
    "print(row)\n",
    "w2v_model.transform(words, aggregate_method=\"AVERAGE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>ProductId  </th><th>UserId        </th><th>Summary                               </th><th style=\"text-align: right;\">  Score</th><th style=\"text-align: right;\">  HelpfulnessDenominator</th><th style=\"text-align: right;\">    Id</th><th>ProfileName                                     </th><th style=\"text-align: right;\">  HelpfulnessNumerator</th><th style=\"text-align: right;\">       Time</th><th>Text                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </th><th style=\"text-align: right;\">  PositiveReview</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>B00141QYSQ </td><td>A1YS02UZZGRDCT</td><td>Do Not Buy                            </td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">                       2</td><td style=\"text-align: right;\"> 41471</td><td>Evan Eberhardt                                  </td><td style=\"text-align: right;\">                     2</td><td style=\"text-align: right;\">1.34836e+09</td><td>These are made in China (do not buy ANY pet food from China).  Dogswell has been using propylene glycol to soften their treats (what are they thinkng?).  Do not purchase or support this company in any way until they clean up their act.  And for whatever reason Amazon doesn&#x27;t allow returns of this item, so I had to toss mine out.  Bad business all around on this one.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            </td><td style=\"text-align: right;\">               0</td></tr>\n",
       "<tr><td>B0089SPEO2 </td><td>A3JOYNYL458QHP</td><td>Less lemon and less zing              </td><td style=\"text-align: right;\">      3</td><td style=\"text-align: right;\">                       0</td><td style=\"text-align: right;\"> 28582</td><td>coleridge                                       </td><td style=\"text-align: right;\">                     0</td><td style=\"text-align: right;\">1.32391e+09</td><td>Everything is ok, except it just isn&#x27;t as good as it is in the bags.  Just considerably more bland -- less lemon and less zing.  Boring.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </td><td style=\"text-align: right;\">               0</td></tr>\n",
       "<tr><td>B001PMCDK2 </td><td>A14TTMM0Z03Y2W</td><td>my cat goes crazy for these!          </td><td style=\"text-align: right;\">      5</td><td style=\"text-align: right;\">                       0</td><td style=\"text-align: right;\">389965</td><td>Lindsay S. Bradford                             </td><td style=\"text-align: right;\">                     0</td><td style=\"text-align: right;\">1.3106e+09 </td><td>Best cat treat ever. There isn&#x27;t anything comparable to the love my cat has for these treats, he snubs away any other kind now.&lt;br /&gt;I know he likes to manipulate me with his cattiness but these treats are my way of manipulating him to come sit on my lap and have some chill time. :)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 </td><td style=\"text-align: right;\">               1</td></tr>\n",
       "<tr><td>B002Q8JOSI </td><td>A17UQD2RSSQH5X</td><td>My dogs tell me these treats are YUMMY</td><td style=\"text-align: right;\">      5</td><td style=\"text-align: right;\">                       1</td><td style=\"text-align: right;\">212536</td><td>in the dark                                     </td><td style=\"text-align: right;\">                     1</td><td style=\"text-align: right;\">1.31613e+09</td><td>My two Corgis were thoroughly spoiled by my late husband (I spent a year and a half dieting them down a combined total of 25 pounds!)&lt;br /&gt;&lt;br /&gt;They are accustomed to the finest of fare, and they absolutely love the Wellness brand of treats.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          </td><td style=\"text-align: right;\">               1</td></tr>\n",
       "<tr><td>B00176G870 </td><td>A2F2MZW8EOGH5J</td><td>Yummy to the tummy                    </td><td style=\"text-align: right;\">      5</td><td style=\"text-align: right;\">                       0</td><td style=\"text-align: right;\">115971</td><td>daemoncycler &quot;When you arrive at a fork in th...</td><td style=\"text-align: right;\">                     0</td><td style=\"text-align: right;\">1.33479e+09</td><td>We used to have drive down to the specialty pet food store for this product.  So glad we discovered Amazon.  As far as I can tell it is no more expensive &amp; in some cases less - Prime membership is awesome.  Loving Pets treats are some of the best according to my dog.  They do not develop that nasty smell like some dog treats do.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  </td><td style=\"text-align: right;\">               1</td></tr>\n",
       "<tr><td>B001CHFUGY </td><td>A2M8VROSDPU4JT</td><td>Very good coffee                      </td><td style=\"text-align: right;\">      5</td><td style=\"text-align: right;\">                       1</td><td style=\"text-align: right;\">434484</td><td>Officefan &quot;Officefankt&quot;                         </td><td style=\"text-align: right;\">                     1</td><td style=\"text-align: right;\">1.27725e+09</td><td>I really liked this coffee, it was just as good as everyone claimed it was.  Strong, bold and flavorful!  I would recommend!                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                </td><td style=\"text-align: right;\">               1</td></tr>\n",
       "<tr><td>B0041CIR62 </td><td>A16I6WJUEBJ1C3</td><td>okay but not as healthy as it appears </td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">                       1</td><td style=\"text-align: right;\">138997</td><td>doctorsirena &quot;doctorsirena&quot;                     </td><td style=\"text-align: right;\">                     1</td><td style=\"text-align: right;\">1.34369e+09</td><td>I am always looking for healthier, whole grain versions of foods I enjoy.  Unfortunately, these Peacock brand noodles are yet another food masquerading as healthy.  The product title in big letters on the front says &quot;Brown Rice Vermicelli&quot;, making the consumer think &quot;this is made with brown rice, so it should be a healthy choice&quot;.  But the first indication that it is not is when looking at the fiber content on the nutrition facts - only 0.6g per 2oz serving.  Then onto the ingredients list to see why so low... contains brown rice, sago starch and water.  The sago starch comes from palms and must not have much (if any) fiber.&lt;br /&gt;&lt;br /&gt;The Annie Chun&#x27;s Maifun Brown Rice Noodles (sold on Amazon and in my local healthy grocer) has become one of my staples and is my frame of reference when comparing to the Peacock brand.  The Annie Chun&#x27;s product is made with 100% whole grain, with ingredients brown rice flour and water.  Per 2oz serving, it has 4g fiber and pretty much the same calories and other nutrients as the Peacock brand.&lt;br /&gt;&lt;br /&gt;If you do try this Peacock brand noodles and have not used rice noodles before, you will need to seek guidance elsewhere on preparation.  As others have pointed out, the Peacock package gives almost no directions on how to prepare the product, aside from a brief mention in the recipes (in the header text it does say that they are &quot;easy-to-cook&quot; but does not say how).  It also contains a very strange recipe for rice noodles: Aglio Olio style - this is an Italian recipe for noodles with olive oil/garlic/sprinkled with grated cheese that I think would not be very tasty.  The second recipe appears to be for a soup with veggie strips.  Neither recipe gives amounts or much direction.  In comparison, the Annie Chun&#x27;s package gives clear, specific directions on rice noodle preparation and two recipes.&lt;br /&gt;&lt;br /&gt;I use rice noodles = maifun = rice sticks = sometimes called vermicelli for making the Vietnamese salad &quot;bun tofu&quot;, to serve with stir-fried veggies or in lettuce rolls.  They can also be used in spring rolls/egg rolls.  When cooking with thin rice noodles, be careful not to oversoak/overcook/overmix or they tend to disintegrate.  Asian rice noodle vermicelli (maifun) are not the same as Italian vermicelli and are not readily interchangeable.  If making an Italian recipe, the best results would be expected from Italian pasta and not maifun.&lt;br /&gt;&lt;br /&gt;A few final notes...  Both Peacock and Annie Chun&#x27;s brown rice noodles are gluten free.  The Peacock is made in Singapore and the Annie Chun&#x27;s in Thailand.  The Peacock noodles do taste fine (kind of bland), but so do the Annie Chun&#x27;s.  At this time, they are both approximately the same price.  Peacock come in an plastic bag with some noodle crushage upon shipping; Annie Chun&#x27;s are perfect upon removal from their cellophane bag in a box.  Overall, I highly recommend the Annie Chun&#x27;s Maifun as a healthier option over the Peacock brand.  On a related note, the Annie Chun&#x27;s soba and brown rice pad thai noodles are also excellent.&lt;br /&gt;&lt;br /&gt;Rating for this product: 2.5 stars rounded down to 2 stars.</td><td style=\"text-align: right;\">               0</td></tr>\n",
       "<tr><td>B001R3BQFW </td><td>AM50E42AFUVNL </td><td>Taste great.                          </td><td style=\"text-align: right;\">      5</td><td style=\"text-align: right;\">                       0</td><td style=\"text-align: right;\">126555</td><td>T. Higley &quot;Tina&quot;                                </td><td style=\"text-align: right;\">                     0</td><td style=\"text-align: right;\">1.32356e+09</td><td>I have tried many different drink mix, this is the best tasting by far. It does not have the after taste of the sweetener and I really like it, it is pretty strong, so I use a big water bottle (20 oz) for one tube, it still a little stronger than I like, but it is just my taste.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     </td><td style=\"text-align: right;\">               1</td></tr>\n",
       "<tr><td>B005HGAV8I </td><td>A2I5KDNOESGJ1H</td><td>variety galore                        </td><td style=\"text-align: right;\">      5</td><td style=\"text-align: right;\">                       1</td><td style=\"text-align: right;\">438837</td><td>TJ                                              </td><td style=\"text-align: right;\">                     1</td><td style=\"text-align: right;\">1.33402e+09</td><td>This is my favorite item to order for my Keurig. There are so many flavors, my finicky palate never gets bored!  The only downside is there are probably 5-6 decaf varieties.  I don&#x27;t drink decaf (I REQUIRE copious amounts of caffeine), so they sit on the shelf...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     </td><td style=\"text-align: right;\">               1</td></tr>\n",
       "<tr><td>B000GFYRHQ </td><td>A3A7YUR6FS6ZCI</td><td>Bigelow Earl Grey Green Tea           </td><td style=\"text-align: right;\">      5</td><td style=\"text-align: right;\">                       0</td><td style=\"text-align: right;\">245379</td><td>Tea Lover                                       </td><td style=\"text-align: right;\">                     0</td><td style=\"text-align: right;\">1.17841e+09</td><td>Tastes like Earl Grey, but it&#x27;s green tea so it&#x27;s healthier.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                </td><td style=\"text-align: right;\">               1</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>C1        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>everything</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[32,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  C1</th><th style=\"text-align: right;\">  C2</th><th style=\"text-align: right;\">  C3</th><th style=\"text-align: right;\">  C4</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">   2</td><td style=\"text-align: right;\">   4</td><td style=\"text-align: right;\">   2</td><td style=\"text-align: right;\">   2</td></tr>\n",
       "<tr><td style=\"text-align: right;\">   2</td><td style=\"text-align: right;\">   2</td><td style=\"text-align: right;\">   2</td><td style=\"text-align: right;\">   2</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from h2o.assembly import *\n",
    "from h2o.transforms.preprocessing import *\n",
    "\n",
    "python_list1 = [[4,4,4,4],[4,4,4,4]]\n",
    "python_list2 = [[2,1,2,2], [2,2,2,2]]\n",
    "\n",
    "frame1 = h2o.H2OFrame(python_obj=python_list1)\n",
    "frame2 = h2o.H2OFrame(python_obj=python_list2)\n",
    "\n",
    "# assembly = H2OAssembly(steps=[]\n",
    "\n",
    "H2OAssembly.divide(frame1, frame2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class H2OWord2vecEstimator in module h2o.estimators.word2vec:\n",
      "\n",
      "class H2OWord2vecEstimator(h2o.estimators.estimator_base.H2OEstimator)\n",
      " |  H2OWord2vecEstimator(**kwargs)\n",
      " |  \n",
      " |  Word2Vec\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      H2OWord2vecEstimator\n",
      " |      h2o.estimators.estimator_base.H2OEstimator\n",
      " |      h2o.model.model_base.ModelBase\n",
      " |      h2o.model.model_base.ModelBase\n",
      " |      h2o.base.Keyed\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, **kwargs)\n",
      " |      Construct a new model instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  from_external(external=<class 'h2o.frame.H2OFrame'>)\n",
      " |      Creates new H2OWord2vecEstimator based on an external model.\n",
      " |      \n",
      " |      :param external: H2OFrame with an external model\n",
      " |      :return: H2OWord2vecEstimator instance representing the external model\n",
      " |      \n",
      " |      :examples:\n",
      " |      \n",
      " |      >>> words = h2o.create_frame(rows=10, cols=1,\n",
      " |      ...                          string_fraction=1.0,\n",
      " |      ...                          missing_fraction=0.0)\n",
      " |      >>> embeddings = h2o.create_frame(rows=10, cols=100,\n",
      " |      ...                               real_fraction=1.0,\n",
      " |      ...                               missing_fraction=0.0)\n",
      " |      >>> word_embeddings = words.cbind(embeddings)\n",
      " |      >>> w2v_model = H2OWord2vecEstimator.from_external(external=word_embeddings)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  epochs\n",
      " |      Number of training iterations to run\n",
      " |      \n",
      " |      Type: ``int``  (default: ``5``).\n",
      " |      \n",
      " |      :examples:\n",
      " |      \n",
      " |      >>> job_titles = h2o.import_file((\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/craigslistJobTitles.csv\"), \n",
      " |      ...                               col_names = [\"category\", \"jobtitle\"], \n",
      " |      ...                               col_types = [\"string\", \"string\"], \n",
      " |      ...                               header = 1)\n",
      " |      >>> words = job_titles.tokenize(\" \")\n",
      " |      >>> w2v_model = H2OWord2vecEstimator(sent_sample_rate = 0.0, epochs = 10)\n",
      " |      >>> w2v_model.train(training_frame=words)\n",
      " |      >>> synonyms = w2v_model.find_synonyms(\"teacher\", count = 5)\n",
      " |      >>> print(synonyms)\n",
      " |      >>>\n",
      " |      >>> w2v_model2 = H2OWord2vecEstimator(sent_sample_rate = 0.0, epochs = 1)\n",
      " |      >>> w2v_model2.train(training_frame=words)\n",
      " |      >>> synonyms2 = w2v_model2.find_synonyms(\"teacher\", 3)\n",
      " |      >>> print(synonyms2)\n",
      " |  \n",
      " |  export_checkpoints_dir\n",
      " |      Automatically export generated models to this directory.\n",
      " |      \n",
      " |      Type: ``str``.\n",
      " |      \n",
      " |      :examples:\n",
      " |      \n",
      " |      >>> import tempfile\n",
      " |      >>> from os import listdir\n",
      " |      >>> job_titles = h2o.import_file((\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/craigslistJobTitles.csv\"), \n",
      " |      ...                               col_names = [\"category\", \"jobtitle\"], \n",
      " |      ...                               col_types = [\"string\", \"string\"], \n",
      " |      ...                               header = 1)\n",
      " |      >>> checkpoints_dir = tempfile.mkdtemp()\n",
      " |      >>> words = job_titles.tokenize(\" \")\n",
      " |      >>> w2v_model = H2OWord2vecEstimator(epochs=1,\n",
      " |      ...                                  max_runtime_secs=10,\n",
      " |      ...                                  export_checkpoints_dir=checkpoints_dir)\n",
      " |      >>> w2v_model.train(training_frame=words)\n",
      " |      >>> len(listdir(checkpoints_dir))\n",
      " |  \n",
      " |  init_learning_rate\n",
      " |      Set the starting learning rate\n",
      " |      \n",
      " |      Type: ``float``  (default: ``0.025``).\n",
      " |      \n",
      " |      :examples:\n",
      " |      \n",
      " |      >>> job_titles = h2o.import_file((\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/craigslistJobTitles.csv\"), \n",
      " |      ...                               col_names = [\"category\", \"jobtitle\"], \n",
      " |      ...                               col_types = [\"string\", \"string\"], \n",
      " |      ...                               header = 1)\n",
      " |      >>> words = job_titles.tokenize(\" \")\n",
      " |      >>> w2v_model = H2OWord2vecEstimator(epochs=3, init_learning_rate=0.05)\n",
      " |      >>> w2v_model.train(training_frame=words)\n",
      " |      >>> synonyms = w2v_model.find_synonyms(\"assistant\", 3)\n",
      " |      >>> print(synonyms)\n",
      " |  \n",
      " |  max_runtime_secs\n",
      " |      Maximum allowed runtime in seconds for model training. Use 0 to disable.\n",
      " |      \n",
      " |      Type: ``float``  (default: ``0``).\n",
      " |      \n",
      " |      :examples:\n",
      " |      \n",
      " |      >>> job_titles = h2o.import_file((\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/craigslistJobTitles.csv\"), \n",
      " |      ...                               col_names = [\"category\", \"jobtitle\"], \n",
      " |      ...                               col_types = [\"string\", \"string\"], \n",
      " |      ...                               header = 1)\n",
      " |      >>> words = job_titles.tokenize(\" \")\n",
      " |      >>> w2v_model = H2OWord2vecEstimator(epochs=1, max_runtime_secs=10)\n",
      " |      >>> w2v_model.train(training_frame=words)\n",
      " |      >>> synonyms = w2v_model.find_synonyms(\"tutor\", 3)\n",
      " |      >>> print(synonyms)\n",
      " |  \n",
      " |  min_word_freq\n",
      " |      This will discard words that appear less than <int> times\n",
      " |      \n",
      " |      Type: ``int``  (default: ``5``).\n",
      " |      \n",
      " |      :examples:\n",
      " |      \n",
      " |      >>> job_titles = h2o.import_file((\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/craigslistJobTitles.csv\"), \n",
      " |      ...                               col_names = [\"category\", \"jobtitle\"], \n",
      " |      ...                               col_types = [\"string\", \"string\"], \n",
      " |      ...                               header = 1)\n",
      " |      >>> words = job_titles.tokenize(\" \")\n",
      " |      >>> w2v_model = H2OWord2vecEstimator(epochs=1, min_word_freq=4)\n",
      " |      >>> w2v_model.train(training_frame=words)\n",
      " |      >>> synonyms = w2v_model.find_synonyms(\"teacher\", 3)\n",
      " |      >>> print(synonyms)\n",
      " |  \n",
      " |  norm_model\n",
      " |      Use Hierarchical Softmax\n",
      " |      \n",
      " |      One of: ``\"hsm\"``  (default: ``\"hsm\"``).\n",
      " |      \n",
      " |      :examples:\n",
      " |      \n",
      " |      >>> job_titles = h2o.import_file((\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/craigslistJobTitles.csv\"), \n",
      " |      ...                               col_names = [\"category\", \"jobtitle\"], \n",
      " |      ...                               col_types = [\"string\", \"string\"], \n",
      " |      ...                               header = 1)\n",
      " |      >>> words = job_titles.tokenize(\" \")\n",
      " |      >>> w2v_model = H2OWord2vecEstimator(epochs=1, norm_model=\"hsm\")\n",
      " |      >>> w2v_model.train(training_frame=words)\n",
      " |      >>> synonyms = w2v_model.find_synonyms(\"teacher\", 3)\n",
      " |      >>> print(synonyms)\n",
      " |  \n",
      " |  pre_trained\n",
      " |      Id of a data frame that contains a pre-trained (external) word2vec model\n",
      " |      \n",
      " |      Type: ``H2OFrame``.\n",
      " |      \n",
      " |      :examples:\n",
      " |      \n",
      " |      >>> words = h2o.create_frame(rows=1000,cols=1,\n",
      " |      ...                          string_fraction=1.0,\n",
      " |      ...                          missing_fraction=0.0)\n",
      " |      >>> embeddings = h2o.create_frame(rows=1000,cols=100,\n",
      " |      ...                               real_fraction=1.0,\n",
      " |      ...                               missing_fraction=0.0)\n",
      " |      >>> word_embeddings = words.cbind(embeddings)\n",
      " |      >>> w2v_model = H2OWord2vecEstimator(pre_trained=word_embeddings)\n",
      " |      >>> w2v_model.train(training_frame=word_embeddings)\n",
      " |      >>> model_id = w2v_model.model_id\n",
      " |      >>> model = h2o.get_model(model_id)\n",
      " |  \n",
      " |  sent_sample_rate\n",
      " |      Set threshold for occurrence of words. Those that appear with higher frequency in the training data\n",
      " |      will be randomly down-sampled; useful range is (0, 1e-5)\n",
      " |      \n",
      " |      Type: ``float``  (default: ``0.001``).\n",
      " |      \n",
      " |      :examples:\n",
      " |      \n",
      " |      >>> job_titles = h2o.import_file((\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/craigslistJobTitles.csv\"), \n",
      " |      ...                               col_names = [\"category\", \"jobtitle\"], \n",
      " |      ...                               col_types = [\"string\", \"string\"], \n",
      " |      ...                               header = 1)\n",
      " |      >>> words = job_titles.tokenize(\" \")\n",
      " |      >>> w2v_model = H2OWord2vecEstimator(epochs=1, sent_sample_rate=0.01)\n",
      " |      >>> w2v_model.train(training_frame=words)\n",
      " |      >>> synonyms = w2v_model.find_synonyms(\"teacher\", 3)\n",
      " |      >>> print(synonyms)\n",
      " |  \n",
      " |  training_frame\n",
      " |      Id of the training data frame.\n",
      " |      \n",
      " |      Type: ``H2OFrame``.\n",
      " |      \n",
      " |      :examples:\n",
      " |      \n",
      " |      >>> job_titles = h2o.import_file((\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/craigslistJobTitles.csv\"), \n",
      " |      ...                               col_names = [\"category\", \"jobtitle\"], \n",
      " |      ...                               col_types = [\"string\", \"string\"], \n",
      " |      ...                               header = 1)\n",
      " |      >>> words = job_titles.tokenize(\" \")\n",
      " |      >>> w2v_model = H2OWord2vecEstimator()\n",
      " |      >>> w2v_model.train(training_frame=words)\n",
      " |      >>> synonyms = w2v_model.find_synonyms(\"tutor\", 3)\n",
      " |      >>> print(synonyms)\n",
      " |  \n",
      " |  vec_size\n",
      " |      Set size of word vectors\n",
      " |      \n",
      " |      Type: ``int``  (default: ``100``).\n",
      " |      \n",
      " |      :examples:\n",
      " |      \n",
      " |      >>> job_titles = h2o.import_file((\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/craigslistJobTitles.csv\"), \n",
      " |      ...                               col_names = [\"category\", \"jobtitle\"], \n",
      " |      ...                               col_types = [\"string\", \"string\"], \n",
      " |      ...                               header = 1)\n",
      " |      >>> words = job_titles.tokenize(\" \")\n",
      " |      >>> w2v_model = H2OWord2vecEstimator(epochs=3, vec_size=50)\n",
      " |      >>> w2v_model.train(training_frame=words)\n",
      " |      >>> synonyms = w2v_model.find_synonyms(\"tutor\", 3)\n",
      " |      >>> print(synonyms)\n",
      " |  \n",
      " |  window_size\n",
      " |      Set max skip length between words\n",
      " |      \n",
      " |      Type: ``int``  (default: ``5``).\n",
      " |      \n",
      " |      :examples:\n",
      " |      \n",
      " |      >>> job_titles = h2o.import_file((\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/craigslistJobTitles.csv\"), \n",
      " |      ...                               col_names = [\"category\", \"jobtitle\"], \n",
      " |      ...                               col_types = [\"string\", \"string\"], \n",
      " |      ...                               header = 1)\n",
      " |      >>> words = job_titles.tokenize(\" \")\n",
      " |      >>> w2v_model = H2OWord2vecEstimator(epochs=3, window_size=2)\n",
      " |      >>> w2v_model.train(training_frame=words)\n",
      " |      >>> synonyms = w2v_model.find_synonyms(\"teacher\", 3)\n",
      " |      >>> print(synonyms)\n",
      " |  \n",
      " |  word_model\n",
      " |      Use the Skip-Gram model\n",
      " |      \n",
      " |      One of: ``\"skip_gram\"``  (default: ``\"skip_gram\"``).\n",
      " |      \n",
      " |      :examples:\n",
      " |      \n",
      " |      >>> job_titles = h2o.import_file((\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/craigslistJobTitles.csv\"), \n",
      " |      ...                               col_names = [\"category\", \"jobtitle\"], \n",
      " |      ...                               col_types = [\"string\", \"string\"], \n",
      " |      ...                               header = 1)\n",
      " |      >>> words = job_titles.tokenize(\" \")\n",
      " |      >>> w2v_model = H2OWord2vecEstimator(epochs=3, word_model=\"skip_gram\")\n",
      " |      >>> w2v_model.train(training_frame=words)\n",
      " |      >>> synonyms = w2v_model.find_synonyms(\"assistant\", 3)\n",
      " |      >>> print(synonyms)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  algo = 'word2vec'\n",
      " |  \n",
      " |  param_names = {'epochs', 'export_checkpoints_dir', 'init_learning_rate...\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from h2o.estimators.estimator_base.H2OEstimator:\n",
      " |  \n",
      " |  convert_H2OXGBoostParams_2_XGBoostParams(self)\n",
      " |      In order to use convert_H2OXGBoostParams_2_XGBoostParams and convert_H2OFrame_2_DMatrix, you must import\n",
      " |      the following toolboxes: xgboost, pandas, numpy and scipy.sparse.\n",
      " |      \n",
      " |      Given an H2OXGBoost model, this method will generate the corresponding parameters that should be used by\n",
      " |      native XGBoost in order to give exactly the same result, assuming that the same dataset\n",
      " |      (derived from h2oFrame) is used to train the native XGBoost model.\n",
      " |      \n",
      " |      Follow the steps below to compare H2OXGBoost and native XGBoost:\n",
      " |      \n",
      " |       1. Train the H2OXGBoost model with H2OFrame trainFile and generate a prediction:\n",
      " |      \n",
      " |        - h2oModelD = H2OXGBoostEstimator(\\*\\*h2oParamsD) # parameters specified as a dict()\n",
      " |        - h2oModelD.train(x=myX, y=y, training_frame=trainFile) # train with H2OFrame trainFile\n",
      " |        - h2oPredict = h2oPredictD = h2oModelD.predict(trainFile)\n",
      " |      \n",
      " |       2. Derive the DMatrix from H2OFrame:\n",
      " |       \n",
      " |        - nativeDMatrix = trainFile.convert_H2OFrame_2_DMatrix(myX, y, h2oModelD)\n",
      " |      \n",
      " |       3. Derive the parameters for native XGBoost:\n",
      " |       \n",
      " |        - nativeParams = h2oModelD.convert_H2OXGBoostParams_2_XGBoostParams()\n",
      " |      \n",
      " |       4. Train your native XGBoost model and generate a prediction:\n",
      " |       \n",
      " |        - nativeModel = xgb.train(params=nativeParams[0], dtrain=nativeDMatrix, num_boost_round=nativeParams[1])\n",
      " |        - nativePredict = nativeModel.predict(data=nativeDMatrix, ntree_limit=nativeParams[1]\n",
      " |      \n",
      " |       5. Compare the predictions h2oPredict from H2OXGBoost, nativePredict from native XGBoost.\n",
      " |      \n",
      " |      :return: nativeParams, num_boost_round\n",
      " |  \n",
      " |  fit(self, X, y=None, **params)\n",
      " |      Fit an H2O model as part of a scikit-learn pipeline or grid search.\n",
      " |      \n",
      " |      A warning will be issued if a caller other than sklearn attempts to use this method.\n",
      " |      \n",
      " |      :param H2OFrame X: An H2OFrame consisting of the predictor variables.\n",
      " |      :param H2OFrame y: An H2OFrame consisting of the response variable.\n",
      " |      :param params: Extra arguments.\n",
      " |      :returns: The current instance of H2OEstimator for method chaining.\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Obtain parameters for this estimator.\n",
      " |      \n",
      " |      Used primarily for sklearn Pipelines and sklearn grid search.\n",
      " |      \n",
      " |      :param deep: If True, return parameters of all sub-objects that are estimators.\n",
      " |      \n",
      " |      :returns: A dict of parameters\n",
      " |  \n",
      " |  join(self)\n",
      " |      Wait until job's completion.\n",
      " |  \n",
      " |  set_params(self, **parms)\n",
      " |      Used by sklearn for updating parameters during grid search.\n",
      " |      \n",
      " |      :param parms: A dictionary of parameters that will be set on this model.\n",
      " |      :returns: self, the current estimator object with the parameters all set as desired.\n",
      " |  \n",
      " |  start(self, x, y=None, training_frame=None, offset_column=None, fold_column=None, weights_column=None, validation_frame=None, **params)\n",
      " |      Train the model asynchronously (to block for results call :meth:`join`).\n",
      " |      \n",
      " |      :param x: A list of column names or indices indicating the predictor columns.\n",
      " |      :param y: An index or a column name indicating the response column.\n",
      " |      :param H2OFrame training_frame: The H2OFrame having the columns indicated by x and y (as well as any\n",
      " |          additional columns specified by fold, offset, and weights).\n",
      " |      :param offset_column: The name or index of the column in training_frame that holds the offsets.\n",
      " |      :param fold_column: The name or index of the column in training_frame that holds the per-row fold\n",
      " |          assignments.\n",
      " |      :param weights_column: The name or index of the column in training_frame that holds the per-row weights.\n",
      " |      :param validation_frame: H2OFrame with validation data to be scored on while training.\n",
      " |  \n",
      " |  train(self, x=None, y=None, training_frame=None, offset_column=None, fold_column=None, weights_column=None, validation_frame=None, max_runtime_secs=None, ignored_columns=None, model_id=None, verbose=False)\n",
      " |      Train the H2O model.\n",
      " |      \n",
      " |      :param x: A list of column names or indices indicating the predictor columns.\n",
      " |      :param y: An index or a column name indicating the response column.\n",
      " |      :param H2OFrame training_frame: The H2OFrame having the columns indicated by x and y (as well as any\n",
      " |          additional columns specified by fold, offset, and weights).\n",
      " |      :param offset_column: The name or index of the column in training_frame that holds the offsets.\n",
      " |      :param fold_column: The name or index of the column in training_frame that holds the per-row fold\n",
      " |          assignments.\n",
      " |      :param weights_column: The name or index of the column in training_frame that holds the per-row weights.\n",
      " |      :param validation_frame: H2OFrame with validation data to be scored on while training.\n",
      " |      :param float max_runtime_secs: Maximum allowed runtime in seconds for model training. Use 0 to disable.\n",
      " |      :param bool verbose: Print scoring history to stdout. Defaults to False.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from h2o.estimators.estimator_base.H2OEstimator:\n",
      " |  \n",
      " |  mixin(obj, cls)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from h2o.model.model_base.ModelBase:\n",
      " |  \n",
      " |  __getattr__(self, name)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  aic(self, train=False, valid=False, xval=False)\n",
      " |      Get the AIC (Akaike Information Criterium).\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the AIC value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the AIC value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the AIC value for the validation data.\n",
      " |      \n",
      " |      :returns: The AIC.\n",
      " |  \n",
      " |  auc(self, train=False, valid=False, xval=False)\n",
      " |      Get the AUC (Area Under Curve).\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the AUC value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the AUC value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the AUC value for the validation data.\n",
      " |      \n",
      " |      :returns: The AUC.\n",
      " |  \n",
      " |  aucpr(self, train=False, valid=False, xval=False)\n",
      " |      Get the aucPR (Area Under PRECISION RECALL Curve).\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the aucpr value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the aucpr value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the aucpr value for the validation data.\n",
      " |      \n",
      " |      :returns: The aucpr.\n",
      " |  \n",
      " |  biases(self, vector_id=0)\n",
      " |      Return the frame for the respective bias vector.\n",
      " |      \n",
      " |      :param: vector_id: an integer, ranging from 0 to number of layers, that specifies the bias vector to return.\n",
      " |      \n",
      " |      :returns: an H2OFrame which represents the bias vector identified by vector_id\n",
      " |  \n",
      " |  catoffsets(self)\n",
      " |      Categorical offsets for one-hot encoding.\n",
      " |  \n",
      " |  coef(self)\n",
      " |      Return the coefficients which can be applied to the non-standardized data.\n",
      " |      \n",
      " |      Note: standardize = True by default, if set to False then coef() return the coefficients which are fit directly.\n",
      " |  \n",
      " |  coef_norm(self)\n",
      " |      Return coefficients fitted on the standardized data (requires standardize = True, which is on by default).\n",
      " |      \n",
      " |      These coefficients can be used to evaluate variable importance.\n",
      " |  \n",
      " |  cross_validation_fold_assignment(self)\n",
      " |      Obtain the cross-validation fold assignment for all rows in the training data.\n",
      " |      \n",
      " |      :returns: H2OFrame\n",
      " |  \n",
      " |  cross_validation_holdout_predictions(self)\n",
      " |      Obtain the (out-of-sample) holdout predictions of all cross-validation models on the training data.\n",
      " |      \n",
      " |      This is equivalent to summing up all H2OFrames returned by cross_validation_predictions.\n",
      " |      \n",
      " |      :returns: H2OFrame\n",
      " |  \n",
      " |  cross_validation_metrics_summary(self)\n",
      " |      Retrieve Cross-Validation Metrics Summary.\n",
      " |      \n",
      " |      :returns: The cross-validation metrics summary as an H2OTwoDimTable\n",
      " |  \n",
      " |  cross_validation_models(self)\n",
      " |      Obtain a list of cross-validation models.\n",
      " |      \n",
      " |      :returns: list of H2OModel objects.\n",
      " |  \n",
      " |  cross_validation_predictions(self)\n",
      " |      Obtain the (out-of-sample) holdout predictions of all cross-validation models on their holdout data.\n",
      " |      \n",
      " |      Note that the predictions are expanded to the full number of rows of the training data, with 0 fill-in.\n",
      " |      \n",
      " |      :returns: list of H2OFrame objects.\n",
      " |  \n",
      " |  deepfeatures(self, test_data, layer)\n",
      " |      Return hidden layer details.\n",
      " |      \n",
      " |      :param test_data: Data to create a feature space on\n",
      " |      :param layer: 0 index hidden layer\n",
      " |  \n",
      " |  detach(self)\n",
      " |      Detach the Python object from the backend, usually by clearing its key\n",
      " |  \n",
      " |  download_model(self, path='')\n",
      " |      Download an H2O Model object to disk.\n",
      " |      \n",
      " |      :param model: The model object to download.\n",
      " |      :param path: a path to the directory where the model should be saved.\n",
      " |      \n",
      " |      :returns: the path of the downloaded model\n",
      " |  \n",
      " |  download_mojo(self, path='.', get_genmodel_jar=False, genmodel_name='')\n",
      " |      Download the model in MOJO format.\n",
      " |      \n",
      " |      :param path: the path where MOJO file should be saved.\n",
      " |      :param get_genmodel_jar: if True, then also download h2o-genmodel.jar and store it in folder ``path``.\n",
      " |      :param genmodel_name: Custom name of genmodel jar\n",
      " |      :returns: name of the MOJO file written.\n",
      " |  \n",
      " |  download_pojo(self, path='', get_genmodel_jar=False, genmodel_name='')\n",
      " |      Download the POJO for this model to the directory specified by path.\n",
      " |      \n",
      " |      If path is an empty string, then dump the output to screen.\n",
      " |      \n",
      " |      :param path:  An absolute path to the directory where POJO should be saved.\n",
      " |      :param get_genmodel_jar: if True, then also download h2o-genmodel.jar and store it in folder ``path``.\n",
      " |      :param genmodel_name: Custom name of genmodel jar\n",
      " |      :returns: name of the POJO file written.\n",
      " |  \n",
      " |  feature_frequencies(self, test_data)\n",
      " |      Retrieve the number of occurrences of each feature for given observations \n",
      " |      on their respective paths in a tree ensemble model.\n",
      " |      Available for GBM, Random Forest and Isolation Forest models.\n",
      " |      \n",
      " |      :param H2OFrame test_data: Data on which to calculate feature frequencies.\n",
      " |      \n",
      " |      :returns: A new H2OFrame made of feature contributions.\n",
      " |  \n",
      " |  get_xval_models(self, key=None)\n",
      " |      Return a Model object.\n",
      " |      \n",
      " |      :param key: If None, return all cross-validated models; otherwise return the model that key points to.\n",
      " |      \n",
      " |      :returns: A model or list of models.\n",
      " |  \n",
      " |  gini(self, train=False, valid=False, xval=False)\n",
      " |      Get the Gini coefficient.\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\"\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the Gini Coefficient value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the Gini Coefficient value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the Gini Coefficient value for the cross validation data.\n",
      " |      \n",
      " |      :returns: The Gini Coefficient for this binomial model.\n",
      " |  \n",
      " |  is_cross_validated(self)\n",
      " |      Return True if the model was cross-validated.\n",
      " |  \n",
      " |  logloss(self, train=False, valid=False, xval=False)\n",
      " |      Get the Log Loss.\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the log loss value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the log loss value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the log loss value for the cross validation data.\n",
      " |      \n",
      " |      :returns: The log loss for this regression model.\n",
      " |  \n",
      " |  mae(self, train=False, valid=False, xval=False)\n",
      " |      Get the Mean Absolute Error.\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the MAE value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the MAE value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the MAE value for the cross validation data.\n",
      " |      \n",
      " |      :returns: The MAE for this regression model.\n",
      " |  \n",
      " |  mean_residual_deviance(self, train=False, valid=False, xval=False)\n",
      " |      Get the Mean Residual Deviances.\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the Mean Residual Deviance value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the Mean Residual Deviance value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the Mean Residual Deviance value for the cross validation data.\n",
      " |      \n",
      " |      :returns: The Mean Residual Deviance for this regression model.\n",
      " |  \n",
      " |  model_performance(self, test_data=None, train=False, valid=False, xval=False)\n",
      " |      Generate model metrics for this model on test_data.\n",
      " |      \n",
      " |      :param H2OFrame test_data: Data set for which model metrics shall be computed against. All three of train,\n",
      " |          valid and xval arguments are ignored if test_data is not None.\n",
      " |      :param bool train: Report the training metrics for the model.\n",
      " |      :param bool valid: Report the validation metrics for the model.\n",
      " |      :param bool xval: Report the cross-validation metrics for the model. If train and valid are True, then it\n",
      " |          defaults to True.\n",
      " |      \n",
      " |      :returns: An object of class H2OModelMetrics.\n",
      " |  \n",
      " |  mse(self, train=False, valid=False, xval=False)\n",
      " |      Get the Mean Square Error.\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the MSE value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the MSE value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the MSE value for the cross validation data.\n",
      " |      \n",
      " |      :returns: The MSE for this regression model.\n",
      " |  \n",
      " |  normmul(self)\n",
      " |      Normalization/Standardization multipliers for numeric predictors.\n",
      " |  \n",
      " |  normsub(self)\n",
      " |      Normalization/Standardization offsets for numeric predictors.\n",
      " |  \n",
      " |  ntrees_actual(self)\n",
      " |      Returns actual number of trees in a tree model. If early stopping enabled, GBM can reset the ntrees value.\n",
      " |      In this case, the actual ntrees value is less than the original ntrees value a user set before\n",
      " |      building the model.\n",
      " |      \n",
      " |      Type: ``float``\n",
      " |  \n",
      " |  null_degrees_of_freedom(self, train=False, valid=False, xval=False)\n",
      " |      Retreive the null degress of freedom if this model has the attribute, or None otherwise.\n",
      " |      \n",
      " |      :param bool train: Get the null dof for the training set. If both train and valid are False, then train is\n",
      " |          selected by default.\n",
      " |      :param bool valid: Get the null dof for the validation set. If both train and valid are True, then train is\n",
      " |          selected by default.\n",
      " |      \n",
      " |      :returns: Return the null dof, or None if it is not present.\n",
      " |  \n",
      " |  null_deviance(self, train=False, valid=False, xval=False)\n",
      " |      Retreive the null deviance if this model has the attribute, or None otherwise.\n",
      " |      \n",
      " |      :param bool train: Get the null deviance for the training set. If both train and valid are False, then train\n",
      " |          is selected by default.\n",
      " |      :param bool valid: Get the null deviance for the validation set. If both train and valid are True, then train\n",
      " |          is selected by default.\n",
      " |      \n",
      " |      :returns: Return the null deviance, or None if it is not present.\n",
      " |  \n",
      " |  partial_plot(self, data, cols=None, destination_key=None, nbins=20, weight_column=None, plot=True, plot_stddev=True, figsize=(7, 10), server=False, include_na=False, user_splits=None, col_pairs_2dpdp=None, save_to_file=None, row_index=None)\n",
      " |      Create partial dependence plot which gives a graphical depiction of the marginal effect of a variable on the\n",
      " |      response. The effect of a variable is measured in change in the mean response.\n",
      " |      \n",
      " |      :param H2OFrame data: An H2OFrame object used for scoring and constructing the plot.\n",
      " |      :param cols: Feature(s) for which partial dependence will be calculated.\n",
      " |      :param destination_key: An key reference to the created partial dependence tables in H2O.\n",
      " |      :param nbins: Number of bins used. For categorical columns make sure the number of bins exceed the level count. If you enable add_missing_NA, the returned length will be nbin+1.\n",
      " |      :param weight_column: A string denoting which column of data should be used as the weight column.\n",
      " |      :param plot: A boolean specifying whether to plot partial dependence table.\n",
      " |      :param plot_stddev: A boolean specifying whether to add std err to partial dependence plot.\n",
      " |      :param figsize: Dimension/size of the returning plots, adjust to fit your output cells.\n",
      " |      :param server: Specify whether to activate matplotlib \"server\" mode. In this case, the plots are saved to a file instead of being rendered.\n",
      " |      :param include_na: A boolean specifying whether missing value should be included in the Feature values.\n",
      " |      :param user_splits: a dictionary containing column names as key and user defined split values as value in a list.\n",
      " |      :param col_pairs_2dpdp: list containing pairs of column names for 2D pdp\n",
      " |      :param save_to_file: Fully qualified name to an image file the resulting plot should be saved to, e.g. '/home/user/pdpplot.png'. The 'png' postfix might be omitted. If the file already exists, it will be overridden. Plot is only saved if plot = True.\n",
      " |      :param row_index: Row for which partial dependence will be calculated instead of the whole input frame.\n",
      " |      :returns: Plot and list of calculated mean response tables for each feature requested.\n",
      " |  \n",
      " |  pprint_coef(self)\n",
      " |      Pretty print the coefficents table (includes normalized coefficients).\n",
      " |  \n",
      " |  pr_auc(self, train=False, valid=False, xval=False)\n",
      " |      ModelBase.pr_auc is deprecated, please use ``ModelBase.aucpr`` instead.\n",
      " |  \n",
      " |  predict(self, test_data, custom_metric=None, custom_metric_func=None)\n",
      " |      Predict on a dataset.\n",
      " |      \n",
      " |      :param H2OFrame test_data: Data on which to make predictions.\n",
      " |      :param custom_metric:  custom evaluation function defined as class reference, the class get uploaded\n",
      " |          into the cluster\n",
      " |      :param custom_metric_func: custom evaluation function reference, e.g, result of upload_custom_metric\n",
      " |      \n",
      " |      :returns: A new H2OFrame of predictions.\n",
      " |  \n",
      " |  predict_contributions(self, test_data)\n",
      " |      Predict feature contributions - SHAP values on an H2O Model (only GBM and XGBoost models).\n",
      " |      \n",
      " |      Returned H2OFrame has shape (#rows, #features + 1) - there is a feature contribution column for each input\n",
      " |      feature, the last column is the model bias (same value for each row). The sum of the feature contributions\n",
      " |      and the bias term is equal to the raw prediction of the model. Raw prediction of tree-based model is the sum \n",
      " |      of the predictions of the individual trees before before the inverse link function is applied to get the actual\n",
      " |      prediction. For Gaussian distribution the sum of the contributions is equal to the model prediction. \n",
      " |      \n",
      " |      Note: Multinomial classification models are currently not supported.\n",
      " |      \n",
      " |      :param H2OFrame test_data: Data on which to calculate contributions.\n",
      " |      \n",
      " |      :returns: A new H2OFrame made of feature contributions.\n",
      " |  \n",
      " |  predict_leaf_node_assignment(self, test_data, type='Path')\n",
      " |      Predict on a dataset and return the leaf node assignment (only for tree-based models).\n",
      " |      \n",
      " |      :param H2OFrame test_data: Data on which to make predictions.\n",
      " |      :param Enum type: How to identify the leaf node. Nodes can be either identified by a path from to the root node\n",
      " |          of the tree to the node or by H2O's internal node id. One of: ``\"Path\"``, ``\"Node_ID\"`` (default: ``\"Path\"``).\n",
      " |      \n",
      " |      :returns: A new H2OFrame of predictions.\n",
      " |  \n",
      " |  r2(self, train=False, valid=False, xval=False)\n",
      " |      Return the R squared for this regression model.\n",
      " |      \n",
      " |      Will return R^2 for GLM Models and will return NaN otherwise.\n",
      " |      \n",
      " |      The R^2 value is defined to be 1 - MSE/var, where var is computed as sigma*sigma.\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the R^2 value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the R^2 value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the R^2 value for the cross validation data.\n",
      " |      \n",
      " |      :returns: The R squared for this regression model.\n",
      " |  \n",
      " |  residual_degrees_of_freedom(self, train=False, valid=False, xval=False)\n",
      " |      Retreive the residual degress of freedom if this model has the attribute, or None otherwise.\n",
      " |      \n",
      " |      :param bool train: Get the residual dof for the training set. If both train and valid are False, then train\n",
      " |          is selected by default.\n",
      " |      :param bool valid: Get the residual dof for the validation set. If both train and valid are True, then train\n",
      " |          is selected by default.\n",
      " |      \n",
      " |      :returns: Return the residual dof, or None if it is not present.\n",
      " |  \n",
      " |  residual_deviance(self, train=False, valid=False, xval=None)\n",
      " |      Retreive the residual deviance if this model has the attribute, or None otherwise.\n",
      " |      \n",
      " |      :param bool train: Get the residual deviance for the training set. If both train and valid are False, then\n",
      " |          train is selected by default.\n",
      " |      :param bool valid: Get the residual deviance for the validation set. If both train and valid are True, then\n",
      " |          train is selected by default.\n",
      " |      \n",
      " |      :returns: Return the residual deviance, or None if it is not present.\n",
      " |  \n",
      " |  respmul(self)\n",
      " |      Normalization/Standardization multipliers for numeric response.\n",
      " |  \n",
      " |  respsub(self)\n",
      " |      Normalization/Standardization offsets for numeric response.\n",
      " |  \n",
      " |  rmse(self, train=False, valid=False, xval=False)\n",
      " |      Get the Root Mean Square Error.\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the RMSE value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the RMSE value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the RMSE value for the cross validation data.\n",
      " |      \n",
      " |      :returns: The RMSE for this regression model.\n",
      " |  \n",
      " |  rmsle(self, train=False, valid=False, xval=False)\n",
      " |      Get the Root Mean Squared Logarithmic Error.\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the RMSLE value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the RMSLE value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the RMSLE value for the cross validation data.\n",
      " |      \n",
      " |      :returns: The RMSLE for this regression model.\n",
      " |  \n",
      " |  rotation(self)\n",
      " |      Obtain the rotations (eigenvectors) for a PCA model\n",
      " |      \n",
      " |      :return: H2OFrame\n",
      " |  \n",
      " |  save_model_details(self, path='', force=False)\n",
      " |      Save Model Details of an H2O Model in JSON Format to disk.\n",
      " |      \n",
      " |      :param model: The model object to save.\n",
      " |      :param path: a path to save the model details at (hdfs, s3, local)\n",
      " |      :param force: if True overwrite destination directory in case it exists, or throw exception if set to False.\n",
      " |      \n",
      " |      :returns str: the path of the saved model details\n",
      " |  \n",
      " |  save_mojo(self, path='', force=False)\n",
      " |      Save an H2O Model as MOJO (Model Object, Optimized) to disk.\n",
      " |      \n",
      " |      :param model: The model object to save.\n",
      " |      :param path: a path to save the model at (hdfs, s3, local)\n",
      " |      :param force: if True overwrite destination directory in case it exists, or throw exception if set to False.\n",
      " |      \n",
      " |      :returns str: the path of the saved model\n",
      " |  \n",
      " |  score_history(self)\n",
      " |      DEPRECATED. Use :meth:`scoring_history` instead.\n",
      " |  \n",
      " |  scoring_history(self)\n",
      " |      Retrieve Model Score History.\n",
      " |      \n",
      " |      :returns: The score history as an H2OTwoDimTable or a Pandas DataFrame.\n",
      " |  \n",
      " |  show(self)\n",
      " |      Print innards of model, without regards to type.\n",
      " |  \n",
      " |  staged_predict_proba(self, test_data)\n",
      " |      Predict class probabilities at each stage of an H2O Model (only GBM models).\n",
      " |      \n",
      " |      The output structure is analogous to the output of function predict_leaf_node_assignment. For each tree t and\n",
      " |      class c there will be a column Tt.Cc (eg. T3.C1 for tree 3 and class 1). The value will be the corresponding\n",
      " |      predicted probability of this class by combining the raw contributions of trees T1.Cc,..,TtCc. Binomial models\n",
      " |      build the trees just for the first class and values in columns Tx.C1 thus correspond to the the probability p0.\n",
      " |      \n",
      " |      :param H2OFrame test_data: Data on which to make predictions.\n",
      " |      \n",
      " |      :returns: A new H2OFrame of staged predictions.\n",
      " |  \n",
      " |  std_coef_plot(self, num_of_features=None, server=False)\n",
      " |      Plot a GLM model\"s standardized coefficient magnitudes.\n",
      " |      \n",
      " |      :param num_of_features: the number of features shown in the plot.\n",
      " |      :param server: ?\n",
      " |      \n",
      " |      :returns: None.\n",
      " |  \n",
      " |  summary(self)\n",
      " |      Print a detailed summary of the model.\n",
      " |  \n",
      " |  training_model_metrics(self)\n",
      " |      Return training model metrics for any model.\n",
      " |  \n",
      " |  varimp(self, use_pandas=False)\n",
      " |      Pretty print the variable importances, or return them in a list.\n",
      " |      \n",
      " |      :param bool use_pandas: If True, then the variable importances will be returned as a pandas data frame.\n",
      " |      \n",
      " |      :returns: A list or Pandas DataFrame.\n",
      " |  \n",
      " |  varimp_plot(self, num_of_features=None, server=False)\n",
      " |      Plot the variable importance for a trained model.\n",
      " |      \n",
      " |      :param num_of_features: the number of features shown in the plot (default is 10 or all if less than 10).\n",
      " |      :param server: ?\n",
      " |      \n",
      " |      :returns: None.\n",
      " |  \n",
      " |  weights(self, matrix_id=0)\n",
      " |      Return the frame for the respective weight matrix.\n",
      " |      \n",
      " |      :param matrix_id: an integer, ranging from 0 to number of layers, that specifies the weight matrix to return.\n",
      " |      \n",
      " |      :returns: an H2OFrame which represents the weight matrix identified by matrix_id\n",
      " |  \n",
      " |  xval_keys(self)\n",
      " |      Return model keys for the cross-validated model.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from h2o.model.model_base.ModelBase:\n",
      " |  \n",
      " |  actual_params\n",
      " |      Dictionary of actual parameters of the model.\n",
      " |  \n",
      " |  default_params\n",
      " |      Dictionary of the default parameters of the model.\n",
      " |  \n",
      " |  end_time\n",
      " |      Timestamp (milliseconds since 1970) when the model training was ended.\n",
      " |  \n",
      " |  full_parameters\n",
      " |      Dictionary of the full specification of all parameters.\n",
      " |  \n",
      " |  have_mojo\n",
      " |      True, if export to MOJO is possible\n",
      " |  \n",
      " |  have_pojo\n",
      " |      True, if export to POJO is possible\n",
      " |  \n",
      " |  key\n",
      " |      :return: the unique key representing the object on the backend\n",
      " |  \n",
      " |  model_id\n",
      " |      Model identifier.\n",
      " |  \n",
      " |  params\n",
      " |      Get the parameters and the actual/default values only.\n",
      " |      \n",
      " |      :returns: A dictionary of parameters used to build this model.\n",
      " |  \n",
      " |  run_time\n",
      " |      Model training time in milliseconds\n",
      " |  \n",
      " |  start_time\n",
      " |      Timestamp (milliseconds since 1970) when the model training was started.\n",
      " |  \n",
      " |  type\n",
      " |      The type of model built: ``\"classifier\"`` or ``\"regressor\"`` or ``\"unsupervised\"``\n",
      " |  \n",
      " |  xvals\n",
      " |      Return a list of the cross-validated models.\n",
      " |      \n",
      " |      :returns: A list of models.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from h2o.base.Keyed:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from h2o.estimators.word2vec import H2OWord2vecEstimator\n",
    "help(H2OWord2vecEstimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_reviews = review_df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pdf_reviews' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-0abfe5d900ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcount_vect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mfit_count_vect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount_vect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdf_reviews\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_count_vect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdf_reviews\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pdf_reviews' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "fit_count_vect = count_vect.fit(pdf_reviews)\n",
    "\n",
    "x = fit_count_vect.transform(pdf_reviews.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The usage of `cmp` is deprecated and will be removed on or after 2021-06-01.  Please use `eq` and `order` instead.\n",
      "The default validate=True will be replaced by validate=False in 0.22.\n",
      "Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "The default validate=True will be replaced by validate=False in 0.22.\n",
      "Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "The default validate=True will be replaced by validate=False in 0.22.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving artifact of size: 2.221 KB to Splice Machine DB\n",
      "Saving model of size: 2.221 KB to Splice Machine DB\n",
      "Prediction labels found. Using ['C0', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7'] as labels for predictions [0, 1, 2, 3, 4, 5, 6, 7] respectively\n",
      "Deploying model 893ed233c789 to table ben.sk_vec_pipe\n",
      "Creating data table ... \n",
      " CREATE TABLE ben.sk_vec_pipe (\n",
      "\tsentence VARCHAR(5000),\tMOMENT_KEY INT,\n",
      "\tPRIMARY KEY(MOMENT_KEY)\n",
      ")\n",
      "\n",
      "Done.\n",
      "Creating prediction table ... \n",
      "CREATE TABLE ben.sk_vec_pipe_PREDS (\n",
      "        \tCUR_USER VARCHAR(50) DEFAULT CURRENT_USER,\n",
      "        \tEVAL_TIME TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
      "        \tRUN_ID VARCHAR(50) DEFAULT '893ed233c789',\n",
      "        \tMOMENT_KEY INT,\n",
      "\t\"C0\" DOUBLE,\n",
      "\t\"C1\" DOUBLE,\n",
      "\t\"C2\" DOUBLE,\n",
      "\t\"C3\" DOUBLE,\n",
      "\t\"C4\" DOUBLE,\n",
      "\t\"C5\" DOUBLE,\n",
      "\t\"C6\" DOUBLE,\n",
      "\t\"C7\" DOUBLE,\n",
      "\tPRIMARY KEY(MOMENT_KEY)\n",
      ")\n",
      "\n",
      "Done.\n",
      "Creating model prediction trigger ... \n",
      "CREATE TRIGGER runModel_ben_sk_vec_pipe_893ed233c789\n",
      " \tAFTER INSERT\n",
      " \tON ben.sk_vec_pipe\n",
      " \tREFERENCING NEW AS NEWROW\n",
      " \tFOR EACH ROW\n",
      " \t\tINSERT INTO ben.sk_vec_pipe_PREDS(MOMENT_KEY,\"C0\",\"C1\",\"C2\",\"C3\",\"C4\",\"C5\",\"C6\",\"C7\") SELECT \tNEWROW.MOMENT_KEY, b.\"C0\",b.\"C1\",b.\"C2\",b.\"C3\",b.\"C4\",b.\"C5\",b.\"C6\",b.\"C7\" FROM new com.splicemachine.mlrunner.MLRunner('key_value', '893ed233c789', TRIM(CAST(NEWROW.sentence as CHAR(41))), 'sentence VARCHAR(5000)', 'transform', 'None') as b (\"C0\" DOUBLE,\"C1\" DOUBLE,\"C2\" DOUBLE,\"C3\" DOUBLE,\"C4\" DOUBLE,\"C5\" DOUBLE,\"C6\" DOUBLE,\"C7\" DOUBLE)\n",
      "\n",
      "Done.\n",
      "Model Deployed.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline as skPipe\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "import pandas as pd\n",
    "# #Custom Transformer that extracts columns passed as argument to its constructor \n",
    "# class PreProcessor( BaseEstimator, TransformerMixin ):\n",
    "#     #Class Constructor \n",
    "#     def __init__( self ):\n",
    "#         pass\n",
    "    \n",
    "#     #Return self nothing else to do here    \n",
    "#     def fit( self, X, y = None):\n",
    "#         return self\n",
    "    \n",
    "#     #Method that describes what we need this transformer to do\n",
    "#     def transform( self, X, y = None ):\n",
    "#         return X[0]\n",
    "\n",
    "# #Custom Transformer that extracts columns passed as argument to its constructor \n",
    "# class VectorSelector( BaseEstimator, TransformerMixin ):\n",
    "#     #Class Constructor \n",
    "#     def __init__( self ):\n",
    "#         pass\n",
    "    \n",
    "#     #Return self nothing else to do here    \n",
    "#     def fit( self, X, y = None):\n",
    "#         return self \n",
    "    \n",
    "#     #Method that describes what we need this transformer to do\n",
    "#     def transform( self, X, y = None ):\n",
    "#         return X.toarray()\n",
    "\n",
    "\n",
    "# def pre_process(X):\n",
    "#     return X[0]\n",
    "# def get_vector(X):\n",
    "#     return X.toarray()\n",
    "# p = skPipe(steps = [\n",
    "#     ('preprocessor', FunctionTransformer(pre_process)),\n",
    "#     ('vectorizer', TfidfVectorizer()),\n",
    "#     ('vector_returner', FunctionTransformer(get_vector, accept_sparse=True))\n",
    "# ])\n",
    "\n",
    "# list of text documents\n",
    "text = [\"The quick brown fox jumped over the lazy dog.\",\n",
    "        \"The dog.\",\n",
    "        \"The fox\"]\n",
    "\n",
    "p = skPipe(steps = [\n",
    "    ('preprocessor', FunctionTransformer(lambda x: x[0])),\n",
    "    ('vectorizer', TfidfVectorizer()),\n",
    "    ('vector_returner', FunctionTransformer(lambda x: x.toarray(), accept_sparse=True))\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# tokenize and build vocab\n",
    "p.fit([text])\n",
    "\n",
    "# vector = p.transform([[text[0]]])\n",
    "\n",
    "\n",
    "splice._dropTableIfExists('ben.sk_vec_pipe')\n",
    "splice._dropTableIfExists('ben.sk_vec_pipe_preds')\n",
    "with mlflow.start_run(run_name = 'sk_tokenizer2'):\n",
    "    mlflow.log_model(p, 'tokenizer_model2')\n",
    "    mlflow.deploy_db(p, pd.DataFrame(text,columns=['sentence']), 'ben', 'sk_vec_pipe', [('MOMENT_KEY', 'INT')], run_id=mlflow.current_run_id(),\n",
    "                     classes = [f'C{i}' for i in range(8)], verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f5e1e44-b1b8-48b9-82c7-5e8ea45eb874",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0417e1d-397c-4d83-b7c8-7e8b9e979fcc",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "CREATE TABLE ben.sk_vec_pipe_2 (\n",
    "\tsentence VARCHAR(5000),\tMOMENT_KEY INT,\n",
    "    CUR_USER VARCHAR(50) DEFAULT CURRENT_USER,\n",
    "    EVAL_TIME TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "    RUN_ID VARCHAR(50) DEFAULT '893ed233c789',\n",
    "    \"C0\" DOUBLE,\n",
    "\t\"C1\" DOUBLE,\n",
    "\t\"C2\" DOUBLE,\n",
    "\t\"C3\" DOUBLE,\n",
    "\t\"C4\" DOUBLE,\n",
    "\t\"C5\" DOUBLE,\n",
    "\t\"C6\" DOUBLE,\n",
    "\t\"C7\" DOUBLE,\n",
    "\tPRIMARY KEY(MOMENT_KEY)\n",
    ");\n",
    "CREATE TRIGGER runModel_ben_sk_vec_pipe_2_893ed233c789\n",
    " \tAFTER INSERT\n",
    " \tON ben.sk_vec_pipe_2\n",
    " \tREFERENCING NEW AS NEWROW\n",
    " \tFOR EACH ROW\n",
    " \t\tINSERT INTO ben.sk_vec_pipe_2(MOMENT_KEY,\"C0\",\"C1\",\"C2\",\"C3\",\"C4\",\"C5\",\"C6\",\"C7\") --splice-properties insertMode=UPSERT\n",
    "        SELECT \tNEWROW.MOMENT_KEY, b.\"C0\",b.\"C1\",b.\"C2\",b.\"C3\",b.\"C4\",b.\"C5\",b.\"C6\",b.\"C7\" FROM new com.splicemachine.mlrunner.MLRunner('key_value', '893ed233c789', TRIM(CAST(NEWROW.sentence as CHAR(41))), 'sentence VARCHAR(5000)', 'transform', 'None') as b (\"C0\" DOUBLE,\"C1\" DOUBLE,\"C2\" DOUBLE,\"C3\" DOUBLE,\"C4\" DOUBLE,\"C5\" DOUBLE,\"C6\" DOUBLE,\"C7\" DOUBLE) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cloudpickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = 'The quick brown fox jumped over the lazy dog.'\n",
    "X = [fast_float(x) for x in X.split(',')]\n",
    "preds = p.transform([X])\n",
    "len(preds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cloudpickle\n",
    "cloudpickle.dump(p,open('model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7609dad-358c-487c-bd73-b81c23dc8cfd",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e22415a-ecf3-42c2-b84c-f9e5f0d6c319",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.56 ms, sys: 4.02 ms, total: 8.58 ms\n",
      "Wall time: 1.06 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%sql\n",
    "insert into ben.sk_vec_pipe_2 (SENTENCE, MOMENT_KEY) values('The dog.', 4);\n",
    "\n",
    "select * from ben.sk_vec_pipe_2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "895eba38-f9b9-4745-a69d-f0c7a27b5852",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfea2c14-1444-48e0-bee6-57d5620b9165",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "%%sql\n",
    "insert into ben.sk_vec_pipe values('The dog.', 1230);\n",
    "\n",
    "select * from ben.sk_vec_pipe_PREDS;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Query executed successfully. Affected rows : 0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "select * from sk_vec_pipe_preds;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The quick brown fox jumped over the lazy dog.'"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[0][:46]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.36388646, 0.27674503, 0.27674503, 0.36388646, 0.36388646,\n",
       "        0.36388646, 0.36388646, 0.42983441]])"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = 'The quick brown fox jumped over the lazy dog.'\n",
    "X = [x for x in X.split(',')]\n",
    "p.transform([X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "212px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
